{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./arxiv_downloads\\\\0812.0743v2.A_Novel_Clustering_Algorithm_Based_on_Quantum_Games.pdf',\n",
       " './arxiv_downloads\\\\1103.4487v1.Handwritten_Digit_Recognition_with_a_Committee_of_Deep_Neural_Nets_on_GPUs.pdf']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rolling.pdf import list_pdfs, read_pdf\n",
    "pdfs = list_pdfs()\n",
    "pdfs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arXiv:0812.0743v2  [cs.LG]  10 Oct 2009\\nA Novel Clustering Algorithm Based on\\nQuantum Games\\nQiang Li, Yan He, Jing-ping Jiang\\nCollege of Electrical Engineering, Zhejiang University,\\nHang Zhou, Zhejiang, 310027, China\\nMay 28, 2018\\nAbstract\\nThe enormous successes have been made by quantum algorithms dur-\\ning the last decade. In this paper, we combine the quantum gam e with\\nthe problem of data clustering, and then develop a quantum-g ame-based\\nclustering algorithm, in which data points in a dataset are c onsidered\\nas players who can make decisions and implement quantum stra tegies in\\nquantum games. After each round of a quantum game, each playe r’s ex-\\npected payoﬀ is calculated. Later, he uses an link-removing -and-rewiring\\n(LRR) function to change his neighbors and adjust the streng th of links\\nconnecting to them in order to maximize his payoﬀ. Further, a lgorithms\\nare discussed and analyzed in two cases of strategies, two pa yoﬀ ma-\\ntrixes and two LRR functions. Consequently, the simul'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = read_pdf(pdfs[0])\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rolling.embedding import GTEEmbeddingModel\n",
    "model = GTEEmbeddingModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper: [-0.05978  0.02739 -0.0586   0.05792  0.04477] ./arxiv_downloads\\0812.0743v2.A_Novel_Clustering_Algorithm_Based_on_Quantum_Games.pdf\n",
      " > 000 [-0.0846   0.0355  -0.0651   0.06506  0.05246] arXiv:0812.0743v2 [cs.LG] 10 Oct 2009 A Novel Clustering Algorithm Based on Quantum Games Qiang Li, Yan He, Jing-ping Jiang College of Electrical Engineering, Zhejiang University, Hang Zhou, Zhejiang, 310027, China May 28, 2018 Abstract The enormous successes have been made by quantum algorithms dur- ing the last decade. In this paper, we combine the quantum gam e with the problem of data clustering, and then develop a quantum-g ame-based clustering algorithm, in which data points in a dataset are c onsidered\n",
      " > 001 [-0.0963   0.03238 -0.05777  0.083    0.04968] successes have been made by quantum algorithms dur- ing the last decade. In this paper, we combine the quantum gam e with the problem of data clustering, and then develop a quantum-g ame-based clustering algorithm, in which data points in a dataset are c onsidered as players who can make decisions and implement quantum stra tegies in quantum games. After each round of a quantum game, each playe r’s ex- pected payoﬀ is calculated. Later, he uses an link-removing -and-rewiring (LRR) function to change his neighbors and\n",
      " > 002 [-0.1095    0.014595 -0.04648   0.0908    0.06024 ] onsidered as players who can make decisions and implement quantum stra tegies in quantum games. After each round of a quantum game, each playe r’s ex- pected payoﬀ is calculated. Later, he uses an link-removing -and-rewiring (LRR) function to change his neighbors and adjust the streng th of links connecting to them in order to maximize his payoﬀ. Further, a lgorithms are discussed and analyzed in two cases of strategies, two pa yoﬀ ma- trixes and two LRR functions. Consequently, the simulation results have demonstrated\n",
      " > 003 [-0.0366   0.03436 -0.06165  0.0847   0.032  ] and adjust the streng th of links connecting to them in order to maximize his payoﬀ. Further, a lgorithms are discussed and analyzed in two cases of strategies, two pa yoﬀ ma- trixes and two LRR functions. Consequently, the simulation results have demonstrated that data points in datasets are clustered rea sonably and eﬃciently, and the clustering algorithms have fast rates of convergence. Moreover, the comparison with other algorithms also provid es an indica- tion of the eﬀectiveness of the proposed approach.\n",
      " > 004 [-0.0598   0.01915 -0.06793  0.0646   0.04584] demonstrated that data points in datasets are clustered rea sonably and eﬃciently, and the clustering algorithms have fast rates of convergence. Moreover, the comparison with other algorithms also provid es an indica- tion of the eﬀectiveness of the proposed approach. Keywords: Unsupervised learning; Data clustering; Quantum compu- tation; Quantum game 1 Introduction Quantum computation is an extremely exciting and rapidly growing ﬁeld . More recently, an increasing number of researchers with diﬀerent backgrounds, ranging\n",
      " > 005 [-0.0764  -0.01968 -0.07025  0.06073  0.04962] approach. Keywords: Unsupervised learning; Data clustering; Quantum compu- tation; Quantum game 1 Introduction Quantum computation is an extremely exciting and rapidly growing ﬁeld . More recently, an increasing number of researchers with diﬀerent backgrounds, ranging from physics, computer sciences and information theory t o mathematics and philosophy, are involved in researching properties of quantum- based com- putation [1]. During the last decade, a series of signiﬁcant breakthr oughs had been made. One was that\n",
      " > 006 [-0.04446  0.0301  -0.02708  0.032    0.05667] ranging from physics, computer sciences and information theory t o mathematics and philosophy, are involved in researching properties of quantum- based com- putation [1]. During the last decade, a series of signiﬁcant breakthr oughs had been made. One was that in 1994 Peter Shor surprised the world by p roposing a polynomial-time quantum algorithm for integer factorization [2], while in the classical world the best-known classical factoring algorithm works in superpoly- nomial time. Three years later, in 1997,\n",
      " > 007 [-0.05396  0.06616 -0.0473   0.03476  0.03375] that in 1994 Peter Shor surprised the world by p roposing a polynomial-time quantum algorithm for integer factorization [2], while in the classical world the best-known classical factoring algorithm works in superpoly- nomial time. Three years later, in 1997, Lov Grover proved that a q uantum computer could search an unsorted database in the square root o f the time [3]. Meanwhile, Gilles Brassard et al. combined ideas from Grover’s and Sho r’s quantum algorithms to propose a quantum counting algorithm [4]. 1In\n",
      " > 008 [-0.0977   0.034   -0.06152  0.0449   0.03763] 1997, Lov Grover proved that a q uantum computer could search an unsorted database in the square root o f the time [3]. Meanwhile, Gilles Brassard et al. combined ideas from Grover’s and Sho r’s quantum algorithms to propose a quantum counting algorithm [4]. 1In recent years, many interests focus on the quantum game theo ry and con- siderable work has been done. For instance, D. A. Meyer [5] studied the Penny Flip game in the quantum world ﬁrstly. His result showed that if a player was allowed to implement quantum\n",
      " > 009 [-0.09625   0.006714 -0.04965   0.0641    0.0426  ] 1In recent years, many interests focus on the quantum game theo ry and con- siderable work has been done. For instance, D. A. Meyer [5] studied the Penny Flip game in the quantum world ﬁrstly. His result showed that if a player was allowed to implement quantum strategies, he would always defeat his o pponent who played the classical strategies and increase his expected payo ﬀ as well. J. Eisert et al. [6] quantized the Prisoners’ Dilemma and demonstrated that the dilemma could be escaped when both players resort\n",
      " > 010 [-0.06134  0.02374 -0.02753  0.0994   0.05283] quantum strategies, he would always defeat his o pponent who played the classical strategies and increase his expected payo ﬀ as well. J. Eisert et al. [6] quantized the Prisoners’ Dilemma and demonstrated that the dilemma could be escaped when both players resort to quantum stra tegies. A. P. Flitney et al. [7] generalized Eisert’s result, the miracle move, i.e., th e result of the game would move towards the quantum player’s preferred re sult, while the other player used classical strategies. L. Marinatto et al.\n",
      " > 011 [-0.0904   0.042   -0.04474  0.0754   0.0624 ] resort to quantum stra tegies. A. P. Flitney et al. [7] generalized Eisert’s result, the miracle move, i.e., th e result of the game would move towards the quantum player’s preferred re sult, while the other player used classical strategies. L. Marinatto et al. [8] in vestigated the Battle of the Sexes game in quantum domain. Their result showed tha t there existed a unique equilibrium in the game, when the entangled strategie s were allowed. C. F. Lee et al. [9] reported that the quantum game is more eﬃcient than\n",
      " > 012 [-0.10614  0.02765 -0.0437   0.067    0.0633 ] al. [8] in vestigated the Battle of the Sexes game in quantum domain. Their result showed tha t there existed a unique equilibrium in the game, when the entangled strategie s were allowed. C. F. Lee et al. [9] reported that the quantum game is more eﬃcient than the classical game, and they found an upper bound for this eﬃ ciency. Be- sides, some experiments about the quantum games have also been im plemented on diﬀerent quantum computers [10, 11, 12]. For more details about quantum games, see [13]. Successes achieved\n",
      " > 013 [-0.06635   0.006283 -0.02904   0.04193   0.0797  ] than the classical game, and they found an upper bound for this eﬃ ciency. Be- sides, some experiments about the quantum games have also been im plemented on diﬀerent quantum computers [10, 11, 12]. For more details about quantum games, see [13]. Successes achieved by quantum algorithms make us guess that pow erful quantum computers can ﬁgure out solutions faster and better th an the best known classical counterparts for certain types of problems. Fur thermore, it is more important that they oﬀer a new way to\n",
      " > 014 [-0.0278    0.03568   0.006874  0.03278   0.0699  ] achieved by quantum algorithms make us guess that pow erful quantum computers can ﬁgure out solutions faster and better th an the best known classical counterparts for certain types of problems. Fur thermore, it is more important that they oﬀer a new way to ﬁnd potentially dramatic algorith- mic speed-ups. Therefore, we may ask naturally: can we construc t quantum versions of classical algorithms or present new quantum algorithms to solve the problems in pattern recognition faster and better on a quantu m computer?\n",
      " > 015 [-0.02129   0.04825  -0.007797  0.04565   0.034   ] ﬁnd potentially dramatic algorith- mic speed-ups. Therefore, we may ask naturally: can we construc t quantum versions of classical algorithms or present new quantum algorithms to solve the problems in pattern recognition faster and better on a quantu m computer? Following this idea, some researchers have proposed their novel me thods and demonstrated exciting results [14, 15, 16, 17, 18]. In addition, data clustering is a main branch of Pattern Recognition, which is widely used in many ﬁelds such as pattern\n",
      " > 016 [-0.04086  0.02998 -0.04315  0.04605  0.01796] computer? Following this idea, some researchers have proposed their novel me thods and demonstrated exciting results [14, 15, 16, 17, 18]. In addition, data clustering is a main branch of Pattern Recognition, which is widely used in many ﬁelds such as pattern analysis, data mining, infor ma- tion retrieval and image segmentation. In these ﬁelds, however, t here is usually little priori knowledge available about the data. In response to thes e restric- tions, clustering methodology come into being which is particularly\n",
      " > 017 [-0.0699    0.0423   -0.0644    0.07245   0.002632] analysis, data mining, infor ma- tion retrieval and image segmentation. In these ﬁelds, however, t here is usually little priori knowledge available about the data. In response to thes e restric- tions, clustering methodology come into being which is particularly suit able for the exploration of interrelationships among data points. Data clust ering is the formal study of algorithms and methods for grouping or classifying unlabeled data points [19]. In other words, its task is to ﬁnd the inherent stru cture\n",
      " > 018 [-0.07947  0.05658 -0.06198  0.08813  0.03217] particularly suit able for the exploration of interrelationships among data points. Data clust ering is the formal study of algorithms and methods for grouping or classifying unlabeled data points [19]. In other words, its task is to ﬁnd the inherent stru cture of a given collection of unlabeled data points and group them into meaningf ul clus- ters [19]. In this paper, we attempt to combine the quantum game wit h the problem of data clustering in order to establish a novel clustering alg orithm based on quantum\n",
      " > 019 [-0.1046   0.03123 -0.06195  0.0899   0.04318] of a given collection of unlabeled data points and group them into meaningf ul clus- ters [19]. In this paper, we attempt to combine the quantum game wit h the problem of data clustering in order to establish a novel clustering alg orithm based on quantum games. In our algorithms, unlabeled data points in a dataset are regarded as players who can make decisions in quantum games. O n a time- varying network formed by players, each player is permitted to use quantum strategies and plays a 2 × 2 entangled quantum\n",
      " > 020 [-0.11304  0.01385 -0.02885  0.0925   0.04453] games. In our algorithms, unlabeled data points in a dataset are regarded as players who can make decisions in quantum games. O n a time- varying network formed by players, each player is permitted to use quantum strategies and plays a 2 × 2 entangled quantum game against every one of his neighbors respectively. Later, he applies a link-removing-and-rew iring (LRR) function to remove the links of neighbors with small payoﬀs and crea te new links to neighbors with higher payoﬀs at the same time. Furthermore,\n",
      " > 021 [-0.0982   0.02423 -0.06805  0.10596  0.0633 ] quantum game against every one of his neighbors respectively. Later, he applies a link-removing-and-rew iring (LRR) function to remove the links of neighbors with small payoﬀs and crea te new links to neighbors with higher payoﬀs at the same time. Furthermore, th e strength of links between a player and his neighbors is diﬀerent from one anoth er, which is updated by the Grover iteration. During quantum games, the str ucture of network and the strength of links between players tend toward st ability grad- ually.\n",
      " > 022 [-0.07623  0.0338  -0.09875  0.0946   0.0581 ] th e strength of links between a player and his neighbors is diﬀerent from one anoth er, which is updated by the Grover iteration. During quantum games, the str ucture of network and the strength of links between players tend toward st ability grad- ually. Finally, if each player only connects to the neighbor with the high est strength, the network will naturally divide into several separate p arts, each of which corresponds to a cluster. 2The remainder of this paper is organized as follows: Section 2 introdu\n",
      " > 023 [-0.07556  0.0186  -0.0948   0.108    0.04092] ually. Finally, if each player only connects to the neighbor with the high est strength, the network will naturally divide into several separate p arts, each of which corresponds to a cluster. 2The remainder of this paper is organized as follows: Section 2 introdu ces some important concepts about the quantum computation and the quantum Prisoners’ Dilemma brieﬂy. In Section 3, the algorithms are establish ed in two cases of strategies, payoﬀ matrices and link-removing-and-rewir ing (LRR) func- tions, and then they\n",
      " > 024 [-0.0693   0.02022 -0.08124  0.0972   0.0286 ] introdu ces some important concepts about the quantum computation and the quantum Prisoners’ Dilemma brieﬂy. In Section 3, the algorithms are establish ed in two cases of strategies, payoﬀ matrices and link-removing-and-rewir ing (LRR) func- tions, and then they are elaborated and analyzed. In Section 4, th e relationship between the number of nearest neighbors and the number of clust ers is dis- cussed. Next, the eﬀect of the cost in the SD-like payoﬀ matrix is an alyzed, and the relationship between the total payoﬀs\n",
      " > 025 [-5.673e-02 -1.538e-05 -7.538e-02  4.810e-02  2.670e-02] they are elaborated and analyzed. In Section 4, th e relationship between the number of nearest neighbors and the number of clust ers is dis- cussed. Next, the eﬀect of the cost in the SD-like payoﬀ matrix is an alyzed, and the relationship between the total payoﬀs and the rates of co nvergence of algorithms is explained. In Section 5, those datasets used in the simu lations are introduced brieﬂy, and then results of algorithms are demonst rated. The conclusion is given in Section 6. 2 Quantum computation and quantum\n",
      " > 026 [-0.0781   0.04556 -0.05093  0.02605  0.04276] payoﬀs and the rates of co nvergence of algorithms is explained. In Section 5, those datasets used in the simu lations are introduced brieﬂy, and then results of algorithms are demonst rated. The conclusion is given in Section 6. 2 Quantum computation and quantum game 2.1 Quantum computation The elementary unit of quantum computation is called the qubit, which is typically a microscopic system, such as an atom, a nuclear spin, or a p olarized photon. In quantum computation, the Boolean states 0 and 1 are r epresented\n",
      " > 027 [-0.0992   0.04587 -0.0658   0.0443   0.0203 ] quantum game 2.1 Quantum computation The elementary unit of quantum computation is called the qubit, which is typically a microscopic system, such as an atom, a nuclear spin, or a p olarized photon. In quantum computation, the Boolean states 0 and 1 are r epresented by a prescribed pair of normalized and mutually orthogonal quantum st ates labeled as {|0⟩, |1⟩} to form a ’computational basis’ [20]. Any pure state of the qubit can be written as a superposition state α|0⟩+ β|1⟩ for some α and β satisfying |α|2 +\n",
      " > 028 [-0.12463  0.0456  -0.01177  0.08246 -0.02592] epresented by a prescribed pair of normalized and mutually orthogonal quantum st ates labeled as {|0⟩, |1⟩} to form a ’computational basis’ [20]. Any pure state of the qubit can be written as a superposition state α|0⟩+ β|1⟩ for some α and β satisfying |α|2 + |β|2 = 1 [20]. A collection of n qubits is called a quantum register of size n, which spans a Hilbert space of 2 n dimensions, so 2 n mutually orthogonal quantum states can be available. Quantum state preparations, and any other manipulations on qubit s,\n",
      " > 029 [-0.1111   0.0526  -0.0079   0.0722   0.01941] + |β|2 = 1 [20]. A collection of n qubits is called a quantum register of size n, which spans a Hilbert space of 2 n dimensions, so 2 n mutually orthogonal quantum states can be available. Quantum state preparations, and any other manipulations on qubit s, have to be performed by unitary operations. A quantum logic gate is a dev ice which performs a ﬁxed unitary operation on selected qubits in a ﬁxed perio d of time, and a quantum circuit is a device consisting of quantum logic gates who se com- putational steps\n",
      " > 030 [-0.0922   0.06946 -0.00447  0.0755   0.04257] have to be performed by unitary operations. A quantum logic gate is a dev ice which performs a ﬁxed unitary operation on selected qubits in a ﬁxed perio d of time, and a quantum circuit is a device consisting of quantum logic gates who se com- putational steps are synchronized in time [20]. The most common qua ntum gate is the Hadamard gate, which acts on a qubit in state |0⟩ or |1⟩ to produce    |0⟩ H − → 1 √ 2 |0⟩+ 1√ 2 |1⟩ |1⟩ H − → 1√ 2 |0⟩ − 1√ 2 |1⟩ ,H = 1√ 2 ( 1 1 1−1 ) . (1) For more details, see\n",
      " > 031 [-0.0974   0.03537 -0.03485  0.07806  0.02786] steps are synchronized in time [20]. The most common qua ntum gate is the Hadamard gate, which acts on a qubit in state |0⟩ or |1⟩ to produce    |0⟩ H − → 1 √ 2 |0⟩+ 1√ 2 |1⟩ |1⟩ H − → 1√ 2 |0⟩ − 1√ 2 |1⟩ ,H = 1√ 2 ( 1 1 1−1 ) . (1) For more details, see [20, 21]. 2.2 Quantum Prisoners’ Dilemma The Prisoners’ Dilemma (PD), a well-known example in the classical gam e theory, is an abstract of many phenomena in the real world and it ha s been wildly used in plenty of scientiﬁc ﬁelds. In this game, each of two\n",
      " > 032 [-0.0789   -0.004715 -0.03308   0.05624   0.03995 ] [20, 21]. 2.2 Quantum Prisoners’ Dilemma The Prisoners’ Dilemma (PD), a well-known example in the classical gam e theory, is an abstract of many phenomena in the real world and it ha s been wildly used in plenty of scientiﬁc ﬁelds. In this game, each of two player s has two optional strategies, cooperation (C) and defection (D). Lat er, he chooses one strategy against the other’s for maximizing his own payoﬀ, so do es the other side at the same time, but both sides do not know the opponent’s str ategy. As a\n",
      " > 033 [-0.0496  -0.02121 -0.04395  0.04028  0.0794 ] two player s has two optional strategies, cooperation (C) and defection (D). Lat er, he chooses one strategy against the other’s for maximizing his own payoﬀ, so do es the other side at the same time, but both sides do not know the opponent’s str ategy. As a result, each player receives a payoﬀ which depends on his selected strategy, where the payoﬀ matrix under diﬀerent strategy proﬁles is describ ed in Table 1. According to the classical game theory, the strategy proﬁle (def ection, defection) 3Table 1: Payoﬀ\n",
      " > 034 [-0.05438  -0.005234 -0.03732   0.0503    0.03543 ] result, each player receives a payoﬀ which depends on his selected strategy, where the payoﬀ matrix under diﬀerent strategy proﬁles is describ ed in Table 1. According to the classical game theory, the strategy proﬁle (def ection, defection) 3Table 1: Payoﬀ matrix for the Prisoners’ Dilemma. C = 0 D= 1 C = 0 R= 3 S = 0 D= 1 T = 5 P = 1 is the unique Nash Equilibrium [22, 23], but unfortunately it is not Paret o optimal [24]. In the quantum game, however, thanks to the quantum strategie s, the dilemma in the\n",
      " > 035 [-0.03967  0.01581 -0.03683  0.0698   0.01472] Payoﬀ matrix for the Prisoners’ Dilemma. C = 0 D= 1 C = 0 R= 3 S = 0 D= 1 T = 5 P = 1 is the unique Nash Equilibrium [22, 23], but unfortunately it is not Paret o optimal [24]. In the quantum game, however, thanks to the quantum strategie s, the dilemma in the classical game can be escaped in a restricted strategic space [6]. The physical model of quantum Prisoners’ Dilemma presented by Eis ert [6] is shown in Figure 1. Figure 1: The block diagram of the system. If the possible outcomes of the classical strategies,\n",
      " > 036 [-0.08923  0.02211 -0.04517  0.0916   0.02855] classical game can be escaped in a restricted strategic space [6]. The physical model of quantum Prisoners’ Dilemma presented by Eis ert [6] is shown in Figure 1. Figure 1: The block diagram of the system. If the possible outcomes of the classical strategies, C = 0 and D = 1, are assigned to two basis vectors {|C = 0 ⟩, |D = 1 ⟩} in Hilbert space respectively, then at any time the state of the game may be represented by a vec tor in the space spanned by the basis {|00⟩, |01⟩, |10⟩, |11⟩} [6]. Assume the initial\n",
      " > 037 [-0.0947   0.01869 -0.0541   0.04166  0.0488 ] strategies, C = 0 and D = 1, are assigned to two basis vectors {|C = 0 ⟩, |D = 1 ⟩} in Hilbert space respectively, then at any time the state of the game may be represented by a vec tor in the space spanned by the basis {|00⟩, |01⟩, |10⟩, |11⟩} [6]. Assume the initial state of the game is |ψ0⟩ = ˆJ |00⟩, where ˆJ is an entangling operator which is known to both players. For a two-player game with two pure strategies, the general form of ˆJ may be written as [25, 26] ˆJ(γ) = exp(iγ 2 σ⊗ 2 x ) = I⊗ 2cosγ 2 + iσ⊗ 2 x sinγ\n",
      " > 038 [-0.0912   0.041   -0.06635  0.03635  0.04794] initial state of the game is |ψ0⟩ = ˆJ |00⟩, where ˆJ is an entangling operator which is known to both players. For a two-player game with two pure strategies, the general form of ˆJ may be written as [25, 26] ˆJ(γ) = exp(iγ 2 σ⊗ 2 x ) = I⊗ 2cosγ 2 + iσ⊗ 2 x sinγ 2 (2) where γ ∈ [0,π/ 2] is a measure of entanglement of a game. When γ = π/ 2, there is a maximally entangled game, in which the entangling operator t akes form ˆJ(γ) = 1√ 2 (I⊗ 2 + iσ⊗ 2 x ). (3) Next, each player chooses a unitary operator ˆY1( ˆY2)\n",
      " > 039 [-0.08276  0.04187 -0.0626   0.04755  0.05222] sinγ 2 (2) where γ ∈ [0,π/ 2] is a measure of entanglement of a game. When γ = π/ 2, there is a maximally entangled game, in which the entangling operator t akes form ˆJ(γ) = 1√ 2 (I⊗ 2 + iσ⊗ 2 x ). (3) Next, each player chooses a unitary operator ˆY1( ˆY2) from the strategy space S1(S2) and operates it on the qubit that belongs to him, which makes the ga me in a state ( ˆY1 ⊗ ˆY2) ˆJ|00⟩. Speciﬁcally, the unitary operators ˆC and ˆD that correspond to the strategies, cooperation and defection, are g iven below\n",
      " > 040 [-0.0704   0.01341 -0.0843   0.04492  0.04385] ˆY2) from the strategy space S1(S2) and operates it on the qubit that belongs to him, which makes the ga me in a state ( ˆY1 ⊗ ˆY2) ˆJ|00⟩. Speciﬁcally, the unitary operators ˆC and ˆD that correspond to the strategies, cooperation and defection, are g iven below [6] ˆC = (1 0 0 1 ) , ˆD= ( 0 1 −1 0 ) . (4) In the end, before a projective measurement in the basis {|0⟩, |1⟩} is carried out, the ﬁnal state is |ψf ⟩ = ˆJ†( ˆY1 ⊗ ˆY2) ˆJ |00⟩. (5) Thus, the player’s expected payoﬀ is written as z= R|⟨ψf |00⟩|2 + S|⟨ψf\n",
      " > 041 [-0.08344  0.01414 -0.0872   0.05176  0.04547] below [6] ˆC = (1 0 0 1 ) , ˆD= ( 0 1 −1 0 ) . (4) In the end, before a projective measurement in the basis {|0⟩, |1⟩} is carried out, the ﬁnal state is |ψf ⟩ = ˆJ†( ˆY1 ⊗ ˆY2) ˆJ |00⟩. (5) Thus, the player’s expected payoﬀ is written as z= R|⟨ψf |00⟩|2 + S|⟨ψf |01⟩|2 + T|⟨ψf |10⟩|2 + P|⟨ψf |11⟩|2. (6) For more details, see [6, 27]. 43 Algorithm In the section, we will combine the model of the quantum game with th e problem of data clustering, and then establish clustering algorithms based on quantum games. Assume\n",
      " > 042 [-0.0746    0.004993 -0.06274   0.0835    0.0342  ] S|⟨ψf |01⟩|2 + T|⟨ψf |10⟩|2 + P|⟨ψf |11⟩|2. (6) For more details, see [6, 27]. 43 Algorithm In the section, we will combine the model of the quantum game with th e problem of data clustering, and then establish clustering algorithms based on quantum games. Assume an unlabeled dataset X = {X 1, X 2, · · · , X N },which are distributed in a m-dimensional metric space. Each data point in the dataset is considered as a player in quantum games who can make decisions and always hope to maximize his payoﬀ. In the metric\n",
      " > 043 [-0.0994    0.003895 -0.04562   0.09436   0.04092 ] Assume an unlabeled dataset X = {X 1, X 2, · · · , X N },which are distributed in a m-dimensional metric space. Each data point in the dataset is considered as a player in quantum games who can make decisions and always hope to maximize his payoﬀ. In the metric space, there is a distance f unction d : X × X − → R, satisfying the closer the two players are, the smaller the output is. Based on the distance function, a k nearest neighbors (knn) network as a weighted and directed network, G0(X ,E 0,d ), may be created\n",
      " > 044 [-0.0711   0.01927 -0.0544   0.041    0.04016] metric space, there is a distance f unction d : X × X − → R, satisfying the closer the two players are, the smaller the output is. Based on the distance function, a k nearest neighbors (knn) network as a weighted and directed network, G0(X ,E 0,d ), may be created among data points by adding k edges directed toward its k nearest neighbors for each player. Deﬁnition 1 If there is a set X with N players, X = {X1, X2, · · · , XN }, the weighted and directed knn network, G0(X,E 0,d ), is created as below.     \n",
      " > 045 [-0.05045  0.02597 -0.06555  0.05075  0.04288] created among data points by adding k edges directed toward its k nearest neighbors for each player. Deﬁnition 1 If there is a set X with N players, X = {X1, X2, · · · , XN }, the weighted and directed knn network, G0(X,E 0,d ), is created as below.                  X = { Xi,i = 1 , 2, · · · ,N } E0 = ⋃ N i=1 E0(i) E0(i) = { e0 ( Xi, Xj ) | j ∈ Γ 0(i) } Γ 0(i) = { j ⏐ ⏐ ⏐j = argmink Xh∈ X ({ d(Xi, Xh), Xh ∈ X } )} (7) Here, each player in the set X corresponds to a vertex in the network G0(X,E\n",
      " > 046 [-0.079    0.00581 -0.0728   0.05417  0.0759 ]             X = { Xi,i = 1 , 2, · · · ,N } E0 = ⋃ N i=1 E0(i) E0(i) = { e0 ( Xi, Xj ) | j ∈ Γ 0(i) } Γ 0(i) = { j ⏐ ⏐ ⏐j = argmink Xh∈ X ({ d(Xi, Xh), Xh ∈ X } )} (7) Here, each player in the set X corresponds to a vertex in the network G0(X,E 0,d ); E0 is a link set and a link in the network represents certain rela tionship between a pair of players; the distances denote the weights over link s; the function, argmink(·), is to ﬁnd k nearest neighbors of a player which construct a ne igh- bor set,\n",
      " > 047 [-0.0537   0.01424 -0.0752   0.04462  0.08057] 0,d ); E0 is a link set and a link in the network represents certain rela tionship between a pair of players; the distances denote the weights over link s; the function, argmink(·), is to ﬁnd k nearest neighbors of a player which construct a ne igh- bor set, Γ 0(i); the subscript ’0’ is the initial time step. It is worth noting that the strength of links between a player X i and his k nearest neighbors represented by ρt− 1(X i, X j ),j ∈ Γ t− 1(i)(t ≥ 1) is time- varying, whose initial values is calculated by\n",
      " > 048 [-0.09717  0.03293 -0.06036  0.04288  0.04102] set, Γ 0(i); the subscript ’0’ is the initial time step. It is worth noting that the strength of links between a player X i and his k nearest neighbors represented by ρt− 1(X i, X j ),j ∈ Γ t− 1(i)(t ≥ 1) is time- varying, whose initial values is calculated by ρ0(X i, X j) = { 1/ |Γ 0(i)| = 1 /k, j ∈ Γ 0(i) 0, otherwise (8) where the symbol | · | denotes the cardinality of a set. After the initial connections are constructed among players (dat a points), on this weighted and directed knn network, a quantum game\n",
      " > 049 [-0.11584  0.04477 -0.0396   0.0453   0.02483] by ρ0(X i, X j) = { 1/ |Γ 0(i)| = 1 /k, j ∈ Γ 0(i) 0, otherwise (8) where the symbol | · | denotes the cardinality of a set. After the initial connections are constructed among players (dat a points), on this weighted and directed knn network, a quantum game can be d eﬁned as following. Deﬁnition 2A quantum game Ω = {X,G t,S,Z t} on a network Gt is a 4- tuple: X is a set of players; Gt represents the connections among players; S = {s(i),i = 1 , 2, · · · ,N } represents a set of players’ strategies including the\n",
      " > 050 [-0.10815  0.02757 -0.0647   0.02852  0.0407 ] game can be d eﬁned as following. Deﬁnition 2A quantum game Ω = {X,G t,S,Z t} on a network Gt is a 4- tuple: X is a set of players; Gt represents the connections among players; S = {s(i),i = 1 , 2, · · · ,N } represents a set of players’ strategies including the full range of quantum strategies; Zt = {zt(i),i = 1 , 2, · · · ,N } represents a set of players’ expected payoﬀs. Here, the variable tdenotes the time step (the number of iterations). In each round, players choose theirs strate gies simultaneously, and\n",
      " > 051 [-0.079    0.00835 -0.08936  0.03099  0.0328 ] the full range of quantum strategies; Zt = {zt(i),i = 1 , 2, · · · ,N } represents a set of players’ expected payoﬀs. Here, the variable tdenotes the time step (the number of iterations). In each round, players choose theirs strate gies simultaneously, and each player can only observe its neighbors’ payoﬀs, but d oes not know the strategy proﬁles of all other players in X. 53.1 Cases of quantum strategies and payoﬀ matrices At ﬁrst, each player selects a strategy from his strategy set, an d then plays a 2 ×\n",
      " > 052 [-0.0972    0.004467 -0.05698   0.09045   0.04068 ] each player can only observe its neighbors’ payoﬀs, but d oes not know the strategy proﬁles of all other players in X. 53.1 Cases of quantum strategies and payoﬀ matrices At ﬁrst, each player selects a strategy from his strategy set, an d then plays a 2 × 2 entangled quantum game against one of his k neighbors respectively. In the classical 2 × 2 game, such as the Prisoners’ Dilemma, usually there are only two pure strategies, cooperation and defection, but in the quant um game, one can design diﬀerent unitary\n",
      " > 053 [-0.1088   0.01582 -0.0508   0.0813   0.05148] 2 entangled quantum game against one of his k neighbors respectively. In the classical 2 × 2 game, such as the Prisoners’ Dilemma, usually there are only two pure strategies, cooperation and defection, but in the quant um game, one can design diﬀerent unitary operators as strategies, i.e., the stra tegy set S may be identiﬁed with some subset of the group of 2 × 2 unitary matrices [6]. Here, for the purpose of clustering and simplifying computation, the stra tegy set of a player X i is restricted in a set S1\n",
      " > 054 [-0.0908   0.01949 -0.0224   0.05246  0.04364] unitary operators as strategies, i.e., the stra tegy set S may be identiﬁed with some subset of the group of 2 × 2 unitary matrices [6]. Here, for the purpose of clustering and simplifying computation, the stra tegy set of a player X i is restricted in a set S1 = { ˆH, ˆD} or S2 = { ˆFt− 1(i,j ), ˆD}, and then two cases of strategy sets are described respectively. Case 1: In this case, a player and his opponent can apply strategies inS1 = { ˆH, ˆD}. When a player X i use the Hadamard matrix ˆH as a strategy, his\n",
      " > 055 [-0.027    0.02235 -0.0353   0.08014  0.04126] S1 = { ˆH, ˆD} or S2 = { ˆFt− 1(i,j ), ˆD}, and then two cases of strategy sets are described respectively. Case 1: In this case, a player and his opponent can apply strategies inS1 = { ˆH, ˆD}. When a player X i use the Hadamard matrix ˆH as a strategy, his opponent (neighbor) X j has two optional strategies { ˆH, ˆD}, but which strategy is chosen is dependent on the strength of the link between them, as is a rule of the clustering algorithm. If the strength ρt− 1(X j , X i) equals to zero, i.e., there is no\n",
      " > 056 [-0.02599  0.04413 -0.0931   0.0933   0.03568] opponent (neighbor) X j has two optional strategies { ˆH, ˆD}, but which strategy is chosen is dependent on the strength of the link between them, as is a rule of the clustering algorithm. If the strength ρt− 1(X j , X i) equals to zero, i.e., there is no link directed from the player X j to the player X i, then the player X j will apply the strategy ’Defection’ ( ˆD). Alternatively, if ρt− 1(X j , X i) >0, namely mutual connections between them, the player X j implements the strategy ˆH. If the initial state\n",
      " > 057 [-0.0814   0.02086 -0.07263  0.0553   0.04208] link directed from the player X j to the player X i, then the player X j will apply the strategy ’Defection’ ( ˆD). Alternatively, if ρt− 1(X j , X i) >0, namely mutual connections between them, the player X j implements the strategy ˆH. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, by applying the model of the quantum game the ﬁnal state of the game is |ψf,j ⟩ = { 1 2 (|00⟩ − i|01⟩ − i|10⟩+ |11⟩), ˆH⊗ ˆH 1√ 2 (i|00⟩ − |01⟩), ˆH⊗ ˆD (9) Case 2: The strategy setS2 = { ˆFt− 1(i,j ), ˆD} is adopted in the\n",
      " > 058 [-0.0952  -0.00537 -0.0388   0.05545  0.02718] state of the game is |ψ0⟩ = ˆJ|00⟩, by applying the model of the quantum game the ﬁnal state of the game is |ψf,j ⟩ = { 1 2 (|00⟩ − i|01⟩ − i|10⟩+ |11⟩), ˆH⊗ ˆH 1√ 2 (i|00⟩ − |01⟩), ˆH⊗ ˆD (9) Case 2: The strategy setS2 = { ˆFt− 1(i,j ), ˆD} is adopted in the case. The strategy ˆFt− 1(i,j ), ˆFt− 1(i,j ) = ( √ ρt− 1(X i, X j ) √ 1 − ρt− 1(X i, X j )√ 1 − ρt− 1(X i, X j ) − √ ρt− 1(X i, X j ) ) , is a general form of Hadamard matrix ˆH whose elements are associated with the strength of links ρt− 1(X i, X j ). When\n",
      " > 059 [-0.03128   0.01836  -0.03119   0.0786    0.000689] case. The strategy ˆFt− 1(i,j ), ˆFt− 1(i,j ) = ( √ ρt− 1(X i, X j ) √ 1 − ρt− 1(X i, X j )√ 1 − ρt− 1(X i, X j ) − √ ρt− 1(X i, X j ) ) , is a general form of Hadamard matrix ˆH whose elements are associated with the strength of links ρt− 1(X i, X j ). When ρt− 1(X i, X j )=0.5, the strategy ˆFt− 1(i,j ) recovers the strategy ˆH. Similarly, the neighbor X j , when ρt− 1(X j , X i) = 0, applies the strategy ’Defection’ ( ˆD), while using the strategy ˆFt− 1(i,j ) when ρt− 1(X j , X i) > 0. If the initial state\n",
      " > 060 [-0.0518   0.02011 -0.10803  0.0776   0.0298 ] When ρt− 1(X i, X j )=0.5, the strategy ˆFt− 1(i,j ) recovers the strategy ˆH. Similarly, the neighbor X j , when ρt− 1(X j , X i) = 0, applies the strategy ’Defection’ ( ˆD), while using the strategy ˆFt− 1(i,j ) when ρt− 1(X j , X i) > 0. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, after their moves, the ﬁnal state of the game is |ψf,j ⟩ =      √ ρ1ρ2|00⟩ − i √ ρ2(1 − ρ1)|01⟩ −i √ ρ1(1 − ρ2)|10⟩+ √ (1 − ρ1)(1 − ρ2)|11⟩, ˆFt− 1 ⊗ ˆFt− 1 i√1 − ρ1|00⟩ − √ρ1|01⟩, ˆFt− 1 ⊗ ˆD . (10) According to the payoﬀ\n",
      " > 061 [-0.06915  0.02486 -0.0908   0.01976  0.02396] state of the game is |ψ0⟩ = ˆJ|00⟩, after their moves, the ﬁnal state of the game is |ψf,j ⟩ =      √ ρ1ρ2|00⟩ − i √ ρ2(1 − ρ1)|01⟩ −i √ ρ1(1 − ρ2)|10⟩+ √ (1 − ρ1)(1 − ρ2)|11⟩, ˆFt− 1 ⊗ ˆFt− 1 i√1 − ρ1|00⟩ − √ρ1|01⟩, ˆFt− 1 ⊗ ˆD . (10) According to the payoﬀ matrix, the player’s expected payoﬀ can be computed by zt− 1(i) = ∑ j∈ Γ t− 1 (i) zt− 1(X i, X j ) = ∑ j∈ Γ t− 1 (i) R|⟨ψf,j |00⟩|2 + S|⟨ψf,j |01⟩|2 + T|⟨ψf,j |10⟩|2 + P|⟨ψf,j |11⟩|2. (11) 6In practice, the payoﬀ matrix takes PD-like or Snowdrift (SD)-like\n",
      " > 062 [-0.00948   0.03247  -0.02747  -0.003271  0.0445  ] payoﬀ matrix, the player’s expected payoﬀ can be computed by zt− 1(i) = ∑ j∈ Γ t− 1 (i) zt− 1(X i, X j ) = ∑ j∈ Γ t− 1 (i) R|⟨ψf,j |00⟩|2 + S|⟨ψf,j |01⟩|2 + T|⟨ψf,j |10⟩|2 + P|⟨ψf,j |11⟩|2. (11) 6In practice, the payoﬀ matrix takes PD-like or Snowdrift (SD)-like f orm, de- scribed in Table 2 and 3. In the PD-like payoﬀ matrix, the following inequ ali- Table 2: PD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= 0 .6ωt− 1(X i, X j ) S = 0 .01ωt− 1(X i, X j ) D= 1 T = ωt− 1(X i, X j ) P = 0 .2ωt− 1(X i, X j ) Table 3: SD-like\n",
      " > 063 [-0.02065  0.02623 -0.03854  0.02327  0.0439 ] (SD)-like f orm, de- scribed in Table 2 and 3. In the PD-like payoﬀ matrix, the following inequ ali- Table 2: PD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= 0 .6ωt− 1(X i, X j ) S = 0 .01ωt− 1(X i, X j ) D= 1 T = ωt− 1(X i, X j ) P = 0 .2ωt− 1(X i, X j ) Table 3: SD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= ωt− 1(X i, X j ) − c 2 S = ωt− 1(X i, X j ) − c D= 1 T = ωt− 1(X i, X j ) P = 0 .01ωt− 1(X i, X j ) ties holds: T >R>P >S and 2 R>T + S [28]. To avoid a case that a player’s expected payoﬀ is zero, the variable S in\n",
      " > 064 [-0.04675   0.007175 -0.03958   0.0452    0.05527 ] SD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= ωt− 1(X i, X j ) − c 2 S = ωt− 1(X i, X j ) − c D= 1 T = ωt− 1(X i, X j ) P = 0 .01ωt− 1(X i, X j ) ties holds: T >R>P >S and 2 R>T + S [28]. To avoid a case that a player’s expected payoﬀ is zero, the variable S in Table 2 takes a small value instead of zero in Table 1. In addition, the Snowdrift game assumes that two drivers are blocked by a snowdrift, each of whom is in either side of the snowd rift. If they want to go back home, one of them or both must shovel a path\n",
      " > 065 [-0.0597   -0.001031 -0.03754   0.07806   0.03705 ] Table 2 takes a small value instead of zero in Table 1. In addition, the Snowdrift game assumes that two drivers are blocked by a snowdrift, each of whom is in either side of the snowd rift. If they want to go back home, one of them or both must shovel a path through the snowdrift. So, there exists a cost c in the SD-like payoﬀ matrix and the following inequality holds: T > R > S > P[28], where c = β · ωt− 1(X i, X j ) and β is a proportional factor. Besides, the variable ωt− 1(X i, X j ) in two payoﬀ matrices\n",
      " > 066 [-0.04     0.00621 -0.03183  0.05353  0.04953] path through the snowdrift. So, there exists a cost c in the SD-like payoﬀ matrix and the following inequality holds: T > R > S > P[28], where c = β · ωt− 1(X i, X j ) and β is a proportional factor. Besides, the variable ωt− 1(X i, X j ) in two payoﬀ matrices is calculated by the formulation below. ωt− 1(X i, X j ) = ρt− 1(X i, X j ) × Degt− 1(X j )/d (X i, X j ) (12) 3.2 Design of LRR functions When all players’ payoﬀs have been computed, each player will obse rve his neighbors’ payoﬀs, and apply a link-removing-and-rewiring\n",
      " > 067 [-0.071     0.007786 -0.03152   0.04172   0.03998 ] matrices is calculated by the formulation below. ωt− 1(X i, X j ) = ρt− 1(X i, X j ) × Degt− 1(X j )/d (X i, X j ) (12) 3.2 Design of LRR functions When all players’ payoﬀs have been computed, each player will obse rve his neighbors’ payoﬀs, and apply a link-removing-and-rewiring (LRR) f unction Li(·) to change his links. A LRR function is deﬁned as below. Deﬁnition 3The LRR function Li(·) is a function of payoﬀs, whose output is a set with k elements, namely an updated neighbor set Γ t(i) of a player Xi. It is given\n",
      " > 068 [-0.09937  0.041   -0.01212  0.0532   0.04785] link-removing-and-rewiring (LRR) f unction Li(·) to change his links. A LRR function is deﬁned as below. Deﬁnition 3The LRR function Li(·) is a function of payoﬀs, whose output is a set with k elements, namely an updated neighbor set Γ t(i) of a player Xi. It is given as below. Γ t(i) = Li ( ˆzt− 1(i) ) = argmaxk j∈ Γ t− 1 (i) S Υ t− 1(i) ({ zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) }) ˆzt− 1(i) = { zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) } , Υ t− 1(i) = ⋃ j∈ Γ + t− 1 (i) Γ t− 1(j) Γ + t− 1(i) = { j|zt− 1(j) ≥ θt− 1(i),j ∈ Γ t−\n",
      " > 069 [-0.0871   0.01697 -0.0904   0.0961   0.0925 ] given as below. Γ t(i) = Li ( ˆzt− 1(i) ) = argmaxk j∈ Γ t− 1 (i) S Υ t− 1(i) ({ zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) }) ˆzt− 1(i) = { zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) } , Υ t− 1(i) = ⋃ j∈ Γ + t− 1 (i) Γ t− 1(j) Γ + t− 1(i) = { j|zt− 1(j) ≥ θt− 1(i),j ∈ Γ t− 1(i) } , Γ − t− 1(i) = Γ t− 1(i)\\Γ + t− 1(i) (13) where θt− 1(i) is a payoﬀ threshold, Υ t− 1(i) is called an extended neighbor set, and the function argmaxk(·) is to ﬁnd k neighbors with the ﬁrst k largest payoﬀs in the set Γ t− 1(i) ⋃ Υ t− 1(i). Here, two\n",
      " > 070 [-0.089    0.02225 -0.07556  0.06042  0.0483 ] t− 1(i) } , Γ − t− 1(i) = Γ t− 1(i)\\Γ + t− 1(i) (13) where θt− 1(i) is a payoﬀ threshold, Υ t− 1(i) is called an extended neighbor set, and the function argmaxk(·) is to ﬁnd k neighbors with the ﬁrst k largest payoﬀs in the set Γ t− 1(i) ⋃ Υ t− 1(i). Here, two LRR functions L1 i(·) and L2 i(·) are designed. The function L1 i(·) always observes an extended neighbor set formed by half neighbor s of a data 7point X i, α = ⌈ 0.5 × | Γ t− 1(i)| ⌉ , where the symbol ⌈·⌉ is to take an integer part of a number satisfying\n",
      " > 071 [-0.08203  0.01814 -0.05814  0.04688  0.05414] two LRR functions L1 i(·) and L2 i(·) are designed. The function L1 i(·) always observes an extended neighbor set formed by half neighbor s of a data 7point X i, α = ⌈ 0.5 × | Γ t− 1(i)| ⌉ , where the symbol ⌈·⌉ is to take an integer part of a number satisfying the integer part is no larger than the nu mber. Next, the payoﬀ threshold θ1 t− 1(i) is set by θ1 t− 1(i) = findα ({zt− 1(i),j ∈ Γ t− 1(i)}), where the function findα (·) is to ﬁnd the α-th largest payoﬀ in a set that contains all neighbors’ payoﬀs of the\n",
      " > 072 [-0.05643  0.0351  -0.0762   0.0479   0.07086] satisfying the integer part is no larger than the nu mber. Next, the payoﬀ threshold θ1 t− 1(i) is set by θ1 t− 1(i) = findα ({zt− 1(i),j ∈ Γ t− 1(i)}), where the function findα (·) is to ﬁnd the α-th largest payoﬀ in a set that contains all neighbors’ payoﬀs of the data point. When the LRR fun ction L1 i(·) is applied, the links connecting to the neighbors with small payoﬀs are removed and meanwhile new links are created between the data point and foun d players with higher payoﬀs. Hence, according to Eq.(13), the\n",
      " > 073 [-0.06256  0.02556 -0.0751   0.06177  0.05283] the data point. When the LRR fun ction L1 i(·) is applied, the links connecting to the neighbors with small payoﬀs are removed and meanwhile new links are created between the data point and foun d players with higher payoﬀs. Hence, according to Eq.(13), the new neighbor set is Γ t(i) = L1 i(ˆzt− 1(i)). Unlike the LRR function L1 i(·), the LRR function L2 i(·) adjusts the number of neighbors dynamically instead of the constant number of neighbo rs in L1 i(·). Therefore, the payoﬀ threshold θ2 t− 1(i) takes the\n",
      " > 074 [-0.06226  0.03378 -0.11035  0.0859   0.04947] the new neighbor set is Γ t(i) = L1 i(ˆzt− 1(i)). Unlike the LRR function L1 i(·), the LRR function L2 i(·) adjusts the number of neighbors dynamically instead of the constant number of neighbo rs in L1 i(·). Therefore, the payoﬀ threshold θ2 t− 1(i) takes the average of neighbors’ payoﬀs, θ2 t− 1(i) = ∑ j∈ Γ t− 1(i) zt− 1(i)/ |Γ t− 1(i)|. Next, the set Γ + t− 1(i) is formed according to Eq.(13), Γ + t− 1(i) = {j|zt− 1(j) ≥ θ2 t− 1(i),j ∈ Γ t− 1(i)}, and then the new neigh- bor set is achieved by means of the LRR\n",
      " > 075 [-0.07404  0.0387  -0.0985   0.10126  0.05316] the average of neighbors’ payoﬀs, θ2 t− 1(i) = ∑ j∈ Γ t− 1(i) zt− 1(i)/ |Γ t− 1(i)|. Next, the set Γ + t− 1(i) is formed according to Eq.(13), Γ + t− 1(i) = {j|zt− 1(j) ≥ θ2 t− 1(i),j ∈ Γ t− 1(i)}, and then the new neigh- bor set is achieved by means of the LRR function L2 i(·), Γ t(i) = L2 i(ˆzt− 1(i)). In the case, when the payoﬀs of all neighbors are equal to the pay oﬀ thresh- old θ2 t− 1(i), the output of the LRR function is Γ t(i) = Γ t− 1(i). This may be viewed as self-protective behavior for avoiding a\n",
      " > 076 [-0.0626    0.008255 -0.05988   0.06116   0.0546  ] LRR function L2 i(·), Γ t(i) = L2 i(ˆzt− 1(i)). In the case, when the payoﬀs of all neighbors are equal to the pay oﬀ thresh- old θ2 t− 1(i), the output of the LRR function is Γ t(i) = Γ t− 1(i). This may be viewed as self-protective behavior for avoiding a payoﬀ loss due to n o enough information acquired. The LRR function Li(·) expands the view of a player X i, i.e., it makes him observe payoﬀs of players in the extended neighbor set, which pro vides a chance to ﬁnd players with higher payoﬀs around him. If\n",
      " > 077 [-0.06094  0.01452 -0.0773   0.0811   0.05212] a payoﬀ loss due to n o enough information acquired. The LRR function Li(·) expands the view of a player X i, i.e., it makes him observe payoﬀs of players in the extended neighbor set, which pro vides a chance to ﬁnd players with higher payoﬀs around him. If no players with highe r payoﬀs are found in the extended neighbor set, namely min({zt− 1(j),j ∈ Γ t− 1(i)}) ≥ max({zt− 1(h),h ∈ Υ t− 1(i)}), then the output of the LRR function is Γ t(i) = Γ t− 1(i). Otherwise, players with small payoﬀs will be removed together\n",
      " > 078 [-0.06793  0.0423  -0.0912   0.1128   0.06052] If no players with highe r payoﬀs are found in the extended neighbor set, namely min({zt− 1(j),j ∈ Γ t− 1(i)}) ≥ max({zt− 1(h),h ∈ Υ t− 1(i)}), then the output of the LRR function is Γ t(i) = Γ t− 1(i). Otherwise, players with small payoﬀs will be removed together wit h the corresponding links from the neighbor set and link set, and replaced by some found players with higher payoﬀ. This process is repeated till the pa yoﬀs of unlinked players in the extended neighbor set are no larger than tho se of linked neighbors.\n",
      " > 079 [-0.06274  0.0216  -0.091    0.0912   0.04605] together wit h the corresponding links from the neighbor set and link set, and replaced by some found players with higher payoﬀ. This process is repeated till the pa yoﬀs of unlinked players in the extended neighbor set are no larger than tho se of linked neighbors. Since the links among players, namely the link set E0 in the network G0(X ,E 0,d ), are changed by the LRR function, the network Gt(X ,E t,d ) has begun to evolve over time, when t≥ 1. Gt(X ,E t,d ) =                X (t) = { X i(t),i\n",
      " > 080 [-0.04193  0.02637 -0.064    0.05978  0.0412 ] neighbors. Since the links among players, namely the link set E0 in the network G0(X ,E 0,d ), are changed by the LRR function, the network Gt(X ,E t,d ) has begun to evolve over time, when t≥ 1. Gt(X ,E t,d ) =                X (t) = { X i(t),i = 1 , 2, · · · ,N } Γ t(i) = Li(ˆzt− 1(i)) Et = ⋃ N i=1 Et(i) Et(i) = { et ( X i, X j ) | j ∈ Γ t(i) } (14) 3.3 Strength of links updating After the LRR function is applied, the strength of links of players ne eds to be formed and adjusted. The new strength\n",
      " > 081 [-0.03119  0.02608 -0.0427   0.02081  0.03842] i(t),i = 1 , 2, · · · ,N } Γ t(i) = Li(ˆzt− 1(i)) Et = ⋃ N i=1 Et(i) Et(i) = { et ( X i, X j ) | j ∈ Γ t(i) } (14) 3.3 Strength of links updating After the LRR function is applied, the strength of links of players ne eds to be formed and adjusted. The new strength of links of a player X i ∈ X is formed by means of the below formulation. ρt(X i, X j ) =      P h∈ Γ t− 1 (i)\\{ Γ t− 1(i) T Γ t(i)} ρt− 1 (X i, X h) ⏐ ⏐ ⏐Γ t(i)\\ { Γ t− 1(i) T Γ t(i) }⏐ ⏐ ⏐ j ∈ Γ t(i)\\ { Γ t− 1(i) ⋂ Γ t(i) } ρt− 1(X i, X j ) otherwise\n",
      " > 082 [ 0.000941 -0.001508 -0.06714   0.05582   0.03894 ] strength of links of a player X i ∈ X is formed by means of the below formulation. ρt(X i, X j ) =      P h∈ Γ t− 1 (i)\\{ Γ t− 1(i) T Γ t(i)} ρt− 1 (X i, X h) ⏐ ⏐ ⏐Γ t(i)\\ { Γ t− 1(i) T Γ t(i) }⏐ ⏐ ⏐ j ∈ Γ t(i)\\ { Γ t− 1(i) ⋂ Γ t(i) } ρt− 1(X i, X j ) otherwise (15) 8Then, the player adjusts the strength of links as follows. First, he ﬁnds a neighbor X m with maximal payoﬀ in his neighbor set, m= argmax j∈ Γ t(i) ({ zt− 1(j),j ∈ Γ t(i) }) (16) Next, the strength of link ρt(X i, X j ),j ∈ Γ t(i) is taken its\n",
      " > 083 [-0.04736  0.01538 -0.06076  0.0758   0.0643 ] otherwise (15) 8Then, the player adjusts the strength of links as follows. First, he ﬁnds a neighbor X m with maximal payoﬀ in his neighbor set, m= argmax j∈ Γ t(i) ({ zt− 1(j),j ∈ Γ t(i) }) (16) Next, the strength of link ρt(X i, X j ),j ∈ Γ t(i) is taken its square root and the player X m’s strength of the link becomes negative, { {√ ρt(X i, X j ),j ∈ Γ t(i) } √ ρt(X i, X m) = − √ ρt(X i, X m),m ∈ Γ t(i) (17) Further, let Avet(i) = ( ∑ j∈ Γ t(i) √ ρt(X i, X m))/ |Γ t(i)|, thus, the updated strength of link is\n",
      " > 084 [-0.05603  0.02715 -0.0481   0.05725  0.04984] square root and the player X m’s strength of the link becomes negative, { {√ ρt(X i, X j ),j ∈ Γ t(i) } √ ρt(X i, X m) = − √ ρt(X i, X m),m ∈ Γ t(i) (17) Further, let Avet(i) = ( ∑ j∈ Γ t(i) √ ρt(X i, X m))/ |Γ t(i)|, thus, the updated strength of link is ρt(X i, X j ) = ( 2 × Avet(i) − √ ρt(X i, X j ) ) 2 ,j ∈ Γ t(i). (18) The above-mentioned method is a variant of the Grover iteration G in the quantum search algorithm [3], a well-known algorithm in quantum compu tation, which is a way to adjust the probability\n",
      " > 085 [-0.0687   0.0338  -0.0805   0.06323  0.02924] ρt(X i, X j ) = ( 2 × Avet(i) − √ ρt(X i, X j ) ) 2 ,j ∈ Γ t(i). (18) The above-mentioned method is a variant of the Grover iteration G in the quantum search algorithm [3], a well-known algorithm in quantum compu tation, which is a way to adjust the probability amplitude of each term in a supe rposi- tion state. By adjustment, the probability amplitude of the wanted is increased, while the others are reduced. This whole process may be regarded a s the in- version about average operation [3]. For our case, each\n",
      " > 086 [-0.04773  0.0232  -0.1013   0.07245  0.03061] probability amplitude of each term in a supe rposi- tion state. By adjustment, the probability amplitude of the wanted is increased, while the others are reduced. This whole process may be regarded a s the in- version about average operation [3]. For our case, each strength of link is taken its square root ﬁrst, and then the average Avet(i) of square roots is computed. Finally, all values are inverted about the average. There are three main reasons that we select the modiﬁed Grover iteration to update the strengt h\n",
      " > 087 [-0.05786  0.04672 -0.08673  0.08325  0.03754] each strength of link is taken its square root ﬁrst, and then the average Avet(i) of square roots is computed. Finally, all values are inverted about the average. There are three main reasons that we select the modiﬁed Grover iteration to update the strengt h of links: (a) the sum of updated strength of links retains one, ∑ j∈ Γ t(i) ρt(X i, X j ) = 1, (b) certain strength of links between a player and his neighbors is much la rger than the others, ρt(X i, X j ) ≫ ρt(X i, X h),h ∈ Γ t(i)\\j, after the strength\n",
      " > 088 [-0.05737  0.02515 -0.0851   0.0868   0.05768] h of links: (a) the sum of updated strength of links retains one, ∑ j∈ Γ t(i) ρt(X i, X j ) = 1, (b) certain strength of links between a player and his neighbors is much la rger than the others, ρt(X i, X j ) ≫ ρt(X i, X h),h ∈ Γ t(i)\\j, after the strength of links is updated, and (c) it helps players’ payoﬀs to follow a power law distr ibution, in which only a few players’ payoﬀs are far larger than others’ in the end of iterations. Besides, the process that all players adjust their strength is ord er irrelevant,\n",
      " > 089 [-0.063     0.003275 -0.1078    0.06616   0.06143 ] of links is updated, and (c) it helps players’ payoﬀs to follow a power law distr ibution, in which only a few players’ payoﬀs are far larger than others’ in the end of iterations. Besides, the process that all players adjust their strength is ord er irrelevant, because the strength of links of all players is updated synchronou sly, and the network is a directed network, so the strength cannot be overrid den by other players. When the strength of links of each player has been update d, an iteration is completed.\n",
      " > 090 [-0.03073   0.03275  -0.1003    0.0548    0.003857] irrelevant, because the strength of links of all players is updated synchronou sly, and the network is a directed network, so the strength cannot be overrid den by other players. When the strength of links of each player has been update d, an iteration is completed. In conclusion, when t≥ 1 , the structure of network representing connections among players begins to evolve over time. 4 Discussions In the section, ﬁrstly, the relationship between the number of nea rest neigh- bors and the number of clusters is discussed,\n",
      " > 091 [-0.03738  0.03198 -0.08417  0.02812  0.01688] completed. In conclusion, when t≥ 1 , the structure of network representing connections among players begins to evolve over time. 4 Discussions In the section, ﬁrstly, the relationship between the number of nea rest neigh- bors and the number of clusters is discussed, and then how the cos t in the SD-like payoﬀ matrix inﬂuences the results is analyzed, which provide s a way to choose the proportional factor. Finally, the total payoﬀs based on two diﬀerent payoﬀ matrices are compared and the relationship between the\n",
      " > 092 [-0.04785  0.01926 -0.0896   0.00332  0.04752] discussed, and then how the cos t in the SD-like payoﬀ matrix inﬂuences the results is analyzed, which provide s a way to choose the proportional factor. Finally, the total payoﬀs based on two diﬀerent payoﬀ matrices are compared and the relationship between the tot al payoﬀs and the rates of convergence of algorithms is explained. 94.1 Number of nearest neighbors vs. number of clusters The number k of nearest neighbors represents the number of neighbors to which a data point (player) X i ∈ X connects. For a dataset,\n",
      " > 093 [-0.07544  0.04657 -0.0979   0.01758  0.0414 ] the tot al payoﬀs and the rates of convergence of algorithms is explained. 94.1 Number of nearest neighbors vs. number of clusters The number k of nearest neighbors represents the number of neighbors to which a data point (player) X i ∈ X connects. For a dataset, the number k of nearest neighbors determines the number of clusters in part. G enerally speaking, the number of clusters decreases inversely with the num ber k of nearest neighbors. For example, when the number k of nearest neighbors is small, it is\n",
      " > 094 [-0.0701   0.04218 -0.0752   0.0775   0.04797] dataset, the number k of nearest neighbors determines the number of clusters in part. G enerally speaking, the number of clusters decreases inversely with the num ber k of nearest neighbors. For example, when the number k of nearest neighbors is small, it is indicated that the player X i connects to only a few neighbors. At this time only those not-too-distance neighbors can be observed by the LRR fu nction, which means that the elements in the union of the extended neighbor set Υ t− 1(i) and the neighbor set Γ\n",
      " > 095 [-0.06323  0.03387 -0.0991   0.0897   0.04083] indicated that the player X i connects to only a few neighbors. At this time only those not-too-distance neighbors can be observed by the LRR fu nction, which means that the elements in the union of the extended neighbor set Υ t− 1(i) and the neighbor set Γ t− 1(i) are few. Therefore, when the evolution of the network formed by players is ended, many small clusters are established amo ng data points. On the other hand, a big number k of nearest neighbors provides more neighbors for each player, as speciﬁes that\n",
      " > 096 [-0.06085  0.04205 -0.07477  0.06305  0.02042] Γ t− 1(i) are few. Therefore, when the evolution of the network formed by players is ended, many small clusters are established amo ng data points. On the other hand, a big number k of nearest neighbors provides more neighbors for each player, as speciﬁes that the cardinality of the u nion is larger than that when a small k is taken. This means that more neighbors can be observed and explored by the LRR function, so that big clusters co ntaining more data points are formed. For a dataset, the clustering results\n",
      " > 097 [-0.0652   0.04364 -0.03888  0.0738   0.01361] that the cardinality of the u nion is larger than that when a small k is taken. This means that more neighbors can be observed and explored by the LRR function, so that big clusters co ntaining more data points are formed. For a dataset, the clustering results at the diﬀerent number k of nearest neighbors have been illustrated in Fig. 2, in which each data point only c onnects to one of its neighbors who has the largest strength of link, and clus ters are represented by diﬀerent signs. As is shown in Fig. 2,\n",
      " > 098 [-0.08813  0.04266 -0.06067  0.07684  0.00458] results at the diﬀerent number k of nearest neighbors have been illustrated in Fig. 2, in which each data point only c onnects to one of its neighbors who has the largest strength of link, and clus ters are represented by diﬀerent signs. As is shown in Fig. 2, it can be found t hat only a few data points receive considerable links, whereas most of da ta points have only one link. This implies that when the structure of network te nds to stability, the network, if only the links with the largest strength are remained,\n",
      " > 099 [-0.06223  0.02422 -0.0433   0.06396  0.02983] it can be found t hat only a few data points receive considerable links, whereas most of da ta points have only one link. This implies that when the structure of network te nds to stability, the network, if only the links with the largest strength are remained, is characterized by the scale-free network [29], i.e., winner takes all. Besides, in Fig. 2(a), six clusters are obtained by the clustering algorithm, whe n k= 9. As the number k of nearest neighbors rises, four clusters are obtained when k= 12, three\n",
      " > 100 [-0.0653   0.035   -0.04404  0.0699   0.02982] remained, is characterized by the scale-free network [29], i.e., winner takes all. Besides, in Fig. 2(a), six clusters are obtained by the clustering algorithm, whe n k= 9. As the number k of nearest neighbors rises, four clusters are obtained when k= 12, three clusters when k= 16. So, if the exact number of clusters is not known in advance, diﬀerent numbers of clusters may be achieved by adjust ing the number of nearest neighbors in practice. −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (a) k = 9 −5 −4 −3\n",
      " > 101 [-0.05777  0.05127 -0.0385   0.05936  0.05737] three clusters when k= 16. So, if the exact number of clusters is not known in advance, diﬀerent numbers of clusters may be achieved by adjust ing the number of nearest neighbors in practice. −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (a) k = 9 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (b) k = 12 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (c) k = 16 Figure 2: The number of nearest neighbors vs. number of clusters . (a) six clusters are obtained, when the number of nearest neighbors is\n",
      " > 102 [-0.04034  0.03992 -0.05322  0.05945  0.04932] −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (b) k = 12 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (c) k = 16 Figure 2: The number of nearest neighbors vs. number of clusters . (a) six clusters are obtained, when the number of nearest neighbors is k = 9. (b) four clusters, when k= 12. (c) three clusters, when k= 16 4.2 Eﬀect of the cost c in the SD-like payoﬀ matrix In the Snowdrift game, if the cost is too high, the SD-like payoﬀ matr ix recovers the PD-like payoﬀ matrix [28]. Therefore, the proportio\n",
      " > 103 [-0.02777  0.04303 -0.02812  0.04803  0.05768] k = 9. (b) four clusters, when k= 12. (c) three clusters, when k= 16 4.2 Eﬀect of the cost c in the SD-like payoﬀ matrix In the Snowdrift game, if the cost is too high, the SD-like payoﬀ matr ix recovers the PD-like payoﬀ matrix [28]. Therefore, the proportio nal factor β is restricted in an interval (0 , 0.5]. However, diﬀerent costs will bring about 10the changes of the payoﬀ matrix, which means that diﬀerent cluste ring results will be produced even in the same algorithm. Figure 3 illustrates how th e clustering\n",
      " > 104 [-0.00295  0.0482  -0.03098  0.03613  0.036  ] proportio nal factor β is restricted in an interval (0 , 0.5]. However, diﬀerent costs will bring about 10the changes of the payoﬀ matrix, which means that diﬀerent cluste ring results will be produced even in the same algorithm. Figure 3 illustrates how th e clustering results change at the diﬀerent number k of nearest neighbors when the proportional factor β takes diﬀerent values, in which the clustering results are represented by clustering accuracies. The deﬁnition of cluste ring accuracy is given below. Deﬁnition\n",
      " > 105 [-0.01508  0.04614 -0.03055  0.03046  0.0283 ] clustering results change at the diﬀerent number k of nearest neighbors when the proportional factor β takes diﬀerent values, in which the clustering results are represented by clustering accuracies. The deﬁnition of cluste ring accuracy is given below. Deﬁnition 4clusteri is the label which is assigned to a data point Xi in a dataset by the algorithm, and labeli is the actual label of the data point Xi in the dataset. So the clustering accuracy is [30]: accuracy = PN i=1 λ ( map(clusteri ),label i ) N λ(map(clusteri),label\n",
      " > 106 [-0.02316  0.04163 -0.03284  0.01723  0.03125] Deﬁnition 4clusteri is the label which is assigned to a data point Xi in a dataset by the algorithm, and labeli is the actual label of the data point Xi in the dataset. So the clustering accuracy is [30]: accuracy = PN i=1 λ ( map(clusteri ),label i ) N λ(map(clusteri),label i) = { 1 if map(clusteri) = labeli 0 otherwise (19) where the mapping function map(·) maps the label got by the algorithm to the actual label. Clustering accuracy is an important evaluation criterion for clustering algo- rithms, which reﬂects\n",
      " > 107 [-0.02678  0.03394 -0.03574  0.03928  0.04913] λ(map(clusteri),label i) = { 1 if map(clusteri) = labeli 0 otherwise (19) where the mapping function map(·) maps the label got by the algorithm to the actual label. Clustering accuracy is an important evaluation criterion for clustering algo- rithms, which reﬂects the level of matches between the actual lab els in a dataset and the labels assigned by a clustering algorithm, so that the goal of a clustering algorithm is to obtain higher clustering accuracies. As is shown in Figure 3, it can be seen that similar results\n",
      " > 108 [-0.0435   0.02309 -0.0555   0.05807  0.0591 ] reﬂects the level of matches between the actual lab els in a dataset and the labels assigned by a clustering algorithm, so that the goal of a clustering algorithm is to obtain higher clustering accuracies. As is shown in Figure 3, it can be seen that similar results are obtained b y the algorithm at diﬀerent costs, and the best results are produce d when k = 7 and k= 8, but from the Figure 3(b), the clustering result with the largest mean and the least variance is yielded when β = 0 .3. Also, as mentioned above, the\n",
      " > 109 [-0.01504  0.03024 -0.0627   0.04913  0.044  ] results are obtained b y the algorithm at diﬀerent costs, and the best results are produce d when k = 7 and k= 8, but from the Figure 3(b), the clustering result with the largest mean and the least variance is yielded when β = 0 .3. Also, as mentioned above, the high cost leads to the recovery of the SD-like payoﬀ matrix, so the p roportional factor β = 0 .2 or β = 0 .3 is recommended. 4 5 6 7 8 9 10 11 12 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy beta=0.1 beta=0.2\n",
      " > 110 [ 0.00312  0.02176 -0.03375  0.05133  0.05804] the high cost leads to the recovery of the SD-like payoﬀ matrix, so the p roportional factor β = 0 .2 or β = 0 .3 is recommended. 4 5 6 7 8 9 10 11 12 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy beta=0.1 beta=0.2 beta=0.3 beta=0.4 beta=0.5 (a) 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.8 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 1 proportional factor beta mean and variance of results (b) Figure 3: The eﬀect of the cost for the clustering results.\n",
      " > 111 [-0.01686  0.01319 -0.06116  0.0313   0.03017] beta=0.2 beta=0.3 beta=0.4 beta=0.5 (a) 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.8 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 1 proportional factor beta mean and variance of results (b) Figure 3: The eﬀect of the cost for the clustering results. (a) the results of the algorithm using the SD-like payoﬀ matrix at diﬀerent number k of nearest neighbors. (b) the mean and variance corresponding to each curv e in (a). 4.3 Total payoﬀs and the rate of convergence In this subsection, at ﬁrst, the total payoﬀs\n",
      " > 112 [-0.0401    0.004528 -0.05      0.02934   0.03403 ] results. (a) the results of the algorithm using the SD-like payoﬀ matrix at diﬀerent number k of nearest neighbors. (b) the mean and variance corresponding to each curv e in (a). 4.3 Total payoﬀs and the rate of convergence In this subsection, at ﬁrst, the total payoﬀs of algorithms using t he PD- or SD-like payoﬀ matrix are compared respectively, and then the diﬀer ences be- tween total payoﬀs are explained. Later, the rates of converge nce of algorithms 11are discussed when two LRR functions are applied respectively,\n",
      " > 113 [-0.02652   0.004707 -0.03766   0.005745  0.0582  ] payoﬀs of algorithms using t he PD- or SD-like payoﬀ matrix are compared respectively, and then the diﬀer ences be- tween total payoﬀs are explained. Later, the rates of converge nce of algorithms 11are discussed when two LRR functions are applied respectively, and further the impact for the rates of convergence is analyzed in two payoﬀ matric es. If all other conditions are ﬁxed, an algorithm will form two versions d ue to using PD- or SD-like payoﬀ matrix, and naturally this will bring diﬀerent results. As compared\n",
      " > 114 [-0.05136  0.02109 -0.0655   0.01605  0.03406] respectively, and further the impact for the rates of convergence is analyzed in two payoﬀ matric es. If all other conditions are ﬁxed, an algorithm will form two versions d ue to using PD- or SD-like payoﬀ matrix, and naturally this will bring diﬀerent results. As compared with the PD-like payoﬀ matrix, the payoﬀ P and S in the SD-like payoﬀ matrix have a reverse order in the payoﬀ inequality. In all algo rithms, the relationship between the total payoﬀs and the number of iteration s is drawn in Figure 4. From Figure\n",
      " > 115 [-0.03317  0.03595 -0.05148  0.03217  0.02864] compared with the PD-like payoﬀ matrix, the payoﬀ P and S in the SD-like payoﬀ matrix have a reverse order in the payoﬀ inequality. In all algo rithms, the relationship between the total payoﬀs and the number of iteration s is drawn in Figure 4. From Figure 4, it can be found that the total payoﬀs in the algorithms with SD-like payoﬀ matrix are larger than that of the algorithms with P D-like payoﬀ matrix no matter which LRR function is selected. 1 2 3 4 5 6 7 8 9 0 1000 2000 3000 4000 5000 6000 7000 number\n",
      " > 116 [-0.02902  0.01878 -0.03326  0.02948  0.04904] Figure 4, it can be found that the total payoﬀs in the algorithms with SD-like payoﬀ matrix are larger than that of the algorithms with P D-like payoﬀ matrix no matter which LRR function is selected. 1 2 3 4 5 6 7 8 9 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1(a) 1 2 3 4 5 6 7 8 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Figure 4: The total payoﬀs vs. the rates of convergence. (a) to\n",
      " > 117 [-0.006832  0.03616  -0.03494   0.017     0.04623 ] of iterations total payoffs QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1(a) 1 2 3 4 5 6 7 8 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Figure 4: The total payoﬀs vs. the rates of convergence. (a) to tal payoﬀs of algorithms in the case of LRR function L1 i(·), (b) total payoﬀs of algorithms in the case of LRR function L2 i(·) Remark 1 The algorithms are named as follows. For example, the name of an algorithm, QGC1PDL1, denotes that the Case 1, PD-like\n",
      " > 118 [-0.01762  0.01909 -0.02736  0.00759  0.05295] to tal payoﬀs of algorithms in the case of LRR function L1 i(·), (b) total payoﬀs of algorithms in the case of LRR function L2 i(·) Remark 1 The algorithms are named as follows. For example, the name of an algorithm, QGC1PDL1, denotes that the Case 1, PD-like payoﬀ matrix and the LRR function L1 i(·) are employed in this algorithm. According to two payoﬀ matrices, using Eq.(11), each player’s expe cted pay- oﬀ can be calculated in two cases of strategies respectively as below . Case 1: PD : zt(X i, X j ) = { 1\n",
      " > 119 [-0.02078   0.00834  -0.039     0.002394  0.04565 ] PD-like payoﬀ matrix and the LRR function L1 i(·) are employed in this algorithm. According to two payoﬀ matrices, using Eq.(11), each player’s expe cted pay- oﬀ can be calculated in two cases of strategies respectively as below . Case 1: PD : zt(X i, X j ) = { 1 4 (0.6ω + 0.01ω + ω + 0.2ω) = 0 .4525ω 1 2 (0.6ω + 0.01ω) = 0 .305ω (20) SD : zt(X i, X j ) = { 1 4 (ω − c 2 + ω − c+ ω + 0.01ω) = 1 4 (3.01 − 3α 2 )ω 1 2 (ω − c 2 + ω − c) = 1 2 (2 − 3α 2 )ω (21) Case 2: PD : zt(X i, X j ) =      ρ1ρ20.6ω + ρ2(1 − ρ1)0.01ω\n",
      " > 120 [-0.01527  0.0422  -0.04288  0.01768  0.04053] 1 4 (0.6ω + 0.01ω + ω + 0.2ω) = 0 .4525ω 1 2 (0.6ω + 0.01ω) = 0 .305ω (20) SD : zt(X i, X j ) = { 1 4 (ω − c 2 + ω − c+ ω + 0.01ω) = 1 4 (3.01 − 3α 2 )ω 1 2 (ω − c 2 + ω − c) = 1 2 (2 − 3α 2 )ω (21) Case 2: PD : zt(X i, X j ) =      ρ1ρ20.6ω + ρ2(1 − ρ1)0.01ω +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.2ω (1 − ρ1)0.6ω + ρ10.01ω (22) SD : zt(X i, X j ) =      ρ1ρ2(ω − c 2 ) + ρ2(1 − ρ1)(ω − c) +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.01ω (1 − ρ1)(ω − c 2 ) + ρ1(ω − c) (23) 12Comparing the expected payoﬀs in two cases,\n",
      " > 121 [-0.01216  0.01244 -0.02878  0.00859  0.03738] ρ1)0.01ω +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.2ω (1 − ρ1)0.6ω + ρ10.01ω (22) SD : zt(X i, X j ) =      ρ1ρ2(ω − c 2 ) + ρ2(1 − ρ1)(ω − c) +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.01ω (1 − ρ1)(ω − c 2 ) + ρ1(ω − c) (23) 12Comparing the expected payoﬀs in two cases, it can be observed th at when the SD-like payoﬀ matrix is used, the expected payoﬀ is larger than t hat of using PD-like payoﬀ matrix regardless of cases of strategies. Therefor e, this explains why diﬀerences between total payoﬀs are produced. Besides, Figure\n",
      " > 122 [-0.03375   0.00895  -0.07935   0.007122  0.05325 ] cases, it can be observed th at when the SD-like payoﬀ matrix is used, the expected payoﬀ is larger than t hat of using PD-like payoﬀ matrix regardless of cases of strategies. Therefor e, this explains why diﬀerences between total payoﬀs are produced. Besides, Figure 4 not only describes the changes of total payoﬀs o f algo- rithms, but also reﬂects the rates of convergence of algorithms. When the total payoﬀs remain constant or ﬂuctuate slightly, this means that the a lgorithms have converged. At this time, players\n",
      " > 123 [-0.07697  0.025   -0.0909   0.0379   0.0618 ] Figure 4 not only describes the changes of total payoﬀs o f algo- rithms, but also reﬂects the rates of convergence of algorithms. When the total payoﬀs remain constant or ﬂuctuate slightly, this means that the a lgorithms have converged. At this time, players do not frequently apply the L RR function to change his neighbors but reach a stable state. As mentioned in th e section 3.2, the LRR function L2 i(·) only can observe an extended neighbor set formed by those larger-than-average neighbors in contrast to\n",
      " > 124 [-0.0931   0.0328  -0.08215  0.0828   0.0643 ] players do not frequently apply the L RR function to change his neighbors but reach a stable state. As mentioned in th e section 3.2, the LRR function L2 i(·) only can observe an extended neighbor set formed by those larger-than-average neighbors in contrast to an exten ded neighbor set built by half neighbors in the LRR function L1 i(·). Generally speaking, for the same k, the median of payoﬀs is smaller than or equal to the mean, i.e., θ1 t− 1 ≤ θ2 t− 1, which means that the exploring area of the LRR function L1\n",
      " > 125 [-0.06238  0.0551  -0.0594   0.07117  0.0755 ] an exten ded neighbor set built by half neighbors in the LRR function L1 i(·). Generally speaking, for the same k, the median of payoﬀs is smaller than or equal to the mean, i.e., θ1 t− 1 ≤ θ2 t− 1, which means that the exploring area of the LRR function L1 i(·) is larger than that of the LRR function L2 i(·). So, as a whole, the algorithms with the LRR function L2 i(·) are slightly faster than that with the LRR function L1 i(·), i.e., the number of iterations that the former type of algorithms n eeds is a\n",
      " > 126 [-0.0333    0.009224 -0.05273   0.04257   0.0675  ] L1 i(·) is larger than that of the LRR function L2 i(·). So, as a whole, the algorithms with the LRR function L2 i(·) are slightly faster than that with the LRR function L1 i(·), i.e., the number of iterations that the former type of algorithms n eeds is a little less. Furthermore, in the algorithms, a phenomenon that the strategie s ˆH and ˆFt− 1 are more likely used by players in a high density area while the strategy ˆD is used by those in a low density area is always observed. This is becaus e usually they\n",
      " > 127 [-0.0355   0.02051 -0.0722   0.0734   0.03108] little less. Furthermore, in the algorithms, a phenomenon that the strategie s ˆH and ˆFt− 1 are more likely used by players in a high density area while the strategy ˆD is used by those in a low density area is always observed. This is becaus e usually they are mutually neighbors in the high density area on the weig hted and directed knn network, but in the low density area this case is rev erse. As a result, the diﬀerences of payoﬀs between the high density and low d ensity areas are enlarged rapidly for the\n",
      " > 128 [-0.03177  0.02664 -0.07947  0.0786   0.02074] they are mutually neighbors in the high density area on the weig hted and directed knn network, but in the low density area this case is rev erse. As a result, the diﬀerences of payoﬀs between the high density and low d ensity areas are enlarged rapidly for the expected payoﬀ in the strategy proﬁle ( ˆH, ˆH) or ( ˆFt− 1, ˆFt− 1) is higher than that in other strategy proﬁle, and this also cause th e distribution of players’ payoﬀs follows a power-law distribution, whic h is why algorithms converge fast. 5 Simulations\n",
      " > 129 [-0.02666  0.01441 -0.1087   0.0545   0.04053] the expected payoﬀ in the strategy proﬁle ( ˆH, ˆH) or ( ˆFt− 1, ˆFt− 1) is higher than that in other strategy proﬁle, and this also cause th e distribution of players’ payoﬀs follows a power-law distribution, whic h is why algorithms converge fast. 5 Simulations To evaluate these clustering algorithms, six datasets are selected from UCI repository [31], which are Soybean, Iris, Wine, Sonar, Ionosphere and Breast cancer Wisconsin datasets, and complete the simulations on them. I n this sec- tion, ﬁrstly these\n",
      " > 130 [-0.02827  0.0433  -0.06964  0.05667  0.00292] Simulations To evaluate these clustering algorithms, six datasets are selected from UCI repository [31], which are Soybean, Iris, Wine, Sonar, Ionosphere and Breast cancer Wisconsin datasets, and complete the simulations on them. I n this sec- tion, ﬁrstly these datasets are brieﬂy introduced, and then the s imulation results are demonstrated. The original data points in above datasets all are scattered in high d imen- sional spaces spanned by their features which are the individual me asurable heuristic properties\n",
      " > 131 [-0.02075  0.01056 -0.0466  -0.01109 -0.0332 ] these datasets are brieﬂy introduced, and then the s imulation results are demonstrated. The original data points in above datasets all are scattered in high d imen- sional spaces spanned by their features which are the individual me asurable heuristic properties of the phenomena being observed, where the description of all datasets is summarized in Table 4. As for Breast dataset, some lo st features are replaced by random numbers, and the Wine dataset is standard ized. Finally, the algorithms are coded in Matlab\n",
      " > 132 [-0.06128    0.0002728 -0.061      0.01385   -0.04263  ] properties of the phenomena being observed, where the description of all datasets is summarized in Table 4. As for Breast dataset, some lo st features are replaced by random numbers, and the Wine dataset is standard ized. Finally, the algorithms are coded in Matlab 6.5. Throughout all simulations, data points in a dataset are viewed as pla yers in quantum games whose initial positions are taken from the dataset . Next, the initial network representing relations among data points are creat ed according to Def.1, after\n",
      " > 133 [-0.0859  -0.01221 -0.05878  0.03415 -0.00746] Matlab 6.5. Throughout all simulations, data points in a dataset are viewed as pla yers in quantum games whose initial positions are taken from the dataset . Next, the initial network representing relations among data points are creat ed according to Def.1, after a distance function is selected, which only needs to s atisfy that the more similar data points are, the smaller the output of the funct ion is. In 13Table 4: Description of datasets. Dataset Instances Features classes Soybean 47 21 4 Iris 150 4 3 Wine 178\n",
      " > 134 [-0.02867  0.02946 -0.05038  0.01207  0.02042] after a distance function is selected, which only needs to s atisfy that the more similar data points are, the smaller the output of the funct ion is. In 13Table 4: Description of datasets. Dataset Instances Features classes Soybean 47 21 4 Iris 150 4 3 Wine 178 13 3 Sonar 208 60 2 Ionosphere 351 32 2 Breast 699 9 2 the simulations, the distance function is employed as following d ( X i, X j ) = exp ( ∥X i − X j ∥/ 2σ2 ) ,i,j = 1 , 2, · · · ,N (24) where the symbol ∥ · ∥ represents L2-norm. The advantage of this\n",
      " > 135 [-0.02373  0.0192  -0.03857  0.02666  0.0627 ] 178 13 3 Sonar 208 60 2 Ionosphere 351 32 2 Breast 699 9 2 the simulations, the distance function is employed as following d ( X i, X j ) = exp ( ∥X i − X j ∥/ 2σ2 ) ,i,j = 1 , 2, · · · ,N (24) where the symbol ∥ · ∥ represents L2-norm. The advantage of this function is that it not only satisﬁes our requirements, but also overcomes the drawbacks of Euclidean distance. For instance, when two points are very close, t he output of Euclidean distance function approaches zero, which may make the c omputation of payoﬀ\n",
      " > 136 [-0.06995  0.04166 -0.08466  0.0335   0.08905] this function is that it not only satisﬁes our requirements, but also overcomes the drawbacks of Euclidean distance. For instance, when two points are very close, t he output of Euclidean distance function approaches zero, which may make the c omputation of payoﬀ fail due to the payoﬀ approaching inﬁnite. Nevertheless, when Eq.(24) is selected as the distance function, it is more convenient to comput e the players’ payoﬀs, since its minimum is one and the reciprocals of its output are b etween zero and one, 1 /d\n",
      " > 137 [-0.04852  0.04758 -0.1034   0.04617  0.08356] payoﬀ fail due to the payoﬀ approaching inﬁnite. Nevertheless, when Eq.(24) is selected as the distance function, it is more convenient to comput e the players’ payoﬀs, since its minimum is one and the reciprocals of its output are b etween zero and one, 1 /d (X i, X j ) ∈ [0, 1]. In addition, the distance between a player X i and itself, d(X i, X i), is one according to the deﬁned distance function, which means that initially he is one of his k nearest neighbors. So there is an edge between the player X i and\n",
      " > 138 [-0.01755  0.04047 -0.04895  0.02235  0.03696] /d (X i, X j ) ∈ [0, 1]. In addition, the distance between a player X i and itself, d(X i, X i), is one according to the deﬁned distance function, which means that initially he is one of his k nearest neighbors. So there is an edge between the player X i and himself, namely a self-loop. Additionally, the parameter σ in Eq.(24) takes one. As is analyzed in the section 4.2, the cost c in SD-like payoﬀ matrix is set by c= 0 .2ωt(X i, X j ) in the related clustering algorithms. The clustering algorithms are applied\n",
      " > 139 [-0.03983  0.01451 -0.03604  0.0329   0.0513 ] and himself, namely a self-loop. Additionally, the parameter σ in Eq.(24) takes one. As is analyzed in the section 4.2, the cost c in SD-like payoﬀ matrix is set by c= 0 .2ωt(X i, X j ) in the related clustering algorithms. The clustering algorithms are applied on the six datasets respective ly. Be- cause two cases of strategies are designed and the diﬀerent payo ﬀ matrices and LRR functions are employed, the algorithms are run on every datas et at the diﬀerent number k of nearest neighbors. As is analyzed in section\n",
      " > 140 [-0.06116   0.008095 -0.0806    0.06055   0.0382  ] applied on the six datasets respective ly. Be- cause two cases of strategies are designed and the diﬀerent payo ﬀ matrices and LRR functions are employed, the algorithms are run on every datas et at the diﬀerent number k of nearest neighbors. As is analyzed in section 4.1, for a dataset the number k of clusters decreases inversely with the number of nearest neighbors. When a small k is selected, it is possible that the number of clusters is larger than the preset number of the dataset, after the algorit hm is ended.\n",
      " > 141 [-0.0564   0.0757  -0.1101   0.0933   0.01985] section 4.1, for a dataset the number k of clusters decreases inversely with the number of nearest neighbors. When a small k is selected, it is possible that the number of clusters is larger than the preset number of the dataset, after the algorit hm is ended. So a merging-subroutine is called to merge unwanted clusters, which wo rks in this way. At ﬁrst, the cluster with the fewest data points is identiﬁed, a nd then it is merged to the cluster whose distance between their centroids is sm allest. This subroutine\n",
      " > 142 [-0.02472  0.0664  -0.0997   0.09735  0.00537] ended. So a merging-subroutine is called to merge unwanted clusters, which wo rks in this way. At ﬁrst, the cluster with the fewest data points is identiﬁed, a nd then it is merged to the cluster whose distance between their centroids is sm allest. This subroutine is repeated till the number of clusters is equal to the pr eset number. The clustering results obtained by these algorithms are compared in Fig. 5, in which each point represents a clustering accuracy. As is shown in F ig. 5, the similar results are obtained\n",
      " > 143 [-0.01496  0.03705 -0.0585   0.04593  0.02129] subroutine is repeated till the number of clusters is equal to the pr eset number. The clustering results obtained by these algorithms are compared in Fig. 5, in which each point represents a clustering accuracy. As is shown in F ig. 5, the similar results are obtained by these algorithms at diﬀerent number o f nearest neighbors, but almost all the best results are obtained by the algor ithms using the LRR function L1 i(·). Further, we show a simple comparison with three other algorithms: K means [32, 33], PCA-Kmeans\n",
      " > 144 [-0.03815  0.03336 -0.04047  0.02391  0.04337] obtained by these algorithms at diﬀerent number o f nearest neighbors, but almost all the best results are obtained by the algor ithms using the LRR function L1 i(·). Further, we show a simple comparison with three other algorithms: K means [32, 33], PCA-Kmeans [33], LDA-Km [33]. The Kmeans algorithm is a popular clu s- tering algorithm because it is easy to implement. It begins with k randomly- chosen cluster centers, and then assigns each data point in a data set to the closest cluster center. Next, the cluster\n",
      " > 145 [-0.02512  0.0603  -0.03702  0.0316   0.05057] PCA-Kmeans [33], LDA-Km [33]. The Kmeans algorithm is a popular clu s- tering algorithm because it is easy to implement. It begins with k randomly- chosen cluster centers, and then assigns each data point in a data set to the closest cluster center. Next, the cluster centers are recomput ed according to the current cluster memberships. This process will be repeated till a co nvergence 142 2.5 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1\n",
      " > 146 [-0.036    0.04672 -0.0849   0.07153  0.02708] cluster centers are recomput ed according to the current cluster memberships. This process will be repeated till a co nvergence 142 2.5 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(a) Soybean dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b)\n",
      " > 147 [-0.005817  0.05536  -0.04044   0.0119    0.01639 ] QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(a) Soybean dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Iris dataset 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(c) Wine dataset 3 3.5 4 4.5 5 5.5 6 6.5 7 7.5 8 0.4\n",
      " > 148 [ 0.012955  0.07916  -0.02795   0.015175  0.0316  ] QGC2SDL2(b) Iris dataset 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(c) Wine dataset 3 3.5 4 4.5 5 5.5 6 6.5 7 7.5 8 0.4 0.42 0.44 0.46 0.48 0.5 0.52 0.54 0.56 0.58 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(d) Sonar dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 number of nearest neighbors\n",
      " > 149 [-0.01198  0.0931  -0.03162  0.02649  0.082  ] 0.4 0.42 0.44 0.46 0.48 0.5 0.52 0.54 0.56 0.58 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(d) Sonar dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(e) Ionosphere dataset 3 4 5 6 7 8 9 10 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2\n",
      " > 150 [-0.00858  0.0782  -0.0345   0.0386   0.0525 ] neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(e) Ionosphere dataset 3 4 5 6 7 8 9 10 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(f) breast dataset Figure 5: Comparison of clustering accuracies at diﬀerent k in all proposed algorithms. criterion is met. However, its major problem is sensitive to the selection of the initial partition [19]. The PCA-Kmeans algorithm consists\n",
      " > 151 [-9.876e-05  5.630e-02 -5.444e-02  2.159e-02  1.694e-02] QGC2PDL2 QGC2SDL2(f) breast dataset Figure 5: Comparison of clustering accuracies at diﬀerent k in all proposed algorithms. criterion is met. However, its major problem is sensitive to the selection of the initial partition [19]. The PCA-Kmeans algorithm consists of two steps : (1) Re- duce the data dimension by principal component analysis (PCA); (2) Clustering data points by the Kmeans algorithm. Ding et al combine linear discrimin ant analysis (LDA) with the Kmeans algorithm, and construct a new clust ering\n",
      " > 152 [ 0.00393  0.0548  -0.05466  0.02759  0.0333 ] consists of two steps : (1) Re- duce the data dimension by principal component analysis (PCA); (2) Clustering data points by the Kmeans algorithm. Ding et al combine linear discrimin ant analysis (LDA) with the Kmeans algorithm, and construct a new clust ering algorithm called ’LDA-Km’. In the LDA-Km algorithm, Kmeans is used to generate class labels, while LDA is used to do subspace selection. Finally, in the subspace selection process, data points are clustered. Our algorithms are established on the model of\n",
      " > 153 [-0.05176  0.04413 -0.03973  0.03784  0.05072] ering algorithm called ’LDA-Km’. In the LDA-Km algorithm, Kmeans is used to generate class labels, while LDA is used to do subspace selection. Finally, in the subspace selection process, data points are clustered. Our algorithms are established on the model of quantum games, so d ata points in datasets are considered as players. This idea is totally diﬀer ent from traditional clustering algorithms, such as Kmeans and its variants, because in traditional clustering algorithms data points for clustering are ﬁxe d,\n",
      " > 154 [-0.0792   0.02423 -0.06683  0.0738   0.03488] of quantum games, so d ata points in datasets are considered as players. This idea is totally diﬀer ent from traditional clustering algorithms, such as Kmeans and its variants, because in traditional clustering algorithms data points for clustering are ﬁxe d, and various functions or methods are designed to ﬁnd cluster centers or sepa rating hyper- planes, whereas in the quantum-game-based clustering algorithms data points (players) themselves choose their clusters, which leads clusters a re formed au- tomatically\n",
      " > 155 [-0.0675   0.03415 -0.0646   0.06152  0.05914] d, and various functions or methods are designed to ﬁnd cluster centers or sepa rating hyper- planes, whereas in the quantum-game-based clustering algorithms data points (players) themselves choose their clusters, which leads clusters a re formed au- tomatically during quantum games. In conclusion, traditional cluste ring algo- rithms do it from outside, while ours are from inside. Furthermore, o ur algo- rithms do not need to choose cluster centers at beginning, so ther e does not exist the problem that is ”sensitive\n",
      " > 156 [-0.05713  0.0635  -0.04544  0.0591   0.0674 ] tomatically during quantum games. In conclusion, traditional cluste ring algo- rithms do it from outside, while ours are from inside. Furthermore, o ur algo- rithms do not need to choose cluster centers at beginning, so ther e does not exist the problem that is ”sensitive to the selection of the initial partition” . Besides, distances between data points are commonly used as the measurem ent of their similarities in the Kmeans algorithm and its variants. However, when sim ilar- ities are measured in our algorithms,\n",
      " > 157 [-0.05432  0.03104 -0.037    0.05942  0.05057] ”sensitive to the selection of the initial partition” . Besides, distances between data points are commonly used as the measurem ent of their similarities in the Kmeans algorithm and its variants. However, when sim ilar- ities are measured in our algorithms, not only distances between dat a points but also their degrees and the strength of links are integrated, wh ich provides more information for the measurement of similarities. Later, accor ding to pay- oﬀs in quantum games, players apply a LRR function to\n",
      " > 158 [-0.0661   0.03494 -0.04922  0.06213  0.0491 ] algorithms, not only distances between dat a points but also their degrees and the strength of links are integrated, wh ich provides more information for the measurement of similarities. Later, accor ding to pay- oﬀs in quantum games, players apply a LRR function to change the st ructure of the network, which makes the clusters emerge. As a result, bet ter clustering accuracies are obtained by our algorithms. Table 5 displays the clustering accuracies of our algorithms and the o ther 15three algorithms using the datasets\n",
      " > 159 [-0.04382  0.05527 -0.0428   0.05582  0.0427 ] to change the st ructure of the network, which makes the clusters emerge. As a result, bet ter clustering accuracies are obtained by our algorithms. Table 5 displays the clustering accuracies of our algorithms and the o ther 15three algorithms using the datasets in Table 4. It can be observed t hat on almost all datasets the quantum game based clustering algorithms h ave the best clustering accuracies. Only on the Iris dataset, the LDA-Km a lgorithm is better than ours, but our result is close to it as well. The\n",
      " > 160 [-0.0568   0.05884 -0.02718  0.05692  0.0347 ] datasets in Table 4. It can be observed t hat on almost all datasets the quantum game based clustering algorithms h ave the best clustering accuracies. Only on the Iris dataset, the LDA-Km a lgorithm is better than ours, but our result is close to it as well. The Iris datase t contains three clusters, one of which is far from the other two, so data poin ts in it can be clustered easily and correctly. The other clusters in the Iris dataset, however, are mixed partly in their boundaries, which brings a diﬃculty for\n",
      " > 161 [-0.03568  0.08466 -0.03305  0.0691   0.01563] The Iris datase t contains three clusters, one of which is far from the other two, so data poin ts in it can be clustered easily and correctly. The other clusters in the Iris dataset, however, are mixed partly in their boundaries, which brings a diﬃculty for clustering. These mixed boundary points may be assigned to diﬀeren t clusters by algorithms, which is why the clustering accuracies of algorithms ar e various. It is more diﬃcult to cluster data points in the Sonar and Ionosphere dataset, because in these\n",
      " > 162 [-0.038    0.05905 -0.0454   0.05698  0.0801 ] for clustering. These mixed boundary points may be assigned to diﬀeren t clusters by algorithms, which is why the clustering accuracies of algorithms ar e various. It is more diﬃcult to cluster data points in the Sonar and Ionosphere dataset, because in these two datasets plenty of data points belonging to diﬀ erent clusters are mixed together. Therefore, the clustering accuracies of algo rithms in them are not high, and it is rather hard to improve the clustering accurac ies even by several percents. From the\n",
      " > 163 [-0.07153  0.05167 -0.03665  0.0426   0.05563] these two datasets plenty of data points belonging to diﬀ erent clusters are mixed together. Therefore, the clustering accuracies of algo rithms in them are not high, and it is rather hard to improve the clustering accurac ies even by several percents. From the ﬁfth and sixth columns in Table 5, it c an be seen that the quantum game based clustering algorithms are bette r than other algorithms, which indicates the eﬀectiveness of our algorithms. Table 5: Comparison of clustering accuracies of algorithms. Algorithm\n",
      " > 164 [-0.02802  0.0578  -0.05228  0.02197  0.0581 ] the ﬁfth and sixth columns in Table 5, it c an be seen that the quantum game based clustering algorithms are bette r than other algorithms, which indicates the eﬀectiveness of our algorithms. Table 5: Comparison of clustering accuracies of algorithms. Algorithm Soybean Iris Wine Sonar Ionosphere Breast QGC1PDL1 97.9% 92.0% 94.9% 54.8% 75.5% 95.4% QGC1SDL1 95.6% 90.7% 96.6% 56.3% 74.1% 95.4% QGC2PDL1 95.6% 91.3% 96.6% 55.8% 73.8% 95.4% QGC2SDL1 89.4% 91.3% 96.6% 55.8% 75.5% 95.3% QGC1PDL2 95.8% 96.7% 95.5% 54.3%\n",
      " > 165 [ 0.002337  0.04764  -0.02853  -0.02142   0.04095 ] Algorithm Soybean Iris Wine Sonar Ionosphere Breast QGC1PDL1 97.9% 92.0% 94.9% 54.8% 75.5% 95.4% QGC1SDL1 95.6% 90.7% 96.6% 56.3% 74.1% 95.4% QGC2PDL1 95.6% 91.3% 96.6% 55.8% 73.8% 95.4% QGC2SDL1 89.4% 91.3% 96.6% 55.8% 75.5% 95.3% QGC1PDL2 95.8% 96.7% 95.5% 54.3% 74.1% 95.0% QGC1SDL2 89.4% 90.7% 95.5% 54.3% 74.6% 95.1% QGC2PDL2 89.4% 90.0% 95.5% 55.3% 74.6% 95.3% QGC2SDL2 89.4% 91.3% 94.9% 55.8% 74.9% 95.1% Kmeans [33] 68.1% 89.3% 70.2% 47.2% 71.0% – PCA-Kmeans [33] 72.3% 88.7% 70.2% 45.3% 71.0% – LDA-Km [33] 76.6%\n",
      " > 166 [-0.02887  0.0409   0.02026  0.02733  0.0791 ] 54.3% 74.1% 95.0% QGC1SDL2 89.4% 90.7% 95.5% 54.3% 74.6% 95.1% QGC2PDL2 89.4% 90.0% 95.5% 55.3% 74.6% 95.3% QGC2SDL2 89.4% 91.3% 94.9% 55.8% 74.9% 95.1% Kmeans [33] 68.1% 89.3% 70.2% 47.2% 71.0% – PCA-Kmeans [33] 72.3% 88.7% 70.2% 45.3% 71.0% – LDA-Km [33] 76.6% 98.0% 82.6% 51.0% 71.2% – 6 Conclusions The enormous successes gained by the quantum algorithms make us realize it is possible that the quantum algorithms can obtain solutions faster and bet- ter than those classical algorithms for some problems. Therefore\n",
      " > 167 [-0.07794  0.02695 -0.04633  0.0614   0.04337] 76.6% 98.0% 82.6% 51.0% 71.2% – 6 Conclusions The enormous successes gained by the quantum algorithms make us realize it is possible that the quantum algorithms can obtain solutions faster and bet- ter than those classical algorithms for some problems. Therefore , we combine the quantum game with the problem of data clustering, and establish clustering algorithms based on quantum games. In the algorithms, data points for clus- tering are regarded as players who can make decisions in quantum ga mes. On a weighted\n",
      " > 168 [-0.1131   0.02763 -0.0729   0.09955  0.04593] Therefore , we combine the quantum game with the problem of data clustering, and establish clustering algorithms based on quantum games. In the algorithms, data points for clus- tering are regarded as players who can make decisions in quantum ga mes. On a weighted and directed knn network that represents relations am ong players, each player uses quantum strategies against every one of his neigh bors in a 2 × 2 entangled quantum game respectively. We design two cases of stra tegies: (i) one plays the strategy ˆH, the\n",
      " > 169 [-0.1097   0.00656 -0.04987  0.07635  0.0508 ] weighted and directed knn network that represents relations am ong players, each player uses quantum strategies against every one of his neigh bors in a 2 × 2 entangled quantum game respectively. We design two cases of stra tegies: (i) one plays the strategy ˆH, the other plays the strategy ˆH or ˆD, (ii) one plays the strategy ˆFt− 1, the other plays the strategy ˆFt− 1 or ˆD according to the strength of links, in each of which players’ expected payoﬀs are calculated ba sed on the PD- and SD-like payoﬀ matrices respectively.\n",
      " > 170 [-0.04663  -0.002705 -0.07306   0.0835    0.0693  ] the other plays the strategy ˆH or ˆD, (ii) one plays the strategy ˆFt− 1, the other plays the strategy ˆFt− 1 or ˆD according to the strength of links, in each of which players’ expected payoﬀs are calculated ba sed on the PD- and SD-like payoﬀ matrices respectively. According to neighbor s’ payoﬀs in one’s neighbor set, each player applies a LRR function ( L1 i(·) or L2 i(·)) to change his neighbors, i.e., the links connecting to neighbors with small payoﬀs 16are removed and then new links are created to those\n",
      " > 171 [-0.1036   0.022   -0.0884   0.0938   0.05862] respectively. According to neighbor s’ payoﬀs in one’s neighbor set, each player applies a LRR function ( L1 i(·) or L2 i(·)) to change his neighbors, i.e., the links connecting to neighbors with small payoﬀs 16are removed and then new links are created to those with higher pay oﬀs. Later, the Grover iteration G is employed to update the strength of links between him and his neighbors. In the process of playing quantum game, the s tructure of the network formed by players tends to stability gradually. In ot her\n",
      " > 172 [-0.0957   0.01846 -0.08374  0.0944   0.05685] those with higher pay oﬀs. Later, the Grover iteration G is employed to update the strength of links between him and his neighbors. In the process of playing quantum game, the s tructure of the network formed by players tends to stability gradually. In ot her words, each player always connects to one of his neighbors with the largest strength or jumps among some neighbors with the largest strength in a constan t period. At this time, if only the links with the largest strength are left but all oth er links are\n",
      " > 173 [-0.0533   0.01515 -0.09735  0.07324  0.05795] her words, each player always connects to one of his neighbors with the largest strength or jumps among some neighbors with the largest strength in a constan t period. At this time, if only the links with the largest strength are left but all oth er links are removed among players, the network naturally divides into seve ral separate parts, each of which corresponds to a cluster. Additionally, in simulations, it can be found that the total expected p ayoﬀs of algorithms using SD-like payoﬀ matrix are higher than\n",
      " > 174 [-0.03833  0.0221  -0.07935  0.0554   0.0493 ] are removed among players, the network naturally divides into seve ral separate parts, each of which corresponds to a cluster. Additionally, in simulations, it can be found that the total expected p ayoﬀs of algorithms using SD-like payoﬀ matrix are higher than that of algorith ms using PD-like payoﬀ matrix. Later, the reason is explained. Further, we o bserve that the rates of convergence of the algorithms employing the LRR func tion L2 i(·) are faster slightly than that of the algorithms employing the LRR fun\n",
      " > 175 [-0.02838  0.03308 -0.05914  0.0646   0.0454 ] than that of algorith ms using PD-like payoﬀ matrix. Later, the reason is explained. Further, we o bserve that the rates of convergence of the algorithms employing the LRR func tion L2 i(·) are faster slightly than that of the algorithms employing the LRR fun ction L1 i(·), because more areas are explored by the LRR function L1 i(·), but this brings better clustering results. In the case when the exact numb er of clusters is unknown in advance, one can adjust the number k of nearest neighbors to control the number\n",
      " > 176 [-0.04922  0.03857 -0.0466   0.04822  0.02766] fun ction L1 i(·), because more areas are explored by the LRR function L1 i(·), but this brings better clustering results. In the case when the exact numb er of clusters is unknown in advance, one can adjust the number k of nearest neighbors to control the number of clusters, where the number of clusters de creases inversely with the number k of nearest neighbors. Finally, the clustering algorithms are evaluated on six real datasets, and simulation results have demons trated that data points in a dataset are clustered\n",
      " > 177 [-0.0537   0.05838 -0.078    0.06305  0.04477] number of clusters, where the number of clusters de creases inversely with the number k of nearest neighbors. Finally, the clustering algorithms are evaluated on six real datasets, and simulation results have demons trated that data points in a dataset are clustered reasonably and eﬃciently. Acknowledgments The authors would like to thank the anonymous referees for their h elpful comments and suggestions to improve the presentation of this pap er. This work was supported in part by the National Natural Science\n",
      " > 178 [-0.05304  0.04214 -0.0863   0.0691   0.0716 ] clustered reasonably and eﬃciently. Acknowledgments The authors would like to thank the anonymous referees for their h elpful comments and suggestions to improve the presentation of this pap er. This work was supported in part by the National Natural Science Foundation of China (No. 60405012, No. 60675055). References [1] V. Vedral and M. Plenio, “Basics of quantum computation,” Progress in Quantum Electronics , vol. 22, no. 1, pp. 1–39, 1998. [2] P. W. Shor, “Algorithms for quantum computation: discrete loga\n",
      " > 179 [-0.04782  0.0236  -0.03918  0.04016  0.0691 ] Science Foundation of China (No. 60405012, No. 60675055). References [1] V. Vedral and M. Plenio, “Basics of quantum computation,” Progress in Quantum Electronics , vol. 22, no. 1, pp. 1–39, 1998. [2] P. W. Shor, “Algorithms for quantum computation: discrete loga rithms and factoring,” in Proc. of the 35th Annual Symposium on Foundations of Computer Science , pp. 124–134, 1994. [3] L. K. Grover, “Quantum mechanics helps in searching for a needle in a haystack,” Physical Review Letters , vol. 79, no. 2, p. 325, 1997.\n",
      " > 180 [-0.104    0.01613 -0.02937  0.0416   0.0708 ] rithms and factoring,” in Proc. of the 35th Annual Symposium on Foundations of Computer Science , pp. 124–134, 1994. [3] L. K. Grover, “Quantum mechanics helps in searching for a needle in a haystack,” Physical Review Letters , vol. 79, no. 2, p. 325, 1997. [4] G. Brassard, P. Høyer, and A. Tapp, “Quantum counting,” in Automata, Languages and Programming , vol. 1443, pp. 820–831, 1998. [5] D. A. Meyer, “Quantum strategies,” Physical Review Letters , vol. 82, no. 5, p. 1052, 1999. [6] J. Eisert, M. Wilkens, and\n",
      " > 181 [-0.1117   0.02458 -0.05368  0.0408   0.06976] 1997. [4] G. Brassard, P. Høyer, and A. Tapp, “Quantum counting,” in Automata, Languages and Programming , vol. 1443, pp. 820–831, 1998. [5] D. A. Meyer, “Quantum strategies,” Physical Review Letters , vol. 82, no. 5, p. 1052, 1999. [6] J. Eisert, M. Wilkens, and M. Lewenstein, “Quantum games and qu antum strategies,” Physical Review Letters , vol. 83, no. 15, p. 3077, 1999. 17[7] A. P. Flitney and D. Abbott, “Advantage of a quantum player ove r a classical one in 2 x 2 quantum games,” Proceedings of the Royal Society\n",
      " > 182 [-0.08386   0.006157 -0.04343   0.0568    0.0659  ] and M. Lewenstein, “Quantum games and qu antum strategies,” Physical Review Letters , vol. 83, no. 15, p. 3077, 1999. 17[7] A. P. Flitney and D. Abbott, “Advantage of a quantum player ove r a classical one in 2 x 2 quantum games,” Proceedings of the Royal Society B: Biological Sciences, vol. 459, no. 2038, p. 2463, 2003. [8] L. Marinatto and T. Weber, “A quantum approach to static game s of com- plete information,” Physics Letters A , vol. 272, no. 5-6, pp. 291–303, 2000. [9] C. F. Lee and N. F. Johnson, “Eﬃciency\n",
      " > 183 [-0.0964  -0.0104  -0.05234  0.05695  0.03952] Society B: Biological Sciences, vol. 459, no. 2038, p. 2463, 2003. [8] L. Marinatto and T. Weber, “A quantum approach to static game s of com- plete information,” Physics Letters A , vol. 272, no. 5-6, pp. 291–303, 2000. [9] C. F. Lee and N. F. Johnson, “Eﬃciency and formalism of quantum games,” Physical Review A , vol. 67, no. 2, p. 022311, 2003. [10] J. Du, H. Li, X. Xu, M. Shi, J. Wu, X. Zhou, and R. Han, “Experime ntal realization of quantum games on a quantum computer,” Physical Review Letters, vol. 88,\n",
      " > 184 [-0.1181    0.006374 -0.0384    0.04703   0.04907 ] “Eﬃciency and formalism of quantum games,” Physical Review A , vol. 67, no. 2, p. 022311, 2003. [10] J. Du, H. Li, X. Xu, M. Shi, J. Wu, X. Zhou, and R. Han, “Experime ntal realization of quantum games on a quantum computer,” Physical Review Letters, vol. 88, no. 13, p. 137902, 2002. [11] R. Prevedel, A. Stefanov, P. Walther, and A. Zeilinger, “Exper imental realization of a quantum game on a one-way quantum computer,” New Journal of Physics , vol. 5, pp. 205–215, 2007. [12] C. Schmid, A. P. Flitney, W. Wieczorek,\n",
      " > 185 [-0.1034   0.01906 -0.03806  0.04437  0.03427] no. 13, p. 137902, 2002. [11] R. Prevedel, A. Stefanov, P. Walther, and A. Zeilinger, “Exper imental realization of a quantum game on a one-way quantum computer,” New Journal of Physics , vol. 5, pp. 205–215, 2007. [12] C. Schmid, A. P. Flitney, W. Wieczorek, N. Kiesel, H. Weinfurter, and L. C. L. Hollenberg, “Experimental implementation of a four-player quan- tum game,” arXiv:0901.0063v1, 2009. [13] H. Guo, J. Zhang, and G. J. Koehler, “A survey of quantum gam es,” De- cision Support Systems , vol. 46, no.\n",
      " > 186 [-0.08734  -0.003868 -0.04028   0.05054   0.04858 ] Wieczorek, N. Kiesel, H. Weinfurter, and L. C. L. Hollenberg, “Experimental implementation of a four-player quan- tum game,” arXiv:0901.0063v1, 2009. [13] H. Guo, J. Zhang, and G. J. Koehler, “A survey of quantum gam es,” De- cision Support Systems , vol. 46, no. 1, pp. 318–332, 2008. [14] D. Horn and A. Gottlieb, “Algorithm for data clustering in patter n recog- nition problems based on quantum mechanics,” Physical Review Letters , vol. 88, no. 1, p. 018702, 2001. [15] M. Sasaki and A. Carlini, “Quantum learning and\n",
      " > 187 [-0.05322   0.02432  -0.002007  0.065     0.0423  ] 1, pp. 318–332, 2008. [14] D. Horn and A. Gottlieb, “Algorithm for data clustering in patter n recog- nition problems based on quantum mechanics,” Physical Review Letters , vol. 88, no. 1, p. 018702, 2001. [15] M. Sasaki and A. Carlini, “Quantum learning and universal quant um matching machine,” Physical Review A , vol. 66, no. 2, p. 022303, 2002. [16] C. A. Trugenberger, “Quantum pattern recognition,” Quantum Informa- tion Processing, vol. 1, no. 6, pp. 471–493, 2002. [17] R. Sch¨ utzhold, “Pattern recognition\n",
      " > 188 [-0.03864  0.03537  0.00683  0.07275  0.04712] and universal quant um matching machine,” Physical Review A , vol. 66, no. 2, p. 022303, 2002. [16] C. A. Trugenberger, “Quantum pattern recognition,” Quantum Informa- tion Processing, vol. 1, no. 6, pp. 471–493, 2002. [17] R. Sch¨ utzhold, “Pattern recognition on a quantum computer ,” Physical Review A , vol. 67, no. 6, p. 062311, 2003. [18] E. A¨ ımeur, G. Brassard, and S. Gambs, “Quantum clustering a lgorithms,” in Proceedings of the 24th International Conference on Machin e Learning , (Corvallis, OR), 2007.\n",
      " > 189 [-0.05792  0.02217 -0.03598  0.064    0.06158] recognition on a quantum computer ,” Physical Review A , vol. 67, no. 6, p. 062311, 2003. [18] E. A¨ ımeur, G. Brassard, and S. Gambs, “Quantum clustering a lgorithms,” in Proceedings of the 24th International Conference on Machin e Learning , (Corvallis, OR), 2007. [19] A. K. Jain, M. N. Murty, and P. J. Flynn, “Data clustering: a rev iew,” ACM Computing Surveys , vol. 31, no. 3, pp. 264–323, 1999. [20] A. Ekert, P. M. Hayden, and H. Inamori, “Course 10: Basic con cepts in quantum computation,” in Coherent atomic\n",
      " > 190 [-0.1069   0.01913 -0.06903  0.042    0.03973] 2007. [19] A. K. Jain, M. N. Murty, and P. J. Flynn, “Data clustering: a rev iew,” ACM Computing Surveys , vol. 31, no. 3, pp. 264–323, 1999. [20] A. Ekert, P. M. Hayden, and H. Inamori, “Course 10: Basic con cepts in quantum computation,” in Coherent atomic matter waves , vol. 72, p. 661, Springer Berlin / Heidelberg, 2001. [21] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information. Cambridge: Cambridge University Press, 20002005. [22] J. Nash, “Equilibrium points in n-person games,” Proceedings\n",
      " > 191 [-0.1139   0.02737 -0.078    0.04456  0.03983] matter waves , vol. 72, p. 661, Springer Berlin / Heidelberg, 2001. [21] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information. Cambridge: Cambridge University Press, 20002005. [22] J. Nash, “Equilibrium points in n-person games,” Proceedings of the Na- tional Academy of Sciences , vol. 36, pp. 48–49, 1950. 18[23] J. Nash, “Non-cooperative games,” The Annals of Mathematics , vol. 54, no. 2, pp. 286–295, 1951. [24] D. Fudenberg and J. Tirole, Game Theory . MIT Press, 1983. [25] S. C. Benjamin\n",
      " > 192 [-0.11     0.02914 -0.07556  0.0639   0.04544] Proceedings of the Na- tional Academy of Sciences , vol. 36, pp. 48–49, 1950. 18[23] J. Nash, “Non-cooperative games,” The Annals of Mathematics , vol. 54, no. 2, pp. 286–295, 1951. [24] D. Fudenberg and J. Tirole, Game Theory . MIT Press, 1983. [25] S. C. Benjamin and P. M. Hayden, “Multiplayer quantum games,” Physical Review A , vol. 64, no. 3, p. 030301, 2001. [26] J. Du, H. Li, X. Xu, M. Shi, X. Zhou, and R. Han, “Entanglement c orre- lated phase changes in quantum games,” Arxiv preprint quant-ph/0111138 , 2001.\n",
      " > 193 [-0.1018   0.03464 -0.04553  0.0708   0.0262 ] Benjamin and P. M. Hayden, “Multiplayer quantum games,” Physical Review A , vol. 64, no. 3, p. 030301, 2001. [26] J. Du, H. Li, X. Xu, M. Shi, X. Zhou, and R. Han, “Entanglement c orre- lated phase changes in quantum games,” Arxiv preprint quant-ph/0111138 , 2001. [27] J. Du, H. Li, X. Xu, X. Zhou, and R. Han, “Phase-transition-like behaviour of quantum games,” Journal of Physics A: Mathematical and Theoretical , vol. 36, pp. 6551–6562, 2003. [28] C. Hauert and M. Doebeli, “Spatial structure often inhibits the\n",
      " > 194 [-0.0797   -0.008965 -0.0426    0.0771    0.01222 ] 2001. [27] J. Du, H. Li, X. Xu, X. Zhou, and R. Han, “Phase-transition-like behaviour of quantum games,” Journal of Physics A: Mathematical and Theoretical , vol. 36, pp. 6551–6562, 2003. [28] C. Hauert and M. Doebeli, “Spatial structure often inhibits the evolution of cooperation in the snowdrift game,” Nature, vol. 428, no. 6983, pp. 643– 646, 2004. [29] A.-L. Barab´ asi and E. Bonabeau, “Scale-free networks,” Scientiﬁc Ameri- can, vol. 288, no. 5, pp. 60–69, 2003. [30] G. Erkan, “Language model-based document\n",
      " > 195 [-0.01409 -0.02892 -0.0414   0.08014  0.01022] evolution of cooperation in the snowdrift game,” Nature, vol. 428, no. 6983, pp. 643– 646, 2004. [29] A.-L. Barab´ asi and E. Bonabeau, “Scale-free networks,” Scientiﬁc Ameri- can, vol. 288, no. 5, pp. 60–69, 2003. [30] G. Erkan, “Language model-based document clustering using r andom walks,” in Proceedings of the main conference on Human Language Tech- nology Conference of the North American Chapter of the Assoc iation of Computational Linguistics , (New York, New York), Association for Com- putational Linguistics,\n",
      " > 196 [-0.00669  -0.001346 -0.0458    0.0882    0.00561 ] document clustering using r andom walks,” in Proceedings of the main conference on Human Language Tech- nology Conference of the North American Chapter of the Assoc iation of Computational Linguistics , (New York, New York), Association for Com- putational Linguistics, 2006. [31] A. Asuncion and D. J. Newman, UCI Machine Learning Repository (http://www.ics.uci.edu/ mlearn/MLRepository.html). Irvine, CA: Univer- sity of California, School of Information and Computer Science, 20 07. [32] J. MacQueen, “Some methods\n",
      " > 197 [-0.04663   0.02133  -0.02933   0.0155    0.007286] Linguistics, 2006. [31] A. Asuncion and D. J. Newman, UCI Machine Learning Repository (http://www.ics.uci.edu/ mlearn/MLRepository.html). Irvine, CA: Univer- sity of California, School of Information and Computer Science, 20 07. [32] J. MacQueen, “Some methods for classiﬁcation and analysis of m ultivariate observations,” in Proceedings of Fifth Berkeley Symposium on Mathematical Statistics and Probability , vol. 1, (Statistical Laboratory of the University of California, Berkeley), pp. 281–297, 1967. [33] C. Ding\n",
      " > 198 [-0.03442   0.05228  -0.02652   0.003428  0.02216 ] methods for classiﬁcation and analysis of m ultivariate observations,” in Proceedings of Fifth Berkeley Symposium on Mathematical Statistics and Probability , vol. 1, (Statistical Laboratory of the University of California, Berkeley), pp. 281–297, 1967. [33] C. Ding and T. Li, “Adaptive dimension reduction using discriminant anal- ysis and k-means clustering,” in Proceedings of the 24th International Con- ference on Machine Learning , (Corvallis, OR), pp. 521–528, 2007. 19−5 −4 −3 −2 −1 0 1 2 3 −4 −3 −2 −1 0 1 2 3\n",
      " > 199 [-0.0865   0.03827 -0.0591   0.08636  0.04834] arXiv:0812.0743v2 [cs.LG] 10 Oct 2009 A Novel Clustering Algorithm Based on Quantum Games Qiang Li, Yan He, Jing-ping Jiang College of Electrical Engineering, Zhejiang University, Hang Zhou, Zhejiang, 310027, China May 28, 2018 Abstract The enormous successes have been made by quantum algorithms dur- ing the last decade. In this paper, we combine the quantum gam e with the problem of data clustering, and then develop a quantum-g ame-based clustering algorithm, in which data points in a dataset are c onsidered as players who can make decisions and implement quantum stra tegies in quantum games. After each round of a quantum game, each playe r’s ex- pected payoﬀ is calculated. Later, he uses an link-removing -and-rewiring (LRR) function to change his neighbors and adjust the streng th of links connecting to them in order to maximize his payoﬀ. Further, a lgorithms are discussed and analyzed in two cases of strategies, two pa yoﬀ ma- trixes and two LRR functions. Consequently, the simulation results have demonstrated\n",
      " > 200 [-0.08636  0.00915 -0.06494  0.0882   0.04385] onsidered as players who can make decisions and implement quantum stra tegies in quantum games. After each round of a quantum game, each playe r’s ex- pected payoﬀ is calculated. Later, he uses an link-removing -and-rewiring (LRR) function to change his neighbors and adjust the streng th of links connecting to them in order to maximize his payoﬀ. Further, a lgorithms are discussed and analyzed in two cases of strategies, two pa yoﬀ ma- trixes and two LRR functions. Consequently, the simulation results have demonstrated that data points in datasets are clustered rea sonably and eﬃciently, and the clustering algorithms have fast rates of convergence. Moreover, the comparison with other algorithms also provid es an indica- tion of the eﬀectiveness of the proposed approach. Keywords: Unsupervised learning; Data clustering; Quantum compu- tation; Quantum game 1 Introduction Quantum computation is an extremely exciting and rapidly growing ﬁeld . More recently, an increasing number of researchers with diﬀerent backgrounds, ranging\n",
      " > 201 [-0.05426  0.01289 -0.06287  0.0678   0.05197] demonstrated that data points in datasets are clustered rea sonably and eﬃciently, and the clustering algorithms have fast rates of convergence. Moreover, the comparison with other algorithms also provid es an indica- tion of the eﬀectiveness of the proposed approach. Keywords: Unsupervised learning; Data clustering; Quantum compu- tation; Quantum game 1 Introduction Quantum computation is an extremely exciting and rapidly growing ﬁeld . More recently, an increasing number of researchers with diﬀerent backgrounds, ranging from physics, computer sciences and information theory t o mathematics and philosophy, are involved in researching properties of quantum- based com- putation [1]. During the last decade, a series of signiﬁcant breakthr oughs had been made. One was that in 1994 Peter Shor surprised the world by p roposing a polynomial-time quantum algorithm for integer factorization [2], while in the classical world the best-known classical factoring algorithm works in superpoly- nomial time. Three years later, in 1997,\n",
      " > 202 [-0.08673  0.02254 -0.0645   0.035    0.03806] ranging from physics, computer sciences and information theory t o mathematics and philosophy, are involved in researching properties of quantum- based com- putation [1]. During the last decade, a series of signiﬁcant breakthr oughs had been made. One was that in 1994 Peter Shor surprised the world by p roposing a polynomial-time quantum algorithm for integer factorization [2], while in the classical world the best-known classical factoring algorithm works in superpoly- nomial time. Three years later, in 1997, Lov Grover proved that a q uantum computer could search an unsorted database in the square root o f the time [3]. Meanwhile, Gilles Brassard et al. combined ideas from Grover’s and Sho r’s quantum algorithms to propose a quantum counting algorithm [4]. 1In recent years, many interests focus on the quantum game theo ry and con- siderable work has been done. For instance, D. A. Meyer [5] studied the Penny Flip game in the quantum world ﬁrstly. His result showed that if a player was allowed to implement quantum\n",
      " > 203 [-0.0959   0.0273  -0.06995  0.06647  0.05484] 1997, Lov Grover proved that a q uantum computer could search an unsorted database in the square root o f the time [3]. Meanwhile, Gilles Brassard et al. combined ideas from Grover’s and Sho r’s quantum algorithms to propose a quantum counting algorithm [4]. 1In recent years, many interests focus on the quantum game theo ry and con- siderable work has been done. For instance, D. A. Meyer [5] studied the Penny Flip game in the quantum world ﬁrstly. His result showed that if a player was allowed to implement quantum strategies, he would always defeat his o pponent who played the classical strategies and increase his expected payo ﬀ as well. J. Eisert et al. [6] quantized the Prisoners’ Dilemma and demonstrated that the dilemma could be escaped when both players resort to quantum stra tegies. A. P. Flitney et al. [7] generalized Eisert’s result, the miracle move, i.e., th e result of the game would move towards the quantum player’s preferred re sult, while the other player used classical strategies. L. Marinatto et al.\n",
      " > 204 [-0.0728   0.0263  -0.0436   0.08295  0.04782] quantum strategies, he would always defeat his o pponent who played the classical strategies and increase his expected payo ﬀ as well. J. Eisert et al. [6] quantized the Prisoners’ Dilemma and demonstrated that the dilemma could be escaped when both players resort to quantum stra tegies. A. P. Flitney et al. [7] generalized Eisert’s result, the miracle move, i.e., th e result of the game would move towards the quantum player’s preferred re sult, while the other player used classical strategies. L. Marinatto et al. [8] in vestigated the Battle of the Sexes game in quantum domain. Their result showed tha t there existed a unique equilibrium in the game, when the entangled strategie s were allowed. C. F. Lee et al. [9] reported that the quantum game is more eﬃcient than the classical game, and they found an upper bound for this eﬃ ciency. Be- sides, some experiments about the quantum games have also been im plemented on diﬀerent quantum computers [10, 11, 12]. For more details about quantum games, see [13]. Successes achieved\n",
      " > 205 [-0.05313  0.03574 -0.01167  0.04474  0.07434] al. [8] in vestigated the Battle of the Sexes game in quantum domain. Their result showed tha t there existed a unique equilibrium in the game, when the entangled strategie s were allowed. C. F. Lee et al. [9] reported that the quantum game is more eﬃcient than the classical game, and they found an upper bound for this eﬃ ciency. Be- sides, some experiments about the quantum games have also been im plemented on diﬀerent quantum computers [10, 11, 12]. For more details about quantum games, see [13]. Successes achieved by quantum algorithms make us guess that pow erful quantum computers can ﬁgure out solutions faster and better th an the best known classical counterparts for certain types of problems. Fur thermore, it is more important that they oﬀer a new way to ﬁnd potentially dramatic algorith- mic speed-ups. Therefore, we may ask naturally: can we construc t quantum versions of classical algorithms or present new quantum algorithms to solve the problems in pattern recognition faster and better on a quantu m computer?\n",
      " > 206 [-0.03198  0.04443 -0.02089  0.05237  0.02728] achieved by quantum algorithms make us guess that pow erful quantum computers can ﬁgure out solutions faster and better th an the best known classical counterparts for certain types of problems. Fur thermore, it is more important that they oﬀer a new way to ﬁnd potentially dramatic algorith- mic speed-ups. Therefore, we may ask naturally: can we construc t quantum versions of classical algorithms or present new quantum algorithms to solve the problems in pattern recognition faster and better on a quantu m computer? Following this idea, some researchers have proposed their novel me thods and demonstrated exciting results [14, 15, 16, 17, 18]. In addition, data clustering is a main branch of Pattern Recognition, which is widely used in many ﬁelds such as pattern analysis, data mining, infor ma- tion retrieval and image segmentation. In these ﬁelds, however, t here is usually little priori knowledge available about the data. In response to thes e restric- tions, clustering methodology come into being which is particularly\n",
      " > 207 [-0.06824  0.05215 -0.05664  0.07947  0.02681] computer? Following this idea, some researchers have proposed their novel me thods and demonstrated exciting results [14, 15, 16, 17, 18]. In addition, data clustering is a main branch of Pattern Recognition, which is widely used in many ﬁelds such as pattern analysis, data mining, infor ma- tion retrieval and image segmentation. In these ﬁelds, however, t here is usually little priori knowledge available about the data. In response to thes e restric- tions, clustering methodology come into being which is particularly suit able for the exploration of interrelationships among data points. Data clust ering is the formal study of algorithms and methods for grouping or classifying unlabeled data points [19]. In other words, its task is to ﬁnd the inherent stru cture of a given collection of unlabeled data points and group them into meaningf ul clus- ters [19]. In this paper, we attempt to combine the quantum game wit h the problem of data clustering in order to establish a novel clustering alg orithm based on quantum\n",
      " > 208 [-0.1063   0.04105 -0.0559   0.0994   0.04523] particularly suit able for the exploration of interrelationships among data points. Data clust ering is the formal study of algorithms and methods for grouping or classifying unlabeled data points [19]. In other words, its task is to ﬁnd the inherent stru cture of a given collection of unlabeled data points and group them into meaningf ul clus- ters [19]. In this paper, we attempt to combine the quantum game wit h the problem of data clustering in order to establish a novel clustering alg orithm based on quantum games. In our algorithms, unlabeled data points in a dataset are regarded as players who can make decisions in quantum games. O n a time- varying network formed by players, each player is permitted to use quantum strategies and plays a 2 × 2 entangled quantum game against every one of his neighbors respectively. Later, he applies a link-removing-and-rew iring (LRR) function to remove the links of neighbors with small payoﬀs and crea te new links to neighbors with higher payoﬀs at the same time. Furthermore,\n",
      " > 209 [-0.1011   0.0231  -0.0705   0.1043   0.04697] games. In our algorithms, unlabeled data points in a dataset are regarded as players who can make decisions in quantum games. O n a time- varying network formed by players, each player is permitted to use quantum strategies and plays a 2 × 2 entangled quantum game against every one of his neighbors respectively. Later, he applies a link-removing-and-rew iring (LRR) function to remove the links of neighbors with small payoﬀs and crea te new links to neighbors with higher payoﬀs at the same time. Furthermore, th e strength of links between a player and his neighbors is diﬀerent from one anoth er, which is updated by the Grover iteration. During quantum games, the str ucture of network and the strength of links between players tend toward st ability grad- ually. Finally, if each player only connects to the neighbor with the high est strength, the network will naturally divide into several separate p arts, each of which corresponds to a cluster. 2The remainder of this paper is organized as follows: Section 2 introdu\n",
      " > 210 [-0.07825  0.02245 -0.0935   0.1075   0.04654] th e strength of links between a player and his neighbors is diﬀerent from one anoth er, which is updated by the Grover iteration. During quantum games, the str ucture of network and the strength of links between players tend toward st ability grad- ually. Finally, if each player only connects to the neighbor with the high est strength, the network will naturally divide into several separate p arts, each of which corresponds to a cluster. 2The remainder of this paper is organized as follows: Section 2 introdu ces some important concepts about the quantum computation and the quantum Prisoners’ Dilemma brieﬂy. In Section 3, the algorithms are establish ed in two cases of strategies, payoﬀ matrices and link-removing-and-rewir ing (LRR) func- tions, and then they are elaborated and analyzed. In Section 4, th e relationship between the number of nearest neighbors and the number of clust ers is dis- cussed. Next, the eﬀect of the cost in the SD-like payoﬀ matrix is an alyzed, and the relationship between the total payoﬀs\n",
      " > 211 [-0.0719    0.004135 -0.0853    0.06854   0.03183 ] introdu ces some important concepts about the quantum computation and the quantum Prisoners’ Dilemma brieﬂy. In Section 3, the algorithms are establish ed in two cases of strategies, payoﬀ matrices and link-removing-and-rewir ing (LRR) func- tions, and then they are elaborated and analyzed. In Section 4, th e relationship between the number of nearest neighbors and the number of clust ers is dis- cussed. Next, the eﬀect of the cost in the SD-like payoﬀ matrix is an alyzed, and the relationship between the total payoﬀs and the rates of co nvergence of algorithms is explained. In Section 5, those datasets used in the simu lations are introduced brieﬂy, and then results of algorithms are demonst rated. The conclusion is given in Section 6. 2 Quantum computation and quantum game 2.1 Quantum computation The elementary unit of quantum computation is called the qubit, which is typically a microscopic system, such as an atom, a nuclear spin, or a p olarized photon. In quantum computation, the Boolean states 0 and 1 are r epresented\n",
      " > 212 [-0.10406  0.0555  -0.0447   0.05576  0.01283] payoﬀs and the rates of co nvergence of algorithms is explained. In Section 5, those datasets used in the simu lations are introduced brieﬂy, and then results of algorithms are demonst rated. The conclusion is given in Section 6. 2 Quantum computation and quantum game 2.1 Quantum computation The elementary unit of quantum computation is called the qubit, which is typically a microscopic system, such as an atom, a nuclear spin, or a p olarized photon. In quantum computation, the Boolean states 0 and 1 are r epresented by a prescribed pair of normalized and mutually orthogonal quantum st ates labeled as {|0⟩, |1⟩} to form a ’computational basis’ [20]. Any pure state of the qubit can be written as a superposition state α|0⟩+ β|1⟩ for some α and β satisfying |α|2 + |β|2 = 1 [20]. A collection of n qubits is called a quantum register of size n, which spans a Hilbert space of 2 n dimensions, so 2 n mutually orthogonal quantum states can be available. Quantum state preparations, and any other manipulations on qubit s,\n",
      " > 213 [-0.1062     0.05984   -0.0007544  0.07983    0.01776  ] epresented by a prescribed pair of normalized and mutually orthogonal quantum st ates labeled as {|0⟩, |1⟩} to form a ’computational basis’ [20]. Any pure state of the qubit can be written as a superposition state α|0⟩+ β|1⟩ for some α and β satisfying |α|2 + |β|2 = 1 [20]. A collection of n qubits is called a quantum register of size n, which spans a Hilbert space of 2 n dimensions, so 2 n mutually orthogonal quantum states can be available. Quantum state preparations, and any other manipulations on qubit s, have to be performed by unitary operations. A quantum logic gate is a dev ice which performs a ﬁxed unitary operation on selected qubits in a ﬁxed perio d of time, and a quantum circuit is a device consisting of quantum logic gates who se com- putational steps are synchronized in time [20]. The most common qua ntum gate is the Hadamard gate, which acts on a qubit in state |0⟩ or |1⟩ to produce    |0⟩ H − → 1 √ 2 |0⟩+ 1√ 2 |1⟩ |1⟩ H − → 1√ 2 |0⟩ − 1√ 2 |1⟩ ,H = 1√ 2 ( 1 1 1−1 ) . (1) For more details, see\n",
      " > 214 [-0.0936   0.02083 -0.04346  0.0839   0.04318] have to be performed by unitary operations. A quantum logic gate is a dev ice which performs a ﬁxed unitary operation on selected qubits in a ﬁxed perio d of time, and a quantum circuit is a device consisting of quantum logic gates who se com- putational steps are synchronized in time [20]. The most common qua ntum gate is the Hadamard gate, which acts on a qubit in state |0⟩ or |1⟩ to produce    |0⟩ H − → 1 √ 2 |0⟩+ 1√ 2 |1⟩ |1⟩ H − → 1√ 2 |0⟩ − 1√ 2 |1⟩ ,H = 1√ 2 ( 1 1 1−1 ) . (1) For more details, see [20, 21]. 2.2 Quantum Prisoners’ Dilemma The Prisoners’ Dilemma (PD), a well-known example in the classical gam e theory, is an abstract of many phenomena in the real world and it ha s been wildly used in plenty of scientiﬁc ﬁelds. In this game, each of two player s has two optional strategies, cooperation (C) and defection (D). Lat er, he chooses one strategy against the other’s for maximizing his own payoﬀ, so do es the other side at the same time, but both sides do not know the opponent’s str ategy. As a\n",
      " > 215 [-0.0788    0.001884 -0.03452   0.0802    0.0582  ] [20, 21]. 2.2 Quantum Prisoners’ Dilemma The Prisoners’ Dilemma (PD), a well-known example in the classical gam e theory, is an abstract of many phenomena in the real world and it ha s been wildly used in plenty of scientiﬁc ﬁelds. In this game, each of two player s has two optional strategies, cooperation (C) and defection (D). Lat er, he chooses one strategy against the other’s for maximizing his own payoﬀ, so do es the other side at the same time, but both sides do not know the opponent’s str ategy. As a result, each player receives a payoﬀ which depends on his selected strategy, where the payoﬀ matrix under diﬀerent strategy proﬁles is describ ed in Table 1. According to the classical game theory, the strategy proﬁle (def ection, defection) 3Table 1: Payoﬀ matrix for the Prisoners’ Dilemma. C = 0 D= 1 C = 0 R= 3 S = 0 D= 1 T = 5 P = 1 is the unique Nash Equilibrium [22, 23], but unfortunately it is not Paret o optimal [24]. In the quantum game, however, thanks to the quantum strategie s, the dilemma in the\n",
      " > 216 [-0.0856   0.01398 -0.04044  0.0914   0.03647] result, each player receives a payoﬀ which depends on his selected strategy, where the payoﬀ matrix under diﬀerent strategy proﬁles is describ ed in Table 1. According to the classical game theory, the strategy proﬁle (def ection, defection) 3Table 1: Payoﬀ matrix for the Prisoners’ Dilemma. C = 0 D= 1 C = 0 R= 3 S = 0 D= 1 T = 5 P = 1 is the unique Nash Equilibrium [22, 23], but unfortunately it is not Paret o optimal [24]. In the quantum game, however, thanks to the quantum strategie s, the dilemma in the classical game can be escaped in a restricted strategic space [6]. The physical model of quantum Prisoners’ Dilemma presented by Eis ert [6] is shown in Figure 1. Figure 1: The block diagram of the system. If the possible outcomes of the classical strategies, C = 0 and D = 1, are assigned to two basis vectors {|C = 0 ⟩, |D = 1 ⟩} in Hilbert space respectively, then at any time the state of the game may be represented by a vec tor in the space spanned by the basis {|00⟩, |01⟩, |10⟩, |11⟩} [6]. Assume the initial\n",
      " > 217 [-0.0965   0.05115 -0.05627  0.1017   0.0247 ] classical game can be escaped in a restricted strategic space [6]. The physical model of quantum Prisoners’ Dilemma presented by Eis ert [6] is shown in Figure 1. Figure 1: The block diagram of the system. If the possible outcomes of the classical strategies, C = 0 and D = 1, are assigned to two basis vectors {|C = 0 ⟩, |D = 1 ⟩} in Hilbert space respectively, then at any time the state of the game may be represented by a vec tor in the space spanned by the basis {|00⟩, |01⟩, |10⟩, |11⟩} [6]. Assume the initial state of the game is |ψ0⟩ = ˆJ |00⟩, where ˆJ is an entangling operator which is known to both players. For a two-player game with two pure strategies, the general form of ˆJ may be written as [25, 26] ˆJ(γ) = exp(iγ 2 σ⊗ 2 x ) = I⊗ 2cosγ 2 + iσ⊗ 2 x sinγ 2 (2) where γ ∈ [0,π/ 2] is a measure of entanglement of a game. When γ = π/ 2, there is a maximally entangled game, in which the entangling operator t akes form ˆJ(γ) = 1√ 2 (I⊗ 2 + iσ⊗ 2 x ). (3) Next, each player chooses a unitary operator ˆY1( ˆY2)\n",
      " > 218 [-0.0938   0.03958 -0.083    0.06665  0.063  ] initial state of the game is |ψ0⟩ = ˆJ |00⟩, where ˆJ is an entangling operator which is known to both players. For a two-player game with two pure strategies, the general form of ˆJ may be written as [25, 26] ˆJ(γ) = exp(iγ 2 σ⊗ 2 x ) = I⊗ 2cosγ 2 + iσ⊗ 2 x sinγ 2 (2) where γ ∈ [0,π/ 2] is a measure of entanglement of a game. When γ = π/ 2, there is a maximally entangled game, in which the entangling operator t akes form ˆJ(γ) = 1√ 2 (I⊗ 2 + iσ⊗ 2 x ). (3) Next, each player chooses a unitary operator ˆY1( ˆY2) from the strategy space S1(S2) and operates it on the qubit that belongs to him, which makes the ga me in a state ( ˆY1 ⊗ ˆY2) ˆJ|00⟩. Speciﬁcally, the unitary operators ˆC and ˆD that correspond to the strategies, cooperation and defection, are g iven below [6] ˆC = (1 0 0 1 ) , ˆD= ( 0 1 −1 0 ) . (4) In the end, before a projective measurement in the basis {|0⟩, |1⟩} is carried out, the ﬁnal state is |ψf ⟩ = ˆJ†( ˆY1 ⊗ ˆY2) ˆJ |00⟩. (5) Thus, the player’s expected payoﬀ is written as z= R|⟨ψf |00⟩|2 + S|⟨ψf\n",
      " > 219 [-0.0886    0.013756 -0.0868    0.07996   0.04288 ] ˆY2) from the strategy space S1(S2) and operates it on the qubit that belongs to him, which makes the ga me in a state ( ˆY1 ⊗ ˆY2) ˆJ|00⟩. Speciﬁcally, the unitary operators ˆC and ˆD that correspond to the strategies, cooperation and defection, are g iven below [6] ˆC = (1 0 0 1 ) , ˆD= ( 0 1 −1 0 ) . (4) In the end, before a projective measurement in the basis {|0⟩, |1⟩} is carried out, the ﬁnal state is |ψf ⟩ = ˆJ†( ˆY1 ⊗ ˆY2) ˆJ |00⟩. (5) Thus, the player’s expected payoﬀ is written as z= R|⟨ψf |00⟩|2 + S|⟨ψf |01⟩|2 + T|⟨ψf |10⟩|2 + P|⟨ψf |11⟩|2. (6) For more details, see [6, 27]. 43 Algorithm In the section, we will combine the model of the quantum game with th e problem of data clustering, and then establish clustering algorithms based on quantum games. Assume an unlabeled dataset X = {X 1, X 2, · · · , X N },which are distributed in a m-dimensional metric space. Each data point in the dataset is considered as a player in quantum games who can make decisions and always hope to maximize his payoﬀ. In the metric\n",
      " > 220 [-0.0755   0.01807 -0.06247  0.0946   0.03857] S|⟨ψf |01⟩|2 + T|⟨ψf |10⟩|2 + P|⟨ψf |11⟩|2. (6) For more details, see [6, 27]. 43 Algorithm In the section, we will combine the model of the quantum game with th e problem of data clustering, and then establish clustering algorithms based on quantum games. Assume an unlabeled dataset X = {X 1, X 2, · · · , X N },which are distributed in a m-dimensional metric space. Each data point in the dataset is considered as a player in quantum games who can make decisions and always hope to maximize his payoﬀ. In the metric space, there is a distance f unction d : X × X − → R, satisfying the closer the two players are, the smaller the output is. Based on the distance function, a k nearest neighbors (knn) network as a weighted and directed network, G0(X ,E 0,d ), may be created among data points by adding k edges directed toward its k nearest neighbors for each player. Deﬁnition 1 If there is a set X with N players, X = {X1, X2, · · · , XN }, the weighted and directed knn network, G0(X,E 0,d ), is created as below.     \n",
      " > 221 [-0.07184  0.02225 -0.0699   0.05484  0.06934] metric space, there is a distance f unction d : X × X − → R, satisfying the closer the two players are, the smaller the output is. Based on the distance function, a k nearest neighbors (knn) network as a weighted and directed network, G0(X ,E 0,d ), may be created among data points by adding k edges directed toward its k nearest neighbors for each player. Deﬁnition 1 If there is a set X with N players, X = {X1, X2, · · · , XN }, the weighted and directed knn network, G0(X,E 0,d ), is created as below.                  X = { Xi,i = 1 , 2, · · · ,N } E0 = ⋃ N i=1 E0(i) E0(i) = { e0 ( Xi, Xj ) | j ∈ Γ 0(i) } Γ 0(i) = { j ⏐ ⏐ ⏐j = argmink Xh∈ X ({ d(Xi, Xh), Xh ∈ X } )} (7) Here, each player in the set X corresponds to a vertex in the network G0(X,E 0,d ); E0 is a link set and a link in the network represents certain rela tionship between a pair of players; the distances denote the weights over link s; the function, argmink(·), is to ﬁnd k nearest neighbors of a player which construct a ne igh- bor set,\n",
      " > 222 [-0.1022   0.02151 -0.0674   0.0733   0.05997]             X = { Xi,i = 1 , 2, · · · ,N } E0 = ⋃ N i=1 E0(i) E0(i) = { e0 ( Xi, Xj ) | j ∈ Γ 0(i) } Γ 0(i) = { j ⏐ ⏐ ⏐j = argmink Xh∈ X ({ d(Xi, Xh), Xh ∈ X } )} (7) Here, each player in the set X corresponds to a vertex in the network G0(X,E 0,d ); E0 is a link set and a link in the network represents certain rela tionship between a pair of players; the distances denote the weights over link s; the function, argmink(·), is to ﬁnd k nearest neighbors of a player which construct a ne igh- bor set, Γ 0(i); the subscript ’0’ is the initial time step. It is worth noting that the strength of links between a player X i and his k nearest neighbors represented by ρt− 1(X i, X j ),j ∈ Γ t− 1(i)(t ≥ 1) is time- varying, whose initial values is calculated by ρ0(X i, X j) = { 1/ |Γ 0(i)| = 1 /k, j ∈ Γ 0(i) 0, otherwise (8) where the symbol | · | denotes the cardinality of a set. After the initial connections are constructed among players (dat a points), on this weighted and directed knn network, a quantum game\n",
      " > 223 [-0.1015   0.04166 -0.0704   0.03592  0.03946] set, Γ 0(i); the subscript ’0’ is the initial time step. It is worth noting that the strength of links between a player X i and his k nearest neighbors represented by ρt− 1(X i, X j ),j ∈ Γ t− 1(i)(t ≥ 1) is time- varying, whose initial values is calculated by ρ0(X i, X j) = { 1/ |Γ 0(i)| = 1 /k, j ∈ Γ 0(i) 0, otherwise (8) where the symbol | · | denotes the cardinality of a set. After the initial connections are constructed among players (dat a points), on this weighted and directed knn network, a quantum game can be d eﬁned as following. Deﬁnition 2A quantum game Ω = {X,G t,S,Z t} on a network Gt is a 4- tuple: X is a set of players; Gt represents the connections among players; S = {s(i),i = 1 , 2, · · · ,N } represents a set of players’ strategies including the full range of quantum strategies; Zt = {zt(i),i = 1 , 2, · · · ,N } represents a set of players’ expected payoﬀs. Here, the variable tdenotes the time step (the number of iterations). In each round, players choose theirs strate gies simultaneously, and\n",
      " > 224 [-0.1035   0.02513 -0.0714   0.0543   0.03955] game can be d eﬁned as following. Deﬁnition 2A quantum game Ω = {X,G t,S,Z t} on a network Gt is a 4- tuple: X is a set of players; Gt represents the connections among players; S = {s(i),i = 1 , 2, · · · ,N } represents a set of players’ strategies including the full range of quantum strategies; Zt = {zt(i),i = 1 , 2, · · · ,N } represents a set of players’ expected payoﬀs. Here, the variable tdenotes the time step (the number of iterations). In each round, players choose theirs strate gies simultaneously, and each player can only observe its neighbors’ payoﬀs, but d oes not know the strategy proﬁles of all other players in X. 53.1 Cases of quantum strategies and payoﬀ matrices At ﬁrst, each player selects a strategy from his strategy set, an d then plays a 2 × 2 entangled quantum game against one of his k neighbors respectively. In the classical 2 × 2 game, such as the Prisoners’ Dilemma, usually there are only two pure strategies, cooperation and defection, but in the quant um game, one can design diﬀerent unitary\n",
      " > 225 [-0.1021     0.0008845 -0.04364    0.08875    0.04944  ] each player can only observe its neighbors’ payoﬀs, but d oes not know the strategy proﬁles of all other players in X. 53.1 Cases of quantum strategies and payoﬀ matrices At ﬁrst, each player selects a strategy from his strategy set, an d then plays a 2 × 2 entangled quantum game against one of his k neighbors respectively. In the classical 2 × 2 game, such as the Prisoners’ Dilemma, usually there are only two pure strategies, cooperation and defection, but in the quant um game, one can design diﬀerent unitary operators as strategies, i.e., the stra tegy set S may be identiﬁed with some subset of the group of 2 × 2 unitary matrices [6]. Here, for the purpose of clustering and simplifying computation, the stra tegy set of a player X i is restricted in a set S1 = { ˆH, ˆD} or S2 = { ˆFt− 1(i,j ), ˆD}, and then two cases of strategy sets are described respectively. Case 1: In this case, a player and his opponent can apply strategies inS1 = { ˆH, ˆD}. When a player X i use the Hadamard matrix ˆH as a strategy, his\n",
      " > 226 [-0.0736   0.03784 -0.0513   0.07355  0.0434 ] unitary operators as strategies, i.e., the stra tegy set S may be identiﬁed with some subset of the group of 2 × 2 unitary matrices [6]. Here, for the purpose of clustering and simplifying computation, the stra tegy set of a player X i is restricted in a set S1 = { ˆH, ˆD} or S2 = { ˆFt− 1(i,j ), ˆD}, and then two cases of strategy sets are described respectively. Case 1: In this case, a player and his opponent can apply strategies inS1 = { ˆH, ˆD}. When a player X i use the Hadamard matrix ˆH as a strategy, his opponent (neighbor) X j has two optional strategies { ˆH, ˆD}, but which strategy is chosen is dependent on the strength of the link between them, as is a rule of the clustering algorithm. If the strength ρt− 1(X j , X i) equals to zero, i.e., there is no link directed from the player X j to the player X i, then the player X j will apply the strategy ’Defection’ ( ˆD). Alternatively, if ρt− 1(X j , X i) >0, namely mutual connections between them, the player X j implements the strategy ˆH. If the initial state\n",
      " > 227 [-0.05902  0.02249 -0.0628   0.08246  0.0282 ] opponent (neighbor) X j has two optional strategies { ˆH, ˆD}, but which strategy is chosen is dependent on the strength of the link between them, as is a rule of the clustering algorithm. If the strength ρt− 1(X j , X i) equals to zero, i.e., there is no link directed from the player X j to the player X i, then the player X j will apply the strategy ’Defection’ ( ˆD). Alternatively, if ρt− 1(X j , X i) >0, namely mutual connections between them, the player X j implements the strategy ˆH. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, by applying the model of the quantum game the ﬁnal state of the game is |ψf,j ⟩ = { 1 2 (|00⟩ − i|01⟩ − i|10⟩+ |11⟩), ˆH⊗ ˆH 1√ 2 (i|00⟩ − |01⟩), ˆH⊗ ˆD (9) Case 2: The strategy setS2 = { ˆFt− 1(i,j ), ˆD} is adopted in the case. The strategy ˆFt− 1(i,j ), ˆFt− 1(i,j ) = ( √ ρt− 1(X i, X j ) √ 1 − ρt− 1(X i, X j )√ 1 − ρt− 1(X i, X j ) − √ ρt− 1(X i, X j ) ) , is a general form of Hadamard matrix ˆH whose elements are associated with the strength of links ρt− 1(X i, X j ). When\n",
      " > 228 [-0.1007   0.01639 -0.05478  0.07556  0.0505 ] state of the game is |ψ0⟩ = ˆJ|00⟩, by applying the model of the quantum game the ﬁnal state of the game is |ψf,j ⟩ = { 1 2 (|00⟩ − i|01⟩ − i|10⟩+ |11⟩), ˆH⊗ ˆH 1√ 2 (i|00⟩ − |01⟩), ˆH⊗ ˆD (9) Case 2: The strategy setS2 = { ˆFt− 1(i,j ), ˆD} is adopted in the case. The strategy ˆFt− 1(i,j ), ˆFt− 1(i,j ) = ( √ ρt− 1(X i, X j ) √ 1 − ρt− 1(X i, X j )√ 1 − ρt− 1(X i, X j ) − √ ρt− 1(X i, X j ) ) , is a general form of Hadamard matrix ˆH whose elements are associated with the strength of links ρt− 1(X i, X j ). When ρt− 1(X i, X j )=0.5, the strategy ˆFt− 1(i,j ) recovers the strategy ˆH. Similarly, the neighbor X j , when ρt− 1(X j , X i) = 0, applies the strategy ’Defection’ ( ˆD), while using the strategy ˆFt− 1(i,j ) when ρt− 1(X j , X i) > 0. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, after their moves, the ﬁnal state of the game is |ψf,j ⟩ =      √ ρ1ρ2|00⟩ − i √ ρ2(1 − ρ1)|01⟩ −i √ ρ1(1 − ρ2)|10⟩+ √ (1 − ρ1)(1 − ρ2)|11⟩, ˆFt− 1 ⊗ ˆFt− 1 i√1 − ρ1|00⟩ − √ρ1|01⟩, ˆFt− 1 ⊗ ˆD . (10) According to the payoﬀ\n",
      " > 229 [-0.03156  0.00812 -0.0774   0.06976  0.03113] When ρt− 1(X i, X j )=0.5, the strategy ˆFt− 1(i,j ) recovers the strategy ˆH. Similarly, the neighbor X j , when ρt− 1(X j , X i) = 0, applies the strategy ’Defection’ ( ˆD), while using the strategy ˆFt− 1(i,j ) when ρt− 1(X j , X i) > 0. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, after their moves, the ﬁnal state of the game is |ψf,j ⟩ =      √ ρ1ρ2|00⟩ − i √ ρ2(1 − ρ1)|01⟩ −i √ ρ1(1 − ρ2)|10⟩+ √ (1 − ρ1)(1 − ρ2)|11⟩, ˆFt− 1 ⊗ ˆFt− 1 i√1 − ρ1|00⟩ − √ρ1|01⟩, ˆFt− 1 ⊗ ˆD . (10) According to the payoﬀ matrix, the player’s expected payoﬀ can be computed by zt− 1(i) = ∑ j∈ Γ t− 1 (i) zt− 1(X i, X j ) = ∑ j∈ Γ t− 1 (i) R|⟨ψf,j |00⟩|2 + S|⟨ψf,j |01⟩|2 + T|⟨ψf,j |10⟩|2 + P|⟨ψf,j |11⟩|2. (11) 6In practice, the payoﬀ matrix takes PD-like or Snowdrift (SD)-like f orm, de- scribed in Table 2 and 3. In the PD-like payoﬀ matrix, the following inequ ali- Table 2: PD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= 0 .6ωt− 1(X i, X j ) S = 0 .01ωt− 1(X i, X j ) D= 1 T = ωt− 1(X i, X j ) P = 0 .2ωt− 1(X i, X j ) Table 3: SD-like\n",
      " > 230 [-0.0438    0.005577 -0.04764   0.0474    0.0573  ] payoﬀ matrix, the player’s expected payoﬀ can be computed by zt− 1(i) = ∑ j∈ Γ t− 1 (i) zt− 1(X i, X j ) = ∑ j∈ Γ t− 1 (i) R|⟨ψf,j |00⟩|2 + S|⟨ψf,j |01⟩|2 + T|⟨ψf,j |10⟩|2 + P|⟨ψf,j |11⟩|2. (11) 6In practice, the payoﬀ matrix takes PD-like or Snowdrift (SD)-like f orm, de- scribed in Table 2 and 3. In the PD-like payoﬀ matrix, the following inequ ali- Table 2: PD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= 0 .6ωt− 1(X i, X j ) S = 0 .01ωt− 1(X i, X j ) D= 1 T = ωt− 1(X i, X j ) P = 0 .2ωt− 1(X i, X j ) Table 3: SD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= ωt− 1(X i, X j ) − c 2 S = ωt− 1(X i, X j ) − c D= 1 T = ωt− 1(X i, X j ) P = 0 .01ωt− 1(X i, X j ) ties holds: T >R>P >S and 2 R>T + S [28]. To avoid a case that a player’s expected payoﬀ is zero, the variable S in Table 2 takes a small value instead of zero in Table 1. In addition, the Snowdrift game assumes that two drivers are blocked by a snowdrift, each of whom is in either side of the snowd rift. If they want to go back home, one of them or both must shovel a path\n",
      " > 231 [-0.04633   0.001668 -0.0377    0.0549    0.0624  ] SD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= ωt− 1(X i, X j ) − c 2 S = ωt− 1(X i, X j ) − c D= 1 T = ωt− 1(X i, X j ) P = 0 .01ωt− 1(X i, X j ) ties holds: T >R>P >S and 2 R>T + S [28]. To avoid a case that a player’s expected payoﬀ is zero, the variable S in Table 2 takes a small value instead of zero in Table 1. In addition, the Snowdrift game assumes that two drivers are blocked by a snowdrift, each of whom is in either side of the snowd rift. If they want to go back home, one of them or both must shovel a path through the snowdrift. So, there exists a cost c in the SD-like payoﬀ matrix and the following inequality holds: T > R > S > P[28], where c = β · ωt− 1(X i, X j ) and β is a proportional factor. Besides, the variable ωt− 1(X i, X j ) in two payoﬀ matrices is calculated by the formulation below. ωt− 1(X i, X j ) = ρt− 1(X i, X j ) × Degt− 1(X j )/d (X i, X j ) (12) 3.2 Design of LRR functions When all players’ payoﬀs have been computed, each player will obse rve his neighbors’ payoﬀs, and apply a link-removing-and-rewiring\n",
      " > 232 [-0.0654    0.007313 -0.03099   0.05984   0.0552  ] path through the snowdrift. So, there exists a cost c in the SD-like payoﬀ matrix and the following inequality holds: T > R > S > P[28], where c = β · ωt− 1(X i, X j ) and β is a proportional factor. Besides, the variable ωt− 1(X i, X j ) in two payoﬀ matrices is calculated by the formulation below. ωt− 1(X i, X j ) = ρt− 1(X i, X j ) × Degt− 1(X j )/d (X i, X j ) (12) 3.2 Design of LRR functions When all players’ payoﬀs have been computed, each player will obse rve his neighbors’ payoﬀs, and apply a link-removing-and-rewiring (LRR) f unction Li(·) to change his links. A LRR function is deﬁned as below. Deﬁnition 3The LRR function Li(·) is a function of payoﬀs, whose output is a set with k elements, namely an updated neighbor set Γ t(i) of a player Xi. It is given as below. Γ t(i) = Li ( ˆzt− 1(i) ) = argmaxk j∈ Γ t− 1 (i) S Υ t− 1(i) ({ zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) }) ˆzt− 1(i) = { zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) } , Υ t− 1(i) = ⋃ j∈ Γ + t− 1 (i) Γ t− 1(j) Γ + t− 1(i) = { j|zt− 1(j) ≥ θt− 1(i),j ∈ Γ t−\n",
      " > 233 [-0.1035   0.0345  -0.02383  0.06665  0.05322] link-removing-and-rewiring (LRR) f unction Li(·) to change his links. A LRR function is deﬁned as below. Deﬁnition 3The LRR function Li(·) is a function of payoﬀs, whose output is a set with k elements, namely an updated neighbor set Γ t(i) of a player Xi. It is given as below. Γ t(i) = Li ( ˆzt− 1(i) ) = argmaxk j∈ Γ t− 1 (i) S Υ t− 1(i) ({ zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) }) ˆzt− 1(i) = { zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) } , Υ t− 1(i) = ⋃ j∈ Γ + t− 1 (i) Γ t− 1(j) Γ + t− 1(i) = { j|zt− 1(j) ≥ θt− 1(i),j ∈ Γ t− 1(i) } , Γ − t− 1(i) = Γ t− 1(i)\\Γ + t− 1(i) (13) where θt− 1(i) is a payoﬀ threshold, Υ t− 1(i) is called an extended neighbor set, and the function argmaxk(·) is to ﬁnd k neighbors with the ﬁrst k largest payoﬀs in the set Γ t− 1(i) ⋃ Υ t− 1(i). Here, two LRR functions L1 i(·) and L2 i(·) are designed. The function L1 i(·) always observes an extended neighbor set formed by half neighbor s of a data 7point X i, α = ⌈ 0.5 × | Γ t− 1(i)| ⌉ , where the symbol ⌈·⌉ is to take an integer part of a number satisfying\n",
      " > 234 [-0.0879   0.02698 -0.0855   0.0713   0.0719 ] t− 1(i) } , Γ − t− 1(i) = Γ t− 1(i)\\Γ + t− 1(i) (13) where θt− 1(i) is a payoﬀ threshold, Υ t− 1(i) is called an extended neighbor set, and the function argmaxk(·) is to ﬁnd k neighbors with the ﬁrst k largest payoﬀs in the set Γ t− 1(i) ⋃ Υ t− 1(i). Here, two LRR functions L1 i(·) and L2 i(·) are designed. The function L1 i(·) always observes an extended neighbor set formed by half neighbor s of a data 7point X i, α = ⌈ 0.5 × | Γ t− 1(i)| ⌉ , where the symbol ⌈·⌉ is to take an integer part of a number satisfying the integer part is no larger than the nu mber. Next, the payoﬀ threshold θ1 t− 1(i) is set by θ1 t− 1(i) = findα ({zt− 1(i),j ∈ Γ t− 1(i)}), where the function findα (·) is to ﬁnd the α-th largest payoﬀ in a set that contains all neighbors’ payoﬀs of the data point. When the LRR fun ction L1 i(·) is applied, the links connecting to the neighbors with small payoﬀs are removed and meanwhile new links are created between the data point and foun d players with higher payoﬀs. Hence, according to Eq.(13), the\n",
      " > 235 [-0.06058  0.03226 -0.1069   0.0605   0.05994] satisfying the integer part is no larger than the nu mber. Next, the payoﬀ threshold θ1 t− 1(i) is set by θ1 t− 1(i) = findα ({zt− 1(i),j ∈ Γ t− 1(i)}), where the function findα (·) is to ﬁnd the α-th largest payoﬀ in a set that contains all neighbors’ payoﬀs of the data point. When the LRR fun ction L1 i(·) is applied, the links connecting to the neighbors with small payoﬀs are removed and meanwhile new links are created between the data point and foun d players with higher payoﬀs. Hence, according to Eq.(13), the new neighbor set is Γ t(i) = L1 i(ˆzt− 1(i)). Unlike the LRR function L1 i(·), the LRR function L2 i(·) adjusts the number of neighbors dynamically instead of the constant number of neighbo rs in L1 i(·). Therefore, the payoﬀ threshold θ2 t− 1(i) takes the average of neighbors’ payoﬀs, θ2 t− 1(i) = ∑ j∈ Γ t− 1(i) zt− 1(i)/ |Γ t− 1(i)|. Next, the set Γ + t− 1(i) is formed according to Eq.(13), Γ + t− 1(i) = {j|zt− 1(j) ≥ θ2 t− 1(i),j ∈ Γ t− 1(i)}, and then the new neigh- bor set is achieved by means of the LRR\n",
      " > 236 [-0.0826   0.01917 -0.1074   0.0796   0.06616] the new neighbor set is Γ t(i) = L1 i(ˆzt− 1(i)). Unlike the LRR function L1 i(·), the LRR function L2 i(·) adjusts the number of neighbors dynamically instead of the constant number of neighbo rs in L1 i(·). Therefore, the payoﬀ threshold θ2 t− 1(i) takes the average of neighbors’ payoﬀs, θ2 t− 1(i) = ∑ j∈ Γ t− 1(i) zt− 1(i)/ |Γ t− 1(i)|. Next, the set Γ + t− 1(i) is formed according to Eq.(13), Γ + t− 1(i) = {j|zt− 1(j) ≥ θ2 t− 1(i),j ∈ Γ t− 1(i)}, and then the new neigh- bor set is achieved by means of the LRR function L2 i(·), Γ t(i) = L2 i(ˆzt− 1(i)). In the case, when the payoﬀs of all neighbors are equal to the pay oﬀ thresh- old θ2 t− 1(i), the output of the LRR function is Γ t(i) = Γ t− 1(i). This may be viewed as self-protective behavior for avoiding a payoﬀ loss due to n o enough information acquired. The LRR function Li(·) expands the view of a player X i, i.e., it makes him observe payoﬀs of players in the extended neighbor set, which pro vides a chance to ﬁnd players with higher payoﬀs around him. If\n",
      " > 237 [-0.07465  0.02505 -0.0823   0.0894   0.06213] LRR function L2 i(·), Γ t(i) = L2 i(ˆzt− 1(i)). In the case, when the payoﬀs of all neighbors are equal to the pay oﬀ thresh- old θ2 t− 1(i), the output of the LRR function is Γ t(i) = Γ t− 1(i). This may be viewed as self-protective behavior for avoiding a payoﬀ loss due to n o enough information acquired. The LRR function Li(·) expands the view of a player X i, i.e., it makes him observe payoﬀs of players in the extended neighbor set, which pro vides a chance to ﬁnd players with higher payoﬀs around him. If no players with highe r payoﬀs are found in the extended neighbor set, namely min({zt− 1(j),j ∈ Γ t− 1(i)}) ≥ max({zt− 1(h),h ∈ Υ t− 1(i)}), then the output of the LRR function is Γ t(i) = Γ t− 1(i). Otherwise, players with small payoﬀs will be removed together wit h the corresponding links from the neighbor set and link set, and replaced by some found players with higher payoﬀ. This process is repeated till the pa yoﬀs of unlinked players in the extended neighbor set are no larger than tho se of linked neighbors.\n",
      " > 238 [-0.05978   0.014496 -0.08575   0.08246   0.06192 ] If no players with highe r payoﬀs are found in the extended neighbor set, namely min({zt− 1(j),j ∈ Γ t− 1(i)}) ≥ max({zt− 1(h),h ∈ Υ t− 1(i)}), then the output of the LRR function is Γ t(i) = Γ t− 1(i). Otherwise, players with small payoﬀs will be removed together wit h the corresponding links from the neighbor set and link set, and replaced by some found players with higher payoﬀ. This process is repeated till the pa yoﬀs of unlinked players in the extended neighbor set are no larger than tho se of linked neighbors. Since the links among players, namely the link set E0 in the network G0(X ,E 0,d ), are changed by the LRR function, the network Gt(X ,E t,d ) has begun to evolve over time, when t≥ 1. Gt(X ,E t,d ) =                X (t) = { X i(t),i = 1 , 2, · · · ,N } Γ t(i) = Li(ˆzt− 1(i)) Et = ⋃ N i=1 Et(i) Et(i) = { et ( X i, X j ) | j ∈ Γ t(i) } (14) 3.3 Strength of links updating After the LRR function is applied, the strength of links of players ne eds to be formed and adjusted. The new strength\n",
      " > 239 [-0.0468    0.002335 -0.0671    0.0716    0.0494  ] neighbors. Since the links among players, namely the link set E0 in the network G0(X ,E 0,d ), are changed by the LRR function, the network Gt(X ,E t,d ) has begun to evolve over time, when t≥ 1. Gt(X ,E t,d ) =                X (t) = { X i(t),i = 1 , 2, · · · ,N } Γ t(i) = Li(ˆzt− 1(i)) Et = ⋃ N i=1 Et(i) Et(i) = { et ( X i, X j ) | j ∈ Γ t(i) } (14) 3.3 Strength of links updating After the LRR function is applied, the strength of links of players ne eds to be formed and adjusted. The new strength of links of a player X i ∈ X is formed by means of the below formulation. ρt(X i, X j ) =      P h∈ Γ t− 1 (i)\\{ Γ t− 1(i) T Γ t(i)} ρt− 1 (X i, X h) ⏐ ⏐ ⏐Γ t(i)\\ { Γ t− 1(i) T Γ t(i) }⏐ ⏐ ⏐ j ∈ Γ t(i)\\ { Γ t− 1(i) ⋂ Γ t(i) } ρt− 1(X i, X j ) otherwise (15) 8Then, the player adjusts the strength of links as follows. First, he ﬁnds a neighbor X m with maximal payoﬀ in his neighbor set, m= argmax j∈ Γ t(i) ({ zt− 1(j),j ∈ Γ t(i) }) (16) Next, the strength of link ρt(X i, X j ),j ∈ Γ t(i) is taken its\n",
      " > 240 [-0.05212  0.01674 -0.0628   0.0656   0.04813] strength of links of a player X i ∈ X is formed by means of the below formulation. ρt(X i, X j ) =      P h∈ Γ t− 1 (i)\\{ Γ t− 1(i) T Γ t(i)} ρt− 1 (X i, X h) ⏐ ⏐ ⏐Γ t(i)\\ { Γ t− 1(i) T Γ t(i) }⏐ ⏐ ⏐ j ∈ Γ t(i)\\ { Γ t− 1(i) ⋂ Γ t(i) } ρt− 1(X i, X j ) otherwise (15) 8Then, the player adjusts the strength of links as follows. First, he ﬁnds a neighbor X m with maximal payoﬀ in his neighbor set, m= argmax j∈ Γ t(i) ({ zt− 1(j),j ∈ Γ t(i) }) (16) Next, the strength of link ρt(X i, X j ),j ∈ Γ t(i) is taken its square root and the player X m’s strength of the link becomes negative, { {√ ρt(X i, X j ),j ∈ Γ t(i) } √ ρt(X i, X m) = − √ ρt(X i, X m),m ∈ Γ t(i) (17) Further, let Avet(i) = ( ∑ j∈ Γ t(i) √ ρt(X i, X m))/ |Γ t(i)|, thus, the updated strength of link is ρt(X i, X j ) = ( 2 × Avet(i) − √ ρt(X i, X j ) ) 2 ,j ∈ Γ t(i). (18) The above-mentioned method is a variant of the Grover iteration G in the quantum search algorithm [3], a well-known algorithm in quantum compu tation, which is a way to adjust the probability\n",
      " > 241 [-0.0642   0.03732 -0.08093  0.0672   0.0538 ] square root and the player X m’s strength of the link becomes negative, { {√ ρt(X i, X j ),j ∈ Γ t(i) } √ ρt(X i, X m) = − √ ρt(X i, X m),m ∈ Γ t(i) (17) Further, let Avet(i) = ( ∑ j∈ Γ t(i) √ ρt(X i, X m))/ |Γ t(i)|, thus, the updated strength of link is ρt(X i, X j ) = ( 2 × Avet(i) − √ ρt(X i, X j ) ) 2 ,j ∈ Γ t(i). (18) The above-mentioned method is a variant of the Grover iteration G in the quantum search algorithm [3], a well-known algorithm in quantum compu tation, which is a way to adjust the probability amplitude of each term in a supe rposi- tion state. By adjustment, the probability amplitude of the wanted is increased, while the others are reduced. This whole process may be regarded a s the in- version about average operation [3]. For our case, each strength of link is taken its square root ﬁrst, and then the average Avet(i) of square roots is computed. Finally, all values are inverted about the average. There are three main reasons that we select the modiﬁed Grover iteration to update the strengt h\n",
      " > 242 [-0.05695  0.0171  -0.11914  0.0813   0.056  ] probability amplitude of each term in a supe rposi- tion state. By adjustment, the probability amplitude of the wanted is increased, while the others are reduced. This whole process may be regarded a s the in- version about average operation [3]. For our case, each strength of link is taken its square root ﬁrst, and then the average Avet(i) of square roots is computed. Finally, all values are inverted about the average. There are three main reasons that we select the modiﬁed Grover iteration to update the strengt h of links: (a) the sum of updated strength of links retains one, ∑ j∈ Γ t(i) ρt(X i, X j ) = 1, (b) certain strength of links between a player and his neighbors is much la rger than the others, ρt(X i, X j ) ≫ ρt(X i, X h),h ∈ Γ t(i)\\j, after the strength of links is updated, and (c) it helps players’ payoﬀs to follow a power law distr ibution, in which only a few players’ payoﬀs are far larger than others’ in the end of iterations. Besides, the process that all players adjust their strength is ord er irrelevant,\n",
      " > 243 [-0.0494   0.0378  -0.1124   0.07227  0.02368] h of links: (a) the sum of updated strength of links retains one, ∑ j∈ Γ t(i) ρt(X i, X j ) = 1, (b) certain strength of links between a player and his neighbors is much la rger than the others, ρt(X i, X j ) ≫ ρt(X i, X h),h ∈ Γ t(i)\\j, after the strength of links is updated, and (c) it helps players’ payoﬀs to follow a power law distr ibution, in which only a few players’ payoﬀs are far larger than others’ in the end of iterations. Besides, the process that all players adjust their strength is ord er irrelevant, because the strength of links of all players is updated synchronou sly, and the network is a directed network, so the strength cannot be overrid den by other players. When the strength of links of each player has been update d, an iteration is completed. In conclusion, when t≥ 1 , the structure of network representing connections among players begins to evolve over time. 4 Discussions In the section, ﬁrstly, the relationship between the number of nea rest neigh- bors and the number of clusters is discussed,\n",
      " > 244 [-0.03946  0.02458 -0.1055   0.02942  0.03824] irrelevant, because the strength of links of all players is updated synchronou sly, and the network is a directed network, so the strength cannot be overrid den by other players. When the strength of links of each player has been update d, an iteration is completed. In conclusion, when t≥ 1 , the structure of network representing connections among players begins to evolve over time. 4 Discussions In the section, ﬁrstly, the relationship between the number of nea rest neigh- bors and the number of clusters is discussed, and then how the cos t in the SD-like payoﬀ matrix inﬂuences the results is analyzed, which provide s a way to choose the proportional factor. Finally, the total payoﬀs based on two diﬀerent payoﬀ matrices are compared and the relationship between the tot al payoﬀs and the rates of convergence of algorithms is explained. 94.1 Number of nearest neighbors vs. number of clusters The number k of nearest neighbors represents the number of neighbors to which a data point (player) X i ∈ X connects. For a dataset,\n",
      " > 245 [-0.0488   0.01628 -0.0905   0.03418  0.0624 ] discussed, and then how the cos t in the SD-like payoﬀ matrix inﬂuences the results is analyzed, which provide s a way to choose the proportional factor. Finally, the total payoﬀs based on two diﬀerent payoﬀ matrices are compared and the relationship between the tot al payoﬀs and the rates of convergence of algorithms is explained. 94.1 Number of nearest neighbors vs. number of clusters The number k of nearest neighbors represents the number of neighbors to which a data point (player) X i ∈ X connects. For a dataset, the number k of nearest neighbors determines the number of clusters in part. G enerally speaking, the number of clusters decreases inversely with the num ber k of nearest neighbors. For example, when the number k of nearest neighbors is small, it is indicated that the player X i connects to only a few neighbors. At this time only those not-too-distance neighbors can be observed by the LRR fu nction, which means that the elements in the union of the extended neighbor set Υ t− 1(i) and the neighbor set Γ\n",
      " > 246 [-0.06726  0.0423  -0.0906   0.0815   0.0482 ] dataset, the number k of nearest neighbors determines the number of clusters in part. G enerally speaking, the number of clusters decreases inversely with the num ber k of nearest neighbors. For example, when the number k of nearest neighbors is small, it is indicated that the player X i connects to only a few neighbors. At this time only those not-too-distance neighbors can be observed by the LRR fu nction, which means that the elements in the union of the extended neighbor set Υ t− 1(i) and the neighbor set Γ t− 1(i) are few. Therefore, when the evolution of the network formed by players is ended, many small clusters are established amo ng data points. On the other hand, a big number k of nearest neighbors provides more neighbors for each player, as speciﬁes that the cardinality of the u nion is larger than that when a small k is taken. This means that more neighbors can be observed and explored by the LRR function, so that big clusters co ntaining more data points are formed. For a dataset, the clustering results\n",
      " > 247 [-0.06223   0.04175  -0.0624    0.0681    0.007015] Γ t− 1(i) are few. Therefore, when the evolution of the network formed by players is ended, many small clusters are established amo ng data points. On the other hand, a big number k of nearest neighbors provides more neighbors for each player, as speciﬁes that the cardinality of the u nion is larger than that when a small k is taken. This means that more neighbors can be observed and explored by the LRR function, so that big clusters co ntaining more data points are formed. For a dataset, the clustering results at the diﬀerent number k of nearest neighbors have been illustrated in Fig. 2, in which each data point only c onnects to one of its neighbors who has the largest strength of link, and clus ters are represented by diﬀerent signs. As is shown in Fig. 2, it can be found t hat only a few data points receive considerable links, whereas most of da ta points have only one link. This implies that when the structure of network te nds to stability, the network, if only the links with the largest strength are remained,\n",
      " > 248 [-0.0652   0.02711 -0.0628   0.05753  0.04364] results at the diﬀerent number k of nearest neighbors have been illustrated in Fig. 2, in which each data point only c onnects to one of its neighbors who has the largest strength of link, and clus ters are represented by diﬀerent signs. As is shown in Fig. 2, it can be found t hat only a few data points receive considerable links, whereas most of da ta points have only one link. This implies that when the structure of network te nds to stability, the network, if only the links with the largest strength are remained, is characterized by the scale-free network [29], i.e., winner takes all. Besides, in Fig. 2(a), six clusters are obtained by the clustering algorithm, whe n k= 9. As the number k of nearest neighbors rises, four clusters are obtained when k= 12, three clusters when k= 16. So, if the exact number of clusters is not known in advance, diﬀerent numbers of clusters may be achieved by adjust ing the number of nearest neighbors in practice. −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (a) k = 9 −5 −4 −3\n",
      " > 249 [-0.0431    0.011086 -0.07      0.0521    0.05194 ] remained, is characterized by the scale-free network [29], i.e., winner takes all. Besides, in Fig. 2(a), six clusters are obtained by the clustering algorithm, whe n k= 9. As the number k of nearest neighbors rises, four clusters are obtained when k= 12, three clusters when k= 16. So, if the exact number of clusters is not known in advance, diﬀerent numbers of clusters may be achieved by adjust ing the number of nearest neighbors in practice. −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (a) k = 9 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (b) k = 12 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (c) k = 16 Figure 2: The number of nearest neighbors vs. number of clusters . (a) six clusters are obtained, when the number of nearest neighbors is k = 9. (b) four clusters, when k= 12. (c) three clusters, when k= 16 4.2 Eﬀect of the cost c in the SD-like payoﬀ matrix In the Snowdrift game, if the cost is too high, the SD-like payoﬀ matr ix recovers the PD-like payoﬀ matrix [28]. Therefore, the proportio\n",
      " > 250 [-0.02525  0.04828 -0.0406   0.045    0.06934] −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (b) k = 12 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (c) k = 16 Figure 2: The number of nearest neighbors vs. number of clusters . (a) six clusters are obtained, when the number of nearest neighbors is k = 9. (b) four clusters, when k= 12. (c) three clusters, when k= 16 4.2 Eﬀect of the cost c in the SD-like payoﬀ matrix In the Snowdrift game, if the cost is too high, the SD-like payoﬀ matr ix recovers the PD-like payoﬀ matrix [28]. Therefore, the proportio nal factor β is restricted in an interval (0 , 0.5]. However, diﬀerent costs will bring about 10the changes of the payoﬀ matrix, which means that diﬀerent cluste ring results will be produced even in the same algorithm. Figure 3 illustrates how th e clustering results change at the diﬀerent number k of nearest neighbors when the proportional factor β takes diﬀerent values, in which the clustering results are represented by clustering accuracies. The deﬁnition of cluste ring accuracy is given below. Deﬁnition\n",
      " > 251 [ 0.01159  0.03467 -0.04495  0.01825  0.03207] proportio nal factor β is restricted in an interval (0 , 0.5]. However, diﬀerent costs will bring about 10the changes of the payoﬀ matrix, which means that diﬀerent cluste ring results will be produced even in the same algorithm. Figure 3 illustrates how th e clustering results change at the diﬀerent number k of nearest neighbors when the proportional factor β takes diﬀerent values, in which the clustering results are represented by clustering accuracies. The deﬁnition of cluste ring accuracy is given below. Deﬁnition 4clusteri is the label which is assigned to a data point Xi in a dataset by the algorithm, and labeli is the actual label of the data point Xi in the dataset. So the clustering accuracy is [30]: accuracy = PN i=1 λ ( map(clusteri ),label i ) N λ(map(clusteri),label i) = { 1 if map(clusteri) = labeli 0 otherwise (19) where the mapping function map(·) maps the label got by the algorithm to the actual label. Clustering accuracy is an important evaluation criterion for clustering algo- rithms, which reﬂects\n",
      " > 252 [-0.02556  0.04123 -0.04095  0.03128  0.0486 ] Deﬁnition 4clusteri is the label which is assigned to a data point Xi in a dataset by the algorithm, and labeli is the actual label of the data point Xi in the dataset. So the clustering accuracy is [30]: accuracy = PN i=1 λ ( map(clusteri ),label i ) N λ(map(clusteri),label i) = { 1 if map(clusteri) = labeli 0 otherwise (19) where the mapping function map(·) maps the label got by the algorithm to the actual label. Clustering accuracy is an important evaluation criterion for clustering algo- rithms, which reﬂects the level of matches between the actual lab els in a dataset and the labels assigned by a clustering algorithm, so that the goal of a clustering algorithm is to obtain higher clustering accuracies. As is shown in Figure 3, it can be seen that similar results are obtained b y the algorithm at diﬀerent costs, and the best results are produce d when k = 7 and k= 8, but from the Figure 3(b), the clustering result with the largest mean and the least variance is yielded when β = 0 .3. Also, as mentioned above, the\n",
      " > 253 [-0.01267  0.0239  -0.04813  0.0641   0.05234] reﬂects the level of matches between the actual lab els in a dataset and the labels assigned by a clustering algorithm, so that the goal of a clustering algorithm is to obtain higher clustering accuracies. As is shown in Figure 3, it can be seen that similar results are obtained b y the algorithm at diﬀerent costs, and the best results are produce d when k = 7 and k= 8, but from the Figure 3(b), the clustering result with the largest mean and the least variance is yielded when β = 0 .3. Also, as mentioned above, the high cost leads to the recovery of the SD-like payoﬀ matrix, so the p roportional factor β = 0 .2 or β = 0 .3 is recommended. 4 5 6 7 8 9 10 11 12 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy beta=0.1 beta=0.2 beta=0.3 beta=0.4 beta=0.5 (a) 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.8 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 1 proportional factor beta mean and variance of results (b) Figure 3: The eﬀect of the cost for the clustering results.\n",
      " > 254 [-0.011444  0.01617  -0.0486    0.04156   0.04672 ] the high cost leads to the recovery of the SD-like payoﬀ matrix, so the p roportional factor β = 0 .2 or β = 0 .3 is recommended. 4 5 6 7 8 9 10 11 12 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy beta=0.1 beta=0.2 beta=0.3 beta=0.4 beta=0.5 (a) 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.8 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 1 proportional factor beta mean and variance of results (b) Figure 3: The eﬀect of the cost for the clustering results. (a) the results of the algorithm using the SD-like payoﬀ matrix at diﬀerent number k of nearest neighbors. (b) the mean and variance corresponding to each curv e in (a). 4.3 Total payoﬀs and the rate of convergence In this subsection, at ﬁrst, the total payoﬀs of algorithms using t he PD- or SD-like payoﬀ matrix are compared respectively, and then the diﬀer ences be- tween total payoﬀs are explained. Later, the rates of converge nce of algorithms 11are discussed when two LRR functions are applied respectively,\n",
      " > 255 [-0.04694  0.01008 -0.0645   0.02092  0.04834] results. (a) the results of the algorithm using the SD-like payoﬀ matrix at diﬀerent number k of nearest neighbors. (b) the mean and variance corresponding to each curv e in (a). 4.3 Total payoﬀs and the rate of convergence In this subsection, at ﬁrst, the total payoﬀs of algorithms using t he PD- or SD-like payoﬀ matrix are compared respectively, and then the diﬀer ences be- tween total payoﬀs are explained. Later, the rates of converge nce of algorithms 11are discussed when two LRR functions are applied respectively, and further the impact for the rates of convergence is analyzed in two payoﬀ matric es. If all other conditions are ﬁxed, an algorithm will form two versions d ue to using PD- or SD-like payoﬀ matrix, and naturally this will bring diﬀerent results. As compared with the PD-like payoﬀ matrix, the payoﬀ P and S in the SD-like payoﬀ matrix have a reverse order in the payoﬀ inequality. In all algo rithms, the relationship between the total payoﬀs and the number of iteration s is drawn in Figure 4. From Figure\n",
      " > 256 [-0.04022  0.02403 -0.04944  0.03192  0.04037] respectively, and further the impact for the rates of convergence is analyzed in two payoﬀ matric es. If all other conditions are ﬁxed, an algorithm will form two versions d ue to using PD- or SD-like payoﬀ matrix, and naturally this will bring diﬀerent results. As compared with the PD-like payoﬀ matrix, the payoﬀ P and S in the SD-like payoﬀ matrix have a reverse order in the payoﬀ inequality. In all algo rithms, the relationship between the total payoﬀs and the number of iteration s is drawn in Figure 4. From Figure 4, it can be found that the total payoﬀs in the algorithms with SD-like payoﬀ matrix are larger than that of the algorithms with P D-like payoﬀ matrix no matter which LRR function is selected. 1 2 3 4 5 6 7 8 9 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1(a) 1 2 3 4 5 6 7 8 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Figure 4: The total payoﬀs vs. the rates of convergence. (a) to\n",
      " > 257 [-0.01624   0.00993  -0.03186   0.014305  0.05258 ] Figure 4, it can be found that the total payoﬀs in the algorithms with SD-like payoﬀ matrix are larger than that of the algorithms with P D-like payoﬀ matrix no matter which LRR function is selected. 1 2 3 4 5 6 7 8 9 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1(a) 1 2 3 4 5 6 7 8 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Figure 4: The total payoﬀs vs. the rates of convergence. (a) to tal payoﬀs of algorithms in the case of LRR function L1 i(·), (b) total payoﬀs of algorithms in the case of LRR function L2 i(·) Remark 1 The algorithms are named as follows. For example, the name of an algorithm, QGC1PDL1, denotes that the Case 1, PD-like payoﬀ matrix and the LRR function L1 i(·) are employed in this algorithm. According to two payoﬀ matrices, using Eq.(11), each player’s expe cted pay- oﬀ can be calculated in two cases of strategies respectively as below . Case 1: PD : zt(X i, X j ) = { 1\n",
      " > 258 [-0.01278  0.0237  -0.02708  0.00711  0.05072] to tal payoﬀs of algorithms in the case of LRR function L1 i(·), (b) total payoﬀs of algorithms in the case of LRR function L2 i(·) Remark 1 The algorithms are named as follows. For example, the name of an algorithm, QGC1PDL1, denotes that the Case 1, PD-like payoﬀ matrix and the LRR function L1 i(·) are employed in this algorithm. According to two payoﬀ matrices, using Eq.(11), each player’s expe cted pay- oﬀ can be calculated in two cases of strategies respectively as below . Case 1: PD : zt(X i, X j ) = { 1 4 (0.6ω + 0.01ω + ω + 0.2ω) = 0 .4525ω 1 2 (0.6ω + 0.01ω) = 0 .305ω (20) SD : zt(X i, X j ) = { 1 4 (ω − c 2 + ω − c+ ω + 0.01ω) = 1 4 (3.01 − 3α 2 )ω 1 2 (ω − c 2 + ω − c) = 1 2 (2 − 3α 2 )ω (21) Case 2: PD : zt(X i, X j ) =      ρ1ρ20.6ω + ρ2(1 − ρ1)0.01ω +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.2ω (1 − ρ1)0.6ω + ρ10.01ω (22) SD : zt(X i, X j ) =      ρ1ρ2(ω − c 2 ) + ρ2(1 − ρ1)(ω − c) +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.01ω (1 − ρ1)(ω − c 2 ) + ρ1(ω − c) (23) 12Comparing the expected payoﬀs in two cases,\n",
      " > 259 [-0.01182   0.0205   -0.05157  -0.003933  0.0497  ] 1 4 (0.6ω + 0.01ω + ω + 0.2ω) = 0 .4525ω 1 2 (0.6ω + 0.01ω) = 0 .305ω (20) SD : zt(X i, X j ) = { 1 4 (ω − c 2 + ω − c+ ω + 0.01ω) = 1 4 (3.01 − 3α 2 )ω 1 2 (ω − c 2 + ω − c) = 1 2 (2 − 3α 2 )ω (21) Case 2: PD : zt(X i, X j ) =      ρ1ρ20.6ω + ρ2(1 − ρ1)0.01ω +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.2ω (1 − ρ1)0.6ω + ρ10.01ω (22) SD : zt(X i, X j ) =      ρ1ρ2(ω − c 2 ) + ρ2(1 − ρ1)(ω − c) +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.01ω (1 − ρ1)(ω − c 2 ) + ρ1(ω − c) (23) 12Comparing the expected payoﬀs in two cases, it can be observed th at when the SD-like payoﬀ matrix is used, the expected payoﬀ is larger than t hat of using PD-like payoﬀ matrix regardless of cases of strategies. Therefor e, this explains why diﬀerences between total payoﬀs are produced. Besides, Figure 4 not only describes the changes of total payoﬀs o f algo- rithms, but also reﬂects the rates of convergence of algorithms. When the total payoﬀs remain constant or ﬂuctuate slightly, this means that the a lgorithms have converged. At this time, players\n",
      " > 260 [-0.05978  0.01567 -0.0872   0.04788  0.0709 ] cases, it can be observed th at when the SD-like payoﬀ matrix is used, the expected payoﬀ is larger than t hat of using PD-like payoﬀ matrix regardless of cases of strategies. Therefor e, this explains why diﬀerences between total payoﬀs are produced. Besides, Figure 4 not only describes the changes of total payoﬀs o f algo- rithms, but also reﬂects the rates of convergence of algorithms. When the total payoﬀs remain constant or ﬂuctuate slightly, this means that the a lgorithms have converged. At this time, players do not frequently apply the L RR function to change his neighbors but reach a stable state. As mentioned in th e section 3.2, the LRR function L2 i(·) only can observe an extended neighbor set formed by those larger-than-average neighbors in contrast to an exten ded neighbor set built by half neighbors in the LRR function L1 i(·). Generally speaking, for the same k, the median of payoﬀs is smaller than or equal to the mean, i.e., θ1 t− 1 ≤ θ2 t− 1, which means that the exploring area of the LRR function L1\n",
      " > 261 [-0.0571   0.02142 -0.08734  0.07635  0.06256] players do not frequently apply the L RR function to change his neighbors but reach a stable state. As mentioned in th e section 3.2, the LRR function L2 i(·) only can observe an extended neighbor set formed by those larger-than-average neighbors in contrast to an exten ded neighbor set built by half neighbors in the LRR function L1 i(·). Generally speaking, for the same k, the median of payoﬀs is smaller than or equal to the mean, i.e., θ1 t− 1 ≤ θ2 t− 1, which means that the exploring area of the LRR function L1 i(·) is larger than that of the LRR function L2 i(·). So, as a whole, the algorithms with the LRR function L2 i(·) are slightly faster than that with the LRR function L1 i(·), i.e., the number of iterations that the former type of algorithms n eeds is a little less. Furthermore, in the algorithms, a phenomenon that the strategie s ˆH and ˆFt− 1 are more likely used by players in a high density area while the strategy ˆD is used by those in a low density area is always observed. This is becaus e usually they\n",
      " > 262 [-0.03546  0.01458 -0.06433  0.05923  0.04   ] L1 i(·) is larger than that of the LRR function L2 i(·). So, as a whole, the algorithms with the LRR function L2 i(·) are slightly faster than that with the LRR function L1 i(·), i.e., the number of iterations that the former type of algorithms n eeds is a little less. Furthermore, in the algorithms, a phenomenon that the strategie s ˆH and ˆFt− 1 are more likely used by players in a high density area while the strategy ˆD is used by those in a low density area is always observed. This is becaus e usually they are mutually neighbors in the high density area on the weig hted and directed knn network, but in the low density area this case is rev erse. As a result, the diﬀerences of payoﬀs between the high density and low d ensity areas are enlarged rapidly for the expected payoﬀ in the strategy proﬁle ( ˆH, ˆH) or ( ˆFt− 1, ˆFt− 1) is higher than that in other strategy proﬁle, and this also cause th e distribution of players’ payoﬀs follows a power-law distribution, whic h is why algorithms converge fast. 5 Simulations\n",
      " > 263 [-0.02345  0.04007 -0.0922   0.0638   0.02089] they are mutually neighbors in the high density area on the weig hted and directed knn network, but in the low density area this case is rev erse. As a result, the diﬀerences of payoﬀs between the high density and low d ensity areas are enlarged rapidly for the expected payoﬀ in the strategy proﬁle ( ˆH, ˆH) or ( ˆFt− 1, ˆFt− 1) is higher than that in other strategy proﬁle, and this also cause th e distribution of players’ payoﬀs follows a power-law distribution, whic h is why algorithms converge fast. 5 Simulations To evaluate these clustering algorithms, six datasets are selected from UCI repository [31], which are Soybean, Iris, Wine, Sonar, Ionosphere and Breast cancer Wisconsin datasets, and complete the simulations on them. I n this sec- tion, ﬁrstly these datasets are brieﬂy introduced, and then the s imulation results are demonstrated. The original data points in above datasets all are scattered in high d imen- sional spaces spanned by their features which are the individual me asurable heuristic properties\n",
      " > 264 [-0.05145  0.02606 -0.0673   0.05182 -0.00839] Simulations To evaluate these clustering algorithms, six datasets are selected from UCI repository [31], which are Soybean, Iris, Wine, Sonar, Ionosphere and Breast cancer Wisconsin datasets, and complete the simulations on them. I n this sec- tion, ﬁrstly these datasets are brieﬂy introduced, and then the s imulation results are demonstrated. The original data points in above datasets all are scattered in high d imen- sional spaces spanned by their features which are the individual me asurable heuristic properties of the phenomena being observed, where the description of all datasets is summarized in Table 4. As for Breast dataset, some lo st features are replaced by random numbers, and the Wine dataset is standard ized. Finally, the algorithms are coded in Matlab 6.5. Throughout all simulations, data points in a dataset are viewed as pla yers in quantum games whose initial positions are taken from the dataset . Next, the initial network representing relations among data points are creat ed according to Def.1, after\n",
      " > 265 [-0.05618   0.004986 -0.0677    0.01057   0.00868 ] properties of the phenomena being observed, where the description of all datasets is summarized in Table 4. As for Breast dataset, some lo st features are replaced by random numbers, and the Wine dataset is standard ized. Finally, the algorithms are coded in Matlab 6.5. Throughout all simulations, data points in a dataset are viewed as pla yers in quantum games whose initial positions are taken from the dataset . Next, the initial network representing relations among data points are creat ed according to Def.1, after a distance function is selected, which only needs to s atisfy that the more similar data points are, the smaller the output of the funct ion is. In 13Table 4: Description of datasets. Dataset Instances Features classes Soybean 47 21 4 Iris 150 4 3 Wine 178 13 3 Sonar 208 60 2 Ionosphere 351 32 2 Breast 699 9 2 the simulations, the distance function is employed as following d ( X i, X j ) = exp ( ∥X i − X j ∥/ 2σ2 ) ,i,j = 1 , 2, · · · ,N (24) where the symbol ∥ · ∥ represents L2-norm. The advantage of this\n",
      " > 266 [-0.05197  0.02669 -0.0707   0.01967  0.0706 ] after a distance function is selected, which only needs to s atisfy that the more similar data points are, the smaller the output of the funct ion is. In 13Table 4: Description of datasets. Dataset Instances Features classes Soybean 47 21 4 Iris 150 4 3 Wine 178 13 3 Sonar 208 60 2 Ionosphere 351 32 2 Breast 699 9 2 the simulations, the distance function is employed as following d ( X i, X j ) = exp ( ∥X i − X j ∥/ 2σ2 ) ,i,j = 1 , 2, · · · ,N (24) where the symbol ∥ · ∥ represents L2-norm. The advantage of this function is that it not only satisﬁes our requirements, but also overcomes the drawbacks of Euclidean distance. For instance, when two points are very close, t he output of Euclidean distance function approaches zero, which may make the c omputation of payoﬀ fail due to the payoﬀ approaching inﬁnite. Nevertheless, when Eq.(24) is selected as the distance function, it is more convenient to comput e the players’ payoﬀs, since its minimum is one and the reciprocals of its output are b etween zero and one, 1 /d\n",
      " > 267 [-0.05753  0.0321  -0.08344  0.03574  0.0777 ] this function is that it not only satisﬁes our requirements, but also overcomes the drawbacks of Euclidean distance. For instance, when two points are very close, t he output of Euclidean distance function approaches zero, which may make the c omputation of payoﬀ fail due to the payoﬀ approaching inﬁnite. Nevertheless, when Eq.(24) is selected as the distance function, it is more convenient to comput e the players’ payoﬀs, since its minimum is one and the reciprocals of its output are b etween zero and one, 1 /d (X i, X j ) ∈ [0, 1]. In addition, the distance between a player X i and itself, d(X i, X i), is one according to the deﬁned distance function, which means that initially he is one of his k nearest neighbors. So there is an edge between the player X i and himself, namely a self-loop. Additionally, the parameter σ in Eq.(24) takes one. As is analyzed in the section 4.2, the cost c in SD-like payoﬀ matrix is set by c= 0 .2ωt(X i, X j ) in the related clustering algorithms. The clustering algorithms are applied\n",
      " > 268 [-0.0498   0.01613 -0.0744   0.03592  0.05798] /d (X i, X j ) ∈ [0, 1]. In addition, the distance between a player X i and itself, d(X i, X i), is one according to the deﬁned distance function, which means that initially he is one of his k nearest neighbors. So there is an edge between the player X i and himself, namely a self-loop. Additionally, the parameter σ in Eq.(24) takes one. As is analyzed in the section 4.2, the cost c in SD-like payoﬀ matrix is set by c= 0 .2ωt(X i, X j ) in the related clustering algorithms. The clustering algorithms are applied on the six datasets respective ly. Be- cause two cases of strategies are designed and the diﬀerent payo ﬀ matrices and LRR functions are employed, the algorithms are run on every datas et at the diﬀerent number k of nearest neighbors. As is analyzed in section 4.1, for a dataset the number k of clusters decreases inversely with the number of nearest neighbors. When a small k is selected, it is possible that the number of clusters is larger than the preset number of the dataset, after the algorit hm is ended.\n",
      " > 269 [-0.0327   0.04266 -0.094    0.08484  0.01945] applied on the six datasets respective ly. Be- cause two cases of strategies are designed and the diﬀerent payo ﬀ matrices and LRR functions are employed, the algorithms are run on every datas et at the diﬀerent number k of nearest neighbors. As is analyzed in section 4.1, for a dataset the number k of clusters decreases inversely with the number of nearest neighbors. When a small k is selected, it is possible that the number of clusters is larger than the preset number of the dataset, after the algorit hm is ended. So a merging-subroutine is called to merge unwanted clusters, which wo rks in this way. At ﬁrst, the cluster with the fewest data points is identiﬁed, a nd then it is merged to the cluster whose distance between their centroids is sm allest. This subroutine is repeated till the number of clusters is equal to the pr eset number. The clustering results obtained by these algorithms are compared in Fig. 5, in which each point represents a clustering accuracy. As is shown in F ig. 5, the similar results are obtained\n",
      " > 270 [-0.02641  0.04538 -0.06866  0.06006  0.02823] ended. So a merging-subroutine is called to merge unwanted clusters, which wo rks in this way. At ﬁrst, the cluster with the fewest data points is identiﬁed, a nd then it is merged to the cluster whose distance between their centroids is sm allest. This subroutine is repeated till the number of clusters is equal to the pr eset number. The clustering results obtained by these algorithms are compared in Fig. 5, in which each point represents a clustering accuracy. As is shown in F ig. 5, the similar results are obtained by these algorithms at diﬀerent number o f nearest neighbors, but almost all the best results are obtained by the algor ithms using the LRR function L1 i(·). Further, we show a simple comparison with three other algorithms: K means [32, 33], PCA-Kmeans [33], LDA-Km [33]. The Kmeans algorithm is a popular clu s- tering algorithm because it is easy to implement. It begins with k randomly- chosen cluster centers, and then assigns each data point in a data set to the closest cluster center. Next, the cluster\n",
      " > 271 [-0.02725  0.0492  -0.04608  0.0338   0.03363] obtained by these algorithms at diﬀerent number o f nearest neighbors, but almost all the best results are obtained by the algor ithms using the LRR function L1 i(·). Further, we show a simple comparison with three other algorithms: K means [32, 33], PCA-Kmeans [33], LDA-Km [33]. The Kmeans algorithm is a popular clu s- tering algorithm because it is easy to implement. It begins with k randomly- chosen cluster centers, and then assigns each data point in a data set to the closest cluster center. Next, the cluster centers are recomput ed according to the current cluster memberships. This process will be repeated till a co nvergence 142 2.5 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(a) Soybean dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b)\n",
      " > 272 [-0.02693  0.05746 -0.0764   0.05893  0.0319 ] cluster centers are recomput ed according to the current cluster memberships. This process will be repeated till a co nvergence 142 2.5 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(a) Soybean dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Iris dataset 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(c) Wine dataset 3 3.5 4 4.5 5 5.5 6 6.5 7 7.5 8 0.4 0.42 0.44 0.46 0.48 0.5 0.52 0.54 0.56 0.58 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(d) Sonar dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 number of nearest neighbors\n",
      " > 273 [ 0.013855  0.08435  -0.029     0.01504   0.04208 ] QGC2SDL2(b) Iris dataset 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(c) Wine dataset 3 3.5 4 4.5 5 5.5 6 6.5 7 7.5 8 0.4 0.42 0.44 0.46 0.48 0.5 0.52 0.54 0.56 0.58 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(d) Sonar dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(e) Ionosphere dataset 3 4 5 6 7 8 9 10 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(f) breast dataset Figure 5: Comparison of clustering accuracies at diﬀerent k in all proposed algorithms. criterion is met. However, its major problem is sensitive to the selection of the initial partition [19]. The PCA-Kmeans algorithm consists\n",
      " > 274 [-0.001963  0.07776  -0.03616   0.03105   0.05383 ] neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(e) Ionosphere dataset 3 4 5 6 7 8 9 10 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(f) breast dataset Figure 5: Comparison of clustering accuracies at diﬀerent k in all proposed algorithms. criterion is met. However, its major problem is sensitive to the selection of the initial partition [19]. The PCA-Kmeans algorithm consists of two steps : (1) Re- duce the data dimension by principal component analysis (PCA); (2) Clustering data points by the Kmeans algorithm. Ding et al combine linear discrimin ant analysis (LDA) with the Kmeans algorithm, and construct a new clust ering algorithm called ’LDA-Km’. In the LDA-Km algorithm, Kmeans is used to generate class labels, while LDA is used to do subspace selection. Finally, in the subspace selection process, data points are clustered. Our algorithms are established on the model of\n",
      " > 275 [-0.05267  0.04318 -0.07245  0.06323  0.05487] consists of two steps : (1) Re- duce the data dimension by principal component analysis (PCA); (2) Clustering data points by the Kmeans algorithm. Ding et al combine linear discrimin ant analysis (LDA) with the Kmeans algorithm, and construct a new clust ering algorithm called ’LDA-Km’. In the LDA-Km algorithm, Kmeans is used to generate class labels, while LDA is used to do subspace selection. Finally, in the subspace selection process, data points are clustered. Our algorithms are established on the model of quantum games, so d ata points in datasets are considered as players. This idea is totally diﬀer ent from traditional clustering algorithms, such as Kmeans and its variants, because in traditional clustering algorithms data points for clustering are ﬁxe d, and various functions or methods are designed to ﬁnd cluster centers or sepa rating hyper- planes, whereas in the quantum-game-based clustering algorithms data points (players) themselves choose their clusters, which leads clusters a re formed au- tomatically\n",
      " > 276 [-0.05002  0.05466 -0.0587   0.06683  0.0576 ] of quantum games, so d ata points in datasets are considered as players. This idea is totally diﬀer ent from traditional clustering algorithms, such as Kmeans and its variants, because in traditional clustering algorithms data points for clustering are ﬁxe d, and various functions or methods are designed to ﬁnd cluster centers or sepa rating hyper- planes, whereas in the quantum-game-based clustering algorithms data points (players) themselves choose their clusters, which leads clusters a re formed au- tomatically during quantum games. In conclusion, traditional cluste ring algo- rithms do it from outside, while ours are from inside. Furthermore, o ur algo- rithms do not need to choose cluster centers at beginning, so ther e does not exist the problem that is ”sensitive to the selection of the initial partition” . Besides, distances between data points are commonly used as the measurem ent of their similarities in the Kmeans algorithm and its variants. However, when sim ilar- ities are measured in our algorithms,\n",
      " > 277 [-0.04803  0.04855 -0.06015  0.07086  0.0606 ] tomatically during quantum games. In conclusion, traditional cluste ring algo- rithms do it from outside, while ours are from inside. Furthermore, o ur algo- rithms do not need to choose cluster centers at beginning, so ther e does not exist the problem that is ”sensitive to the selection of the initial partition” . Besides, distances between data points are commonly used as the measurem ent of their similarities in the Kmeans algorithm and its variants. However, when sim ilar- ities are measured in our algorithms, not only distances between dat a points but also their degrees and the strength of links are integrated, wh ich provides more information for the measurement of similarities. Later, accor ding to pay- oﬀs in quantum games, players apply a LRR function to change the st ructure of the network, which makes the clusters emerge. As a result, bet ter clustering accuracies are obtained by our algorithms. Table 5 displays the clustering accuracies of our algorithms and the o ther 15three algorithms using the datasets\n",
      " > 278 [-0.05444  0.05002 -0.04578  0.06946  0.04123] algorithms, not only distances between dat a points but also their degrees and the strength of links are integrated, wh ich provides more information for the measurement of similarities. Later, accor ding to pay- oﬀs in quantum games, players apply a LRR function to change the st ructure of the network, which makes the clusters emerge. As a result, bet ter clustering accuracies are obtained by our algorithms. Table 5 displays the clustering accuracies of our algorithms and the o ther 15three algorithms using the datasets in Table 4. It can be observed t hat on almost all datasets the quantum game based clustering algorithms h ave the best clustering accuracies. Only on the Iris dataset, the LDA-Km a lgorithm is better than ours, but our result is close to it as well. The Iris datase t contains three clusters, one of which is far from the other two, so data poin ts in it can be clustered easily and correctly. The other clusters in the Iris dataset, however, are mixed partly in their boundaries, which brings a diﬃculty for\n",
      " > 279 [-0.04254  0.0638  -0.03708  0.05493  0.06464] datasets in Table 4. It can be observed t hat on almost all datasets the quantum game based clustering algorithms h ave the best clustering accuracies. Only on the Iris dataset, the LDA-Km a lgorithm is better than ours, but our result is close to it as well. The Iris datase t contains three clusters, one of which is far from the other two, so data poin ts in it can be clustered easily and correctly. The other clusters in the Iris dataset, however, are mixed partly in their boundaries, which brings a diﬃculty for clustering. These mixed boundary points may be assigned to diﬀeren t clusters by algorithms, which is why the clustering accuracies of algorithms ar e various. It is more diﬃcult to cluster data points in the Sonar and Ionosphere dataset, because in these two datasets plenty of data points belonging to diﬀ erent clusters are mixed together. Therefore, the clustering accuracies of algo rithms in them are not high, and it is rather hard to improve the clustering accurac ies even by several percents. From the\n",
      " > 280 [-0.04065  0.05505 -0.05447  0.03552  0.05884] for clustering. These mixed boundary points may be assigned to diﬀeren t clusters by algorithms, which is why the clustering accuracies of algorithms ar e various. It is more diﬃcult to cluster data points in the Sonar and Ionosphere dataset, because in these two datasets plenty of data points belonging to diﬀ erent clusters are mixed together. Therefore, the clustering accuracies of algo rithms in them are not high, and it is rather hard to improve the clustering accurac ies even by several percents. From the ﬁfth and sixth columns in Table 5, it c an be seen that the quantum game based clustering algorithms are bette r than other algorithms, which indicates the eﬀectiveness of our algorithms. Table 5: Comparison of clustering accuracies of algorithms. Algorithm Soybean Iris Wine Sonar Ionosphere Breast QGC1PDL1 97.9% 92.0% 94.9% 54.8% 75.5% 95.4% QGC1SDL1 95.6% 90.7% 96.6% 56.3% 74.1% 95.4% QGC2PDL1 95.6% 91.3% 96.6% 55.8% 73.8% 95.4% QGC2SDL1 89.4% 91.3% 96.6% 55.8% 75.5% 95.3% QGC1PDL2 95.8% 96.7% 95.5% 54.3%\n",
      " > 281 [-0.0347   0.05264 -0.02736  0.022    0.0705 ] the ﬁfth and sixth columns in Table 5, it c an be seen that the quantum game based clustering algorithms are bette r than other algorithms, which indicates the eﬀectiveness of our algorithms. Table 5: Comparison of clustering accuracies of algorithms. Algorithm Soybean Iris Wine Sonar Ionosphere Breast QGC1PDL1 97.9% 92.0% 94.9% 54.8% 75.5% 95.4% QGC1SDL1 95.6% 90.7% 96.6% 56.3% 74.1% 95.4% QGC2PDL1 95.6% 91.3% 96.6% 55.8% 73.8% 95.4% QGC2SDL1 89.4% 91.3% 96.6% 55.8% 75.5% 95.3% QGC1PDL2 95.8% 96.7% 95.5% 54.3% 74.1% 95.0% QGC1SDL2 89.4% 90.7% 95.5% 54.3% 74.6% 95.1% QGC2PDL2 89.4% 90.0% 95.5% 55.3% 74.6% 95.3% QGC2SDL2 89.4% 91.3% 94.9% 55.8% 74.9% 95.1% Kmeans [33] 68.1% 89.3% 70.2% 47.2% 71.0% – PCA-Kmeans [33] 72.3% 88.7% 70.2% 45.3% 71.0% – LDA-Km [33] 76.6% 98.0% 82.6% 51.0% 71.2% – 6 Conclusions The enormous successes gained by the quantum algorithms make us realize it is possible that the quantum algorithms can obtain solutions faster and bet- ter than those classical algorithms for some problems. Therefore\n",
      " > 282 [-0.07367  0.03424 -0.04425  0.0712   0.05127] 54.3% 74.1% 95.0% QGC1SDL2 89.4% 90.7% 95.5% 54.3% 74.6% 95.1% QGC2PDL2 89.4% 90.0% 95.5% 55.3% 74.6% 95.3% QGC2SDL2 89.4% 91.3% 94.9% 55.8% 74.9% 95.1% Kmeans [33] 68.1% 89.3% 70.2% 47.2% 71.0% – PCA-Kmeans [33] 72.3% 88.7% 70.2% 45.3% 71.0% – LDA-Km [33] 76.6% 98.0% 82.6% 51.0% 71.2% – 6 Conclusions The enormous successes gained by the quantum algorithms make us realize it is possible that the quantum algorithms can obtain solutions faster and bet- ter than those classical algorithms for some problems. Therefore , we combine the quantum game with the problem of data clustering, and establish clustering algorithms based on quantum games. In the algorithms, data points for clus- tering are regarded as players who can make decisions in quantum ga mes. On a weighted and directed knn network that represents relations am ong players, each player uses quantum strategies against every one of his neigh bors in a 2 × 2 entangled quantum game respectively. We design two cases of stra tegies: (i) one plays the strategy ˆH, the\n",
      " > 283 [-0.10443  0.02829 -0.06885  0.10486  0.0487 ] Therefore , we combine the quantum game with the problem of data clustering, and establish clustering algorithms based on quantum games. In the algorithms, data points for clus- tering are regarded as players who can make decisions in quantum ga mes. On a weighted and directed knn network that represents relations am ong players, each player uses quantum strategies against every one of his neigh bors in a 2 × 2 entangled quantum game respectively. We design two cases of stra tegies: (i) one plays the strategy ˆH, the other plays the strategy ˆH or ˆD, (ii) one plays the strategy ˆFt− 1, the other plays the strategy ˆFt− 1 or ˆD according to the strength of links, in each of which players’ expected payoﬀs are calculated ba sed on the PD- and SD-like payoﬀ matrices respectively. According to neighbor s’ payoﬀs in one’s neighbor set, each player applies a LRR function ( L1 i(·) or L2 i(·)) to change his neighbors, i.e., the links connecting to neighbors with small payoﬀs 16are removed and then new links are created to those\n",
      " > 284 [-0.0988   0.01573 -0.08405  0.10016  0.05298] the other plays the strategy ˆH or ˆD, (ii) one plays the strategy ˆFt− 1, the other plays the strategy ˆFt− 1 or ˆD according to the strength of links, in each of which players’ expected payoﬀs are calculated ba sed on the PD- and SD-like payoﬀ matrices respectively. According to neighbor s’ payoﬀs in one’s neighbor set, each player applies a LRR function ( L1 i(·) or L2 i(·)) to change his neighbors, i.e., the links connecting to neighbors with small payoﬀs 16are removed and then new links are created to those with higher pay oﬀs. Later, the Grover iteration G is employed to update the strength of links between him and his neighbors. In the process of playing quantum game, the s tructure of the network formed by players tends to stability gradually. In ot her words, each player always connects to one of his neighbors with the largest strength or jumps among some neighbors with the largest strength in a constan t period. At this time, if only the links with the largest strength are left but all oth er links are\n",
      " > 285 [-0.07477  0.02846 -0.0759   0.08594  0.0561 ] those with higher pay oﬀs. Later, the Grover iteration G is employed to update the strength of links between him and his neighbors. In the process of playing quantum game, the s tructure of the network formed by players tends to stability gradually. In ot her words, each player always connects to one of his neighbors with the largest strength or jumps among some neighbors with the largest strength in a constan t period. At this time, if only the links with the largest strength are left but all oth er links are removed among players, the network naturally divides into seve ral separate parts, each of which corresponds to a cluster. Additionally, in simulations, it can be found that the total expected p ayoﬀs of algorithms using SD-like payoﬀ matrix are higher than that of algorith ms using PD-like payoﬀ matrix. Later, the reason is explained. Further, we o bserve that the rates of convergence of the algorithms employing the LRR func tion L2 i(·) are faster slightly than that of the algorithms employing the LRR fun\n",
      " > 286 [-0.04614  0.02663 -0.0853   0.0656   0.04404] are removed among players, the network naturally divides into seve ral separate parts, each of which corresponds to a cluster. Additionally, in simulations, it can be found that the total expected p ayoﬀs of algorithms using SD-like payoﬀ matrix are higher than that of algorith ms using PD-like payoﬀ matrix. Later, the reason is explained. Further, we o bserve that the rates of convergence of the algorithms employing the LRR func tion L2 i(·) are faster slightly than that of the algorithms employing the LRR fun ction L1 i(·), because more areas are explored by the LRR function L1 i(·), but this brings better clustering results. In the case when the exact numb er of clusters is unknown in advance, one can adjust the number k of nearest neighbors to control the number of clusters, where the number of clusters de creases inversely with the number k of nearest neighbors. Finally, the clustering algorithms are evaluated on six real datasets, and simulation results have demons trated that data points in a dataset are clustered\n",
      " > 287 [-0.05524  0.03174 -0.0683   0.0827   0.05466] fun ction L1 i(·), because more areas are explored by the LRR function L1 i(·), but this brings better clustering results. In the case when the exact numb er of clusters is unknown in advance, one can adjust the number k of nearest neighbors to control the number of clusters, where the number of clusters de creases inversely with the number k of nearest neighbors. Finally, the clustering algorithms are evaluated on six real datasets, and simulation results have demons trated that data points in a dataset are clustered reasonably and eﬃciently. Acknowledgments The authors would like to thank the anonymous referees for their h elpful comments and suggestions to improve the presentation of this pap er. This work was supported in part by the National Natural Science Foundation of China (No. 60405012, No. 60675055). References [1] V. Vedral and M. Plenio, “Basics of quantum computation,” Progress in Quantum Electronics , vol. 22, no. 1, pp. 1–39, 1998. [2] P. W. Shor, “Algorithms for quantum computation: discrete loga\n",
      " > 288 [-0.06183  0.01863 -0.0775   0.0495   0.06384] clustered reasonably and eﬃciently. Acknowledgments The authors would like to thank the anonymous referees for their h elpful comments and suggestions to improve the presentation of this pap er. This work was supported in part by the National Natural Science Foundation of China (No. 60405012, No. 60675055). References [1] V. Vedral and M. Plenio, “Basics of quantum computation,” Progress in Quantum Electronics , vol. 22, no. 1, pp. 1–39, 1998. [2] P. W. Shor, “Algorithms for quantum computation: discrete loga rithms and factoring,” in Proc. of the 35th Annual Symposium on Foundations of Computer Science , pp. 124–134, 1994. [3] L. K. Grover, “Quantum mechanics helps in searching for a needle in a haystack,” Physical Review Letters , vol. 79, no. 2, p. 325, 1997. [4] G. Brassard, P. Høyer, and A. Tapp, “Quantum counting,” in Automata, Languages and Programming , vol. 1443, pp. 820–831, 1998. [5] D. A. Meyer, “Quantum strategies,” Physical Review Letters , vol. 82, no. 5, p. 1052, 1999. [6] J. Eisert, M. Wilkens, and\n",
      " > 289 [-0.10004   0.004536 -0.04535   0.04575   0.07275 ] rithms and factoring,” in Proc. of the 35th Annual Symposium on Foundations of Computer Science , pp. 124–134, 1994. [3] L. K. Grover, “Quantum mechanics helps in searching for a needle in a haystack,” Physical Review Letters , vol. 79, no. 2, p. 325, 1997. [4] G. Brassard, P. Høyer, and A. Tapp, “Quantum counting,” in Automata, Languages and Programming , vol. 1443, pp. 820–831, 1998. [5] D. A. Meyer, “Quantum strategies,” Physical Review Letters , vol. 82, no. 5, p. 1052, 1999. [6] J. Eisert, M. Wilkens, and M. Lewenstein, “Quantum games and qu antum strategies,” Physical Review Letters , vol. 83, no. 15, p. 3077, 1999. 17[7] A. P. Flitney and D. Abbott, “Advantage of a quantum player ove r a classical one in 2 x 2 quantum games,” Proceedings of the Royal Society B: Biological Sciences, vol. 459, no. 2038, p. 2463, 2003. [8] L. Marinatto and T. Weber, “A quantum approach to static game s of com- plete information,” Physics Letters A , vol. 272, no. 5-6, pp. 291–303, 2000. [9] C. F. Lee and N. F. Johnson, “Eﬃciency\n",
      " > 290 [-0.10504  0.00703 -0.04132  0.0422   0.05453] and M. Lewenstein, “Quantum games and qu antum strategies,” Physical Review Letters , vol. 83, no. 15, p. 3077, 1999. 17[7] A. P. Flitney and D. Abbott, “Advantage of a quantum player ove r a classical one in 2 x 2 quantum games,” Proceedings of the Royal Society B: Biological Sciences, vol. 459, no. 2038, p. 2463, 2003. [8] L. Marinatto and T. Weber, “A quantum approach to static game s of com- plete information,” Physics Letters A , vol. 272, no. 5-6, pp. 291–303, 2000. [9] C. F. Lee and N. F. Johnson, “Eﬃciency and formalism of quantum games,” Physical Review A , vol. 67, no. 2, p. 022311, 2003. [10] J. Du, H. Li, X. Xu, M. Shi, J. Wu, X. Zhou, and R. Han, “Experime ntal realization of quantum games on a quantum computer,” Physical Review Letters, vol. 88, no. 13, p. 137902, 2002. [11] R. Prevedel, A. Stefanov, P. Walther, and A. Zeilinger, “Exper imental realization of a quantum game on a one-way quantum computer,” New Journal of Physics , vol. 5, pp. 205–215, 2007. [12] C. Schmid, A. P. Flitney, W. Wieczorek,\n",
      " > 291 [-0.0998   0.00661 -0.04437  0.04828  0.0527 ] “Eﬃciency and formalism of quantum games,” Physical Review A , vol. 67, no. 2, p. 022311, 2003. [10] J. Du, H. Li, X. Xu, M. Shi, J. Wu, X. Zhou, and R. Han, “Experime ntal realization of quantum games on a quantum computer,” Physical Review Letters, vol. 88, no. 13, p. 137902, 2002. [11] R. Prevedel, A. Stefanov, P. Walther, and A. Zeilinger, “Exper imental realization of a quantum game on a one-way quantum computer,” New Journal of Physics , vol. 5, pp. 205–215, 2007. [12] C. Schmid, A. P. Flitney, W. Wieczorek, N. Kiesel, H. Weinfurter, and L. C. L. Hollenberg, “Experimental implementation of a four-player quan- tum game,” arXiv:0901.0063v1, 2009. [13] H. Guo, J. Zhang, and G. J. Koehler, “A survey of quantum gam es,” De- cision Support Systems , vol. 46, no. 1, pp. 318–332, 2008. [14] D. Horn and A. Gottlieb, “Algorithm for data clustering in patter n recog- nition problems based on quantum mechanics,” Physical Review Letters , vol. 88, no. 1, p. 018702, 2001. [15] M. Sasaki and A. Carlini, “Quantum learning and\n",
      " > 292 [-0.06726  0.01968 -0.02061  0.05365  0.04758] Wieczorek, N. Kiesel, H. Weinfurter, and L. C. L. Hollenberg, “Experimental implementation of a four-player quan- tum game,” arXiv:0901.0063v1, 2009. [13] H. Guo, J. Zhang, and G. J. Koehler, “A survey of quantum gam es,” De- cision Support Systems , vol. 46, no. 1, pp. 318–332, 2008. [14] D. Horn and A. Gottlieb, “Algorithm for data clustering in patter n recog- nition problems based on quantum mechanics,” Physical Review Letters , vol. 88, no. 1, p. 018702, 2001. [15] M. Sasaki and A. Carlini, “Quantum learning and universal quant um matching machine,” Physical Review A , vol. 66, no. 2, p. 022303, 2002. [16] C. A. Trugenberger, “Quantum pattern recognition,” Quantum Informa- tion Processing, vol. 1, no. 6, pp. 471–493, 2002. [17] R. Sch¨ utzhold, “Pattern recognition on a quantum computer ,” Physical Review A , vol. 67, no. 6, p. 062311, 2003. [18] E. A¨ ımeur, G. Brassard, and S. Gambs, “Quantum clustering a lgorithms,” in Proceedings of the 24th International Conference on Machin e Learning , (Corvallis, OR), 2007.\n",
      " > 293 [-0.0685   0.02942 -0.03748  0.0469   0.0499 ] and universal quant um matching machine,” Physical Review A , vol. 66, no. 2, p. 022303, 2002. [16] C. A. Trugenberger, “Quantum pattern recognition,” Quantum Informa- tion Processing, vol. 1, no. 6, pp. 471–493, 2002. [17] R. Sch¨ utzhold, “Pattern recognition on a quantum computer ,” Physical Review A , vol. 67, no. 6, p. 062311, 2003. [18] E. A¨ ımeur, G. Brassard, and S. Gambs, “Quantum clustering a lgorithms,” in Proceedings of the 24th International Conference on Machin e Learning , (Corvallis, OR), 2007. [19] A. K. Jain, M. N. Murty, and P. J. Flynn, “Data clustering: a rev iew,” ACM Computing Surveys , vol. 31, no. 3, pp. 264–323, 1999. [20] A. Ekert, P. M. Hayden, and H. Inamori, “Course 10: Basic con cepts in quantum computation,” in Coherent atomic matter waves , vol. 72, p. 661, Springer Berlin / Heidelberg, 2001. [21] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information. Cambridge: Cambridge University Press, 20002005. [22] J. Nash, “Equilibrium points in n-person games,” Proceedings\n",
      " > 294 [-0.1146   0.02477 -0.0766   0.0535   0.0475 ] 2007. [19] A. K. Jain, M. N. Murty, and P. J. Flynn, “Data clustering: a rev iew,” ACM Computing Surveys , vol. 31, no. 3, pp. 264–323, 1999. [20] A. Ekert, P. M. Hayden, and H. Inamori, “Course 10: Basic con cepts in quantum computation,” in Coherent atomic matter waves , vol. 72, p. 661, Springer Berlin / Heidelberg, 2001. [21] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information. Cambridge: Cambridge University Press, 20002005. [22] J. Nash, “Equilibrium points in n-person games,” Proceedings of the Na- tional Academy of Sciences , vol. 36, pp. 48–49, 1950. 18[23] J. Nash, “Non-cooperative games,” The Annals of Mathematics , vol. 54, no. 2, pp. 286–295, 1951. [24] D. Fudenberg and J. Tirole, Game Theory . MIT Press, 1983. [25] S. C. Benjamin and P. M. Hayden, “Multiplayer quantum games,” Physical Review A , vol. 64, no. 3, p. 030301, 2001. [26] J. Du, H. Li, X. Xu, M. Shi, X. Zhou, and R. Han, “Entanglement c orre- lated phase changes in quantum games,” Arxiv preprint quant-ph/0111138 , 2001.\n",
      " > 295 [-0.0915   0.01214 -0.0695   0.0655   0.03104] Proceedings of the Na- tional Academy of Sciences , vol. 36, pp. 48–49, 1950. 18[23] J. Nash, “Non-cooperative games,” The Annals of Mathematics , vol. 54, no. 2, pp. 286–295, 1951. [24] D. Fudenberg and J. Tirole, Game Theory . MIT Press, 1983. [25] S. C. Benjamin and P. M. Hayden, “Multiplayer quantum games,” Physical Review A , vol. 64, no. 3, p. 030301, 2001. [26] J. Du, H. Li, X. Xu, M. Shi, X. Zhou, and R. Han, “Entanglement c orre- lated phase changes in quantum games,” Arxiv preprint quant-ph/0111138 , 2001. [27] J. Du, H. Li, X. Xu, X. Zhou, and R. Han, “Phase-transition-like behaviour of quantum games,” Journal of Physics A: Mathematical and Theoretical , vol. 36, pp. 6551–6562, 2003. [28] C. Hauert and M. Doebeli, “Spatial structure often inhibits the evolution of cooperation in the snowdrift game,” Nature, vol. 428, no. 6983, pp. 643– 646, 2004. [29] A.-L. Barab´ asi and E. Bonabeau, “Scale-free networks,” Scientiﬁc Ameri- can, vol. 288, no. 5, pp. 60–69, 2003. [30] G. Erkan, “Language model-based document\n",
      " > 296 [-0.04663 -0.02576 -0.05084  0.0799   0.02353] 2001. [27] J. Du, H. Li, X. Xu, X. Zhou, and R. Han, “Phase-transition-like behaviour of quantum games,” Journal of Physics A: Mathematical and Theoretical , vol. 36, pp. 6551–6562, 2003. [28] C. Hauert and M. Doebeli, “Spatial structure often inhibits the evolution of cooperation in the snowdrift game,” Nature, vol. 428, no. 6983, pp. 643– 646, 2004. [29] A.-L. Barab´ asi and E. Bonabeau, “Scale-free networks,” Scientiﬁc Ameri- can, vol. 288, no. 5, pp. 60–69, 2003. [30] G. Erkan, “Language model-based document clustering using r andom walks,” in Proceedings of the main conference on Human Language Tech- nology Conference of the North American Chapter of the Assoc iation of Computational Linguistics , (New York, New York), Association for Com- putational Linguistics, 2006. [31] A. Asuncion and D. J. Newman, UCI Machine Learning Repository (http://www.ics.uci.edu/ mlearn/MLRepository.html). Irvine, CA: Univer- sity of California, School of Information and Computer Science, 20 07. [32] J. MacQueen, “Some methods\n",
      " > 297 [-0.0183    0.03705  -0.0401    0.04086   0.005375] document clustering using r andom walks,” in Proceedings of the main conference on Human Language Tech- nology Conference of the North American Chapter of the Assoc iation of Computational Linguistics , (New York, New York), Association for Com- putational Linguistics, 2006. [31] A. Asuncion and D. J. Newman, UCI Machine Learning Repository (http://www.ics.uci.edu/ mlearn/MLRepository.html). Irvine, CA: Univer- sity of California, School of Information and Computer Science, 20 07. [32] J. MacQueen, “Some methods for classiﬁcation and analysis of m ultivariate observations,” in Proceedings of Fifth Berkeley Symposium on Mathematical Statistics and Probability , vol. 1, (Statistical Laboratory of the University of California, Berkeley), pp. 281–297, 1967. [33] C. Ding and T. Li, “Adaptive dimension reduction using discriminant anal- ysis and k-means clustering,” in Proceedings of the 24th International Con- ference on Machine Learning , (Corvallis, OR), pp. 521–528, 2007. 19−5 −4 −3 −2 −1 0 1 2 3 −4 −3 −2 −1 0 1 2 3\n",
      " > 298 [-0.0778   0.01929 -0.05878  0.073    0.05084] arXiv:0812.0743v2 [cs.LG] 10 Oct 2009 A Novel Clustering Algorithm Based on Quantum Games Qiang Li, Yan He, Jing-ping Jiang College of Electrical Engineering, Zhejiang University, Hang Zhou, Zhejiang, 310027, China May 28, 2018 Abstract The enormous successes have been made by quantum algorithms dur- ing the last decade. In this paper, we combine the quantum gam e with the problem of data clustering, and then develop a quantum-g ame-based clustering algorithm, in which data points in a dataset are c onsidered as players who can make decisions and implement quantum stra tegies in quantum games. After each round of a quantum game, each playe r’s ex- pected payoﬀ is calculated. Later, he uses an link-removing -and-rewiring (LRR) function to change his neighbors and adjust the streng th of links connecting to them in order to maximize his payoﬀ. Further, a lgorithms are discussed and analyzed in two cases of strategies, two pa yoﬀ ma- trixes and two LRR functions. Consequently, the simulation results have demonstrated that data points in datasets are clustered rea sonably and eﬃciently, and the clustering algorithms have fast rates of convergence. Moreover, the comparison with other algorithms also provid es an indica- tion of the eﬀectiveness of the proposed approach. Keywords: Unsupervised learning; Data clustering; Quantum compu- tation; Quantum game 1 Introduction Quantum computation is an extremely exciting and rapidly growing ﬁeld . More recently, an increasing number of researchers with diﬀerent backgrounds, ranging from physics, computer sciences and information theory t o mathematics and philosophy, are involved in researching properties of quantum- based com- putation [1]. During the last decade, a series of signiﬁcant breakthr oughs had been made. One was that in 1994 Peter Shor surprised the world by p roposing a polynomial-time quantum algorithm for integer factorization [2], while in the classical world the best-known classical factoring algorithm works in superpoly- nomial time. Three years later, in 1997,\n",
      " > 299 [-0.0737   0.01805 -0.0824   0.0777   0.04117] demonstrated that data points in datasets are clustered rea sonably and eﬃciently, and the clustering algorithms have fast rates of convergence. Moreover, the comparison with other algorithms also provid es an indica- tion of the eﬀectiveness of the proposed approach. Keywords: Unsupervised learning; Data clustering; Quantum compu- tation; Quantum game 1 Introduction Quantum computation is an extremely exciting and rapidly growing ﬁeld . More recently, an increasing number of researchers with diﬀerent backgrounds, ranging from physics, computer sciences and information theory t o mathematics and philosophy, are involved in researching properties of quantum- based com- putation [1]. During the last decade, a series of signiﬁcant breakthr oughs had been made. One was that in 1994 Peter Shor surprised the world by p roposing a polynomial-time quantum algorithm for integer factorization [2], while in the classical world the best-known classical factoring algorithm works in superpoly- nomial time. Three years later, in 1997, Lov Grover proved that a q uantum computer could search an unsorted database in the square root o f the time [3]. Meanwhile, Gilles Brassard et al. combined ideas from Grover’s and Sho r’s quantum algorithms to propose a quantum counting algorithm [4]. 1In recent years, many interests focus on the quantum game theo ry and con- siderable work has been done. For instance, D. A. Meyer [5] studied the Penny Flip game in the quantum world ﬁrstly. His result showed that if a player was allowed to implement quantum strategies, he would always defeat his o pponent who played the classical strategies and increase his expected payo ﬀ as well. J. Eisert et al. [6] quantized the Prisoners’ Dilemma and demonstrated that the dilemma could be escaped when both players resort to quantum stra tegies. A. P. Flitney et al. [7] generalized Eisert’s result, the miracle move, i.e., th e result of the game would move towards the quantum player’s preferred re sult, while the other player used classical strategies. L. Marinatto et al.\n",
      " > 300 [-0.066    0.03787 -0.02966  0.05212  0.0685 ] 1997, Lov Grover proved that a q uantum computer could search an unsorted database in the square root o f the time [3]. Meanwhile, Gilles Brassard et al. combined ideas from Grover’s and Sho r’s quantum algorithms to propose a quantum counting algorithm [4]. 1In recent years, many interests focus on the quantum game theo ry and con- siderable work has been done. For instance, D. A. Meyer [5] studied the Penny Flip game in the quantum world ﬁrstly. His result showed that if a player was allowed to implement quantum strategies, he would always defeat his o pponent who played the classical strategies and increase his expected payo ﬀ as well. J. Eisert et al. [6] quantized the Prisoners’ Dilemma and demonstrated that the dilemma could be escaped when both players resort to quantum stra tegies. A. P. Flitney et al. [7] generalized Eisert’s result, the miracle move, i.e., th e result of the game would move towards the quantum player’s preferred re sult, while the other player used classical strategies. L. Marinatto et al. [8] in vestigated the Battle of the Sexes game in quantum domain. Their result showed tha t there existed a unique equilibrium in the game, when the entangled strategie s were allowed. C. F. Lee et al. [9] reported that the quantum game is more eﬃcient than the classical game, and they found an upper bound for this eﬃ ciency. Be- sides, some experiments about the quantum games have also been im plemented on diﬀerent quantum computers [10, 11, 12]. For more details about quantum games, see [13]. Successes achieved by quantum algorithms make us guess that pow erful quantum computers can ﬁgure out solutions faster and better th an the best known classical counterparts for certain types of problems. Fur thermore, it is more important that they oﬀer a new way to ﬁnd potentially dramatic algorith- mic speed-ups. Therefore, we may ask naturally: can we construc t quantum versions of classical algorithms or present new quantum algorithms to solve the problems in pattern recognition faster and better on a quantu m computer?\n",
      " > 301 [-0.0636   0.05    -0.04965  0.07336  0.03644] al. [8] in vestigated the Battle of the Sexes game in quantum domain. Their result showed tha t there existed a unique equilibrium in the game, when the entangled strategie s were allowed. C. F. Lee et al. [9] reported that the quantum game is more eﬃcient than the classical game, and they found an upper bound for this eﬃ ciency. Be- sides, some experiments about the quantum games have also been im plemented on diﬀerent quantum computers [10, 11, 12]. For more details about quantum games, see [13]. Successes achieved by quantum algorithms make us guess that pow erful quantum computers can ﬁgure out solutions faster and better th an the best known classical counterparts for certain types of problems. Fur thermore, it is more important that they oﬀer a new way to ﬁnd potentially dramatic algorith- mic speed-ups. Therefore, we may ask naturally: can we construc t quantum versions of classical algorithms or present new quantum algorithms to solve the problems in pattern recognition faster and better on a quantu m computer? Following this idea, some researchers have proposed their novel me thods and demonstrated exciting results [14, 15, 16, 17, 18]. In addition, data clustering is a main branch of Pattern Recognition, which is widely used in many ﬁelds such as pattern analysis, data mining, infor ma- tion retrieval and image segmentation. In these ﬁelds, however, t here is usually little priori knowledge available about the data. In response to thes e restric- tions, clustering methodology come into being which is particularly suit able for the exploration of interrelationships among data points. Data clust ering is the formal study of algorithms and methods for grouping or classifying unlabeled data points [19]. In other words, its task is to ﬁnd the inherent stru cture of a given collection of unlabeled data points and group them into meaningf ul clus- ters [19]. In this paper, we attempt to combine the quantum game wit h the problem of data clustering in order to establish a novel clustering alg orithm based on quantum\n",
      " > 302 [-0.089    0.03952 -0.06305  0.0875   0.03775] computer? Following this idea, some researchers have proposed their novel me thods and demonstrated exciting results [14, 15, 16, 17, 18]. In addition, data clustering is a main branch of Pattern Recognition, which is widely used in many ﬁelds such as pattern analysis, data mining, infor ma- tion retrieval and image segmentation. In these ﬁelds, however, t here is usually little priori knowledge available about the data. In response to thes e restric- tions, clustering methodology come into being which is particularly suit able for the exploration of interrelationships among data points. Data clust ering is the formal study of algorithms and methods for grouping or classifying unlabeled data points [19]. In other words, its task is to ﬁnd the inherent stru cture of a given collection of unlabeled data points and group them into meaningf ul clus- ters [19]. In this paper, we attempt to combine the quantum game wit h the problem of data clustering in order to establish a novel clustering alg orithm based on quantum games. In our algorithms, unlabeled data points in a dataset are regarded as players who can make decisions in quantum games. O n a time- varying network formed by players, each player is permitted to use quantum strategies and plays a 2 × 2 entangled quantum game against every one of his neighbors respectively. Later, he applies a link-removing-and-rew iring (LRR) function to remove the links of neighbors with small payoﬀs and crea te new links to neighbors with higher payoﬀs at the same time. Furthermore, th e strength of links between a player and his neighbors is diﬀerent from one anoth er, which is updated by the Grover iteration. During quantum games, the str ucture of network and the strength of links between players tend toward st ability grad- ually. Finally, if each player only connects to the neighbor with the high est strength, the network will naturally divide into several separate p arts, each of which corresponds to a cluster. 2The remainder of this paper is organized as follows: Section 2 introdu\n",
      " > 303 [-0.08325  0.01929 -0.0829   0.08765  0.037  ] games. In our algorithms, unlabeled data points in a dataset are regarded as players who can make decisions in quantum games. O n a time- varying network formed by players, each player is permitted to use quantum strategies and plays a 2 × 2 entangled quantum game against every one of his neighbors respectively. Later, he applies a link-removing-and-rew iring (LRR) function to remove the links of neighbors with small payoﬀs and crea te new links to neighbors with higher payoﬀs at the same time. Furthermore, th e strength of links between a player and his neighbors is diﬀerent from one anoth er, which is updated by the Grover iteration. During quantum games, the str ucture of network and the strength of links between players tend toward st ability grad- ually. Finally, if each player only connects to the neighbor with the high est strength, the network will naturally divide into several separate p arts, each of which corresponds to a cluster. 2The remainder of this paper is organized as follows: Section 2 introdu ces some important concepts about the quantum computation and the quantum Prisoners’ Dilemma brieﬂy. In Section 3, the algorithms are establish ed in two cases of strategies, payoﬀ matrices and link-removing-and-rewir ing (LRR) func- tions, and then they are elaborated and analyzed. In Section 4, th e relationship between the number of nearest neighbors and the number of clust ers is dis- cussed. Next, the eﬀect of the cost in the SD-like payoﬀ matrix is an alyzed, and the relationship between the total payoﬀs and the rates of co nvergence of algorithms is explained. In Section 5, those datasets used in the simu lations are introduced brieﬂy, and then results of algorithms are demonst rated. The conclusion is given in Section 6. 2 Quantum computation and quantum game 2.1 Quantum computation The elementary unit of quantum computation is called the qubit, which is typically a microscopic system, such as an atom, a nuclear spin, or a p olarized photon. In quantum computation, the Boolean states 0 and 1 are r epresented\n",
      " > 304 [-0.0703   0.01523 -0.0711   0.07117  0.02638] introdu ces some important concepts about the quantum computation and the quantum Prisoners’ Dilemma brieﬂy. In Section 3, the algorithms are establish ed in two cases of strategies, payoﬀ matrices and link-removing-and-rewir ing (LRR) func- tions, and then they are elaborated and analyzed. In Section 4, th e relationship between the number of nearest neighbors and the number of clust ers is dis- cussed. Next, the eﬀect of the cost in the SD-like payoﬀ matrix is an alyzed, and the relationship between the total payoﬀs and the rates of co nvergence of algorithms is explained. In Section 5, those datasets used in the simu lations are introduced brieﬂy, and then results of algorithms are demonst rated. The conclusion is given in Section 6. 2 Quantum computation and quantum game 2.1 Quantum computation The elementary unit of quantum computation is called the qubit, which is typically a microscopic system, such as an atom, a nuclear spin, or a p olarized photon. In quantum computation, the Boolean states 0 and 1 are r epresented by a prescribed pair of normalized and mutually orthogonal quantum st ates labeled as {|0⟩, |1⟩} to form a ’computational basis’ [20]. Any pure state of the qubit can be written as a superposition state α|0⟩+ β|1⟩ for some α and β satisfying |α|2 + |β|2 = 1 [20]. A collection of n qubits is called a quantum register of size n, which spans a Hilbert space of 2 n dimensions, so 2 n mutually orthogonal quantum states can be available. Quantum state preparations, and any other manipulations on qubit s, have to be performed by unitary operations. A quantum logic gate is a dev ice which performs a ﬁxed unitary operation on selected qubits in a ﬁxed perio d of time, and a quantum circuit is a device consisting of quantum logic gates who se com- putational steps are synchronized in time [20]. The most common qua ntum gate is the Hadamard gate, which acts on a qubit in state |0⟩ or |1⟩ to produce    |0⟩ H − → 1 √ 2 |0⟩+ 1√ 2 |1⟩ |1⟩ H − → 1√ 2 |0⟩ − 1√ 2 |1⟩ ,H = 1√ 2 ( 1 1 1−1 ) . (1) For more details, see\n",
      " > 305 [-0.10016  0.01698 -0.03937  0.0858   0.05246] epresented by a prescribed pair of normalized and mutually orthogonal quantum st ates labeled as {|0⟩, |1⟩} to form a ’computational basis’ [20]. Any pure state of the qubit can be written as a superposition state α|0⟩+ β|1⟩ for some α and β satisfying |α|2 + |β|2 = 1 [20]. A collection of n qubits is called a quantum register of size n, which spans a Hilbert space of 2 n dimensions, so 2 n mutually orthogonal quantum states can be available. Quantum state preparations, and any other manipulations on qubit s, have to be performed by unitary operations. A quantum logic gate is a dev ice which performs a ﬁxed unitary operation on selected qubits in a ﬁxed perio d of time, and a quantum circuit is a device consisting of quantum logic gates who se com- putational steps are synchronized in time [20]. The most common qua ntum gate is the Hadamard gate, which acts on a qubit in state |0⟩ or |1⟩ to produce    |0⟩ H − → 1 √ 2 |0⟩+ 1√ 2 |1⟩ |1⟩ H − → 1√ 2 |0⟩ − 1√ 2 |1⟩ ,H = 1√ 2 ( 1 1 1−1 ) . (1) For more details, see [20, 21]. 2.2 Quantum Prisoners’ Dilemma The Prisoners’ Dilemma (PD), a well-known example in the classical gam e theory, is an abstract of many phenomena in the real world and it ha s been wildly used in plenty of scientiﬁc ﬁelds. In this game, each of two player s has two optional strategies, cooperation (C) and defection (D). Lat er, he chooses one strategy against the other’s for maximizing his own payoﬀ, so do es the other side at the same time, but both sides do not know the opponent’s str ategy. As a result, each player receives a payoﬀ which depends on his selected strategy, where the payoﬀ matrix under diﬀerent strategy proﬁles is describ ed in Table 1. According to the classical game theory, the strategy proﬁle (def ection, defection) 3Table 1: Payoﬀ matrix for the Prisoners’ Dilemma. C = 0 D= 1 C = 0 R= 3 S = 0 D= 1 T = 5 P = 1 is the unique Nash Equilibrium [22, 23], but unfortunately it is not Paret o optimal [24]. In the quantum game, however, thanks to the quantum strategie s, the dilemma in the\n",
      " > 306 [-0.09     0.03021 -0.0483   0.0892   0.04898] [20, 21]. 2.2 Quantum Prisoners’ Dilemma The Prisoners’ Dilemma (PD), a well-known example in the classical gam e theory, is an abstract of many phenomena in the real world and it ha s been wildly used in plenty of scientiﬁc ﬁelds. In this game, each of two player s has two optional strategies, cooperation (C) and defection (D). Lat er, he chooses one strategy against the other’s for maximizing his own payoﬀ, so do es the other side at the same time, but both sides do not know the opponent’s str ategy. As a result, each player receives a payoﬀ which depends on his selected strategy, where the payoﬀ matrix under diﬀerent strategy proﬁles is describ ed in Table 1. According to the classical game theory, the strategy proﬁle (def ection, defection) 3Table 1: Payoﬀ matrix for the Prisoners’ Dilemma. C = 0 D= 1 C = 0 R= 3 S = 0 D= 1 T = 5 P = 1 is the unique Nash Equilibrium [22, 23], but unfortunately it is not Paret o optimal [24]. In the quantum game, however, thanks to the quantum strategie s, the dilemma in the classical game can be escaped in a restricted strategic space [6]. The physical model of quantum Prisoners’ Dilemma presented by Eis ert [6] is shown in Figure 1. Figure 1: The block diagram of the system. If the possible outcomes of the classical strategies, C = 0 and D = 1, are assigned to two basis vectors {|C = 0 ⟩, |D = 1 ⟩} in Hilbert space respectively, then at any time the state of the game may be represented by a vec tor in the space spanned by the basis {|00⟩, |01⟩, |10⟩, |11⟩} [6]. Assume the initial state of the game is |ψ0⟩ = ˆJ |00⟩, where ˆJ is an entangling operator which is known to both players. For a two-player game with two pure strategies, the general form of ˆJ may be written as [25, 26] ˆJ(γ) = exp(iγ 2 σ⊗ 2 x ) = I⊗ 2cosγ 2 + iσ⊗ 2 x sinγ 2 (2) where γ ∈ [0,π/ 2] is a measure of entanglement of a game. When γ = π/ 2, there is a maximally entangled game, in which the entangling operator t akes form ˆJ(γ) = 1√ 2 (I⊗ 2 + iσ⊗ 2 x ). (3) Next, each player chooses a unitary operator ˆY1( ˆY2)\n",
      " > 307 [-0.0895   0.03568 -0.0751   0.098    0.03043] classical game can be escaped in a restricted strategic space [6]. The physical model of quantum Prisoners’ Dilemma presented by Eis ert [6] is shown in Figure 1. Figure 1: The block diagram of the system. If the possible outcomes of the classical strategies, C = 0 and D = 1, are assigned to two basis vectors {|C = 0 ⟩, |D = 1 ⟩} in Hilbert space respectively, then at any time the state of the game may be represented by a vec tor in the space spanned by the basis {|00⟩, |01⟩, |10⟩, |11⟩} [6]. Assume the initial state of the game is |ψ0⟩ = ˆJ |00⟩, where ˆJ is an entangling operator which is known to both players. For a two-player game with two pure strategies, the general form of ˆJ may be written as [25, 26] ˆJ(γ) = exp(iγ 2 σ⊗ 2 x ) = I⊗ 2cosγ 2 + iσ⊗ 2 x sinγ 2 (2) where γ ∈ [0,π/ 2] is a measure of entanglement of a game. When γ = π/ 2, there is a maximally entangled game, in which the entangling operator t akes form ˆJ(γ) = 1√ 2 (I⊗ 2 + iσ⊗ 2 x ). (3) Next, each player chooses a unitary operator ˆY1( ˆY2) from the strategy space S1(S2) and operates it on the qubit that belongs to him, which makes the ga me in a state ( ˆY1 ⊗ ˆY2) ˆJ|00⟩. Speciﬁcally, the unitary operators ˆC and ˆD that correspond to the strategies, cooperation and defection, are g iven below [6] ˆC = (1 0 0 1 ) , ˆD= ( 0 1 −1 0 ) . (4) In the end, before a projective measurement in the basis {|0⟩, |1⟩} is carried out, the ﬁnal state is |ψf ⟩ = ˆJ†( ˆY1 ⊗ ˆY2) ˆJ |00⟩. (5) Thus, the player’s expected payoﬀ is written as z= R|⟨ψf |00⟩|2 + S|⟨ψf |01⟩|2 + T|⟨ψf |10⟩|2 + P|⟨ψf |11⟩|2. (6) For more details, see [6, 27]. 43 Algorithm In the section, we will combine the model of the quantum game with th e problem of data clustering, and then establish clustering algorithms based on quantum games. Assume an unlabeled dataset X = {X 1, X 2, · · · , X N },which are distributed in a m-dimensional metric space. Each data point in the dataset is considered as a player in quantum games who can make decisions and always hope to maximize his payoﬀ. In the metric\n",
      " > 308 [-0.0911   0.01599 -0.08417  0.0832   0.05582] ˆY2) from the strategy space S1(S2) and operates it on the qubit that belongs to him, which makes the ga me in a state ( ˆY1 ⊗ ˆY2) ˆJ|00⟩. Speciﬁcally, the unitary operators ˆC and ˆD that correspond to the strategies, cooperation and defection, are g iven below [6] ˆC = (1 0 0 1 ) , ˆD= ( 0 1 −1 0 ) . (4) In the end, before a projective measurement in the basis {|0⟩, |1⟩} is carried out, the ﬁnal state is |ψf ⟩ = ˆJ†( ˆY1 ⊗ ˆY2) ˆJ |00⟩. (5) Thus, the player’s expected payoﬀ is written as z= R|⟨ψf |00⟩|2 + S|⟨ψf |01⟩|2 + T|⟨ψf |10⟩|2 + P|⟨ψf |11⟩|2. (6) For more details, see [6, 27]. 43 Algorithm In the section, we will combine the model of the quantum game with th e problem of data clustering, and then establish clustering algorithms based on quantum games. Assume an unlabeled dataset X = {X 1, X 2, · · · , X N },which are distributed in a m-dimensional metric space. Each data point in the dataset is considered as a player in quantum games who can make decisions and always hope to maximize his payoﬀ. In the metric space, there is a distance f unction d : X × X − → R, satisfying the closer the two players are, the smaller the output is. Based on the distance function, a k nearest neighbors (knn) network as a weighted and directed network, G0(X ,E 0,d ), may be created among data points by adding k edges directed toward its k nearest neighbors for each player. Deﬁnition 1 If there is a set X with N players, X = {X1, X2, · · · , XN }, the weighted and directed knn network, G0(X,E 0,d ), is created as below.                  X = { Xi,i = 1 , 2, · · · ,N } E0 = ⋃ N i=1 E0(i) E0(i) = { e0 ( Xi, Xj ) | j ∈ Γ 0(i) } Γ 0(i) = { j ⏐ ⏐ ⏐j = argmink Xh∈ X ({ d(Xi, Xh), Xh ∈ X } )} (7) Here, each player in the set X corresponds to a vertex in the network G0(X,E 0,d ); E0 is a link set and a link in the network represents certain rela tionship between a pair of players; the distances denote the weights over link s; the function, argmink(·), is to ﬁnd k nearest neighbors of a player which construct a ne igh- bor set,\n",
      " > 309 [-0.10944  0.02429 -0.05597  0.06696  0.0657 ] metric space, there is a distance f unction d : X × X − → R, satisfying the closer the two players are, the smaller the output is. Based on the distance function, a k nearest neighbors (knn) network as a weighted and directed network, G0(X ,E 0,d ), may be created among data points by adding k edges directed toward its k nearest neighbors for each player. Deﬁnition 1 If there is a set X with N players, X = {X1, X2, · · · , XN }, the weighted and directed knn network, G0(X,E 0,d ), is created as below.                  X = { Xi,i = 1 , 2, · · · ,N } E0 = ⋃ N i=1 E0(i) E0(i) = { e0 ( Xi, Xj ) | j ∈ Γ 0(i) } Γ 0(i) = { j ⏐ ⏐ ⏐j = argmink Xh∈ X ({ d(Xi, Xh), Xh ∈ X } )} (7) Here, each player in the set X corresponds to a vertex in the network G0(X,E 0,d ); E0 is a link set and a link in the network represents certain rela tionship between a pair of players; the distances denote the weights over link s; the function, argmink(·), is to ﬁnd k nearest neighbors of a player which construct a ne igh- bor set, Γ 0(i); the subscript ’0’ is the initial time step. It is worth noting that the strength of links between a player X i and his k nearest neighbors represented by ρt− 1(X i, X j ),j ∈ Γ t− 1(i)(t ≥ 1) is time- varying, whose initial values is calculated by ρ0(X i, X j) = { 1/ |Γ 0(i)| = 1 /k, j ∈ Γ 0(i) 0, otherwise (8) where the symbol | · | denotes the cardinality of a set. After the initial connections are constructed among players (dat a points), on this weighted and directed knn network, a quantum game can be d eﬁned as following. Deﬁnition 2A quantum game Ω = {X,G t,S,Z t} on a network Gt is a 4- tuple: X is a set of players; Gt represents the connections among players; S = {s(i),i = 1 , 2, · · · ,N } represents a set of players’ strategies including the full range of quantum strategies; Zt = {zt(i),i = 1 , 2, · · · ,N } represents a set of players’ expected payoﬀs. Here, the variable tdenotes the time step (the number of iterations). In each round, players choose theirs strate gies simultaneously, and\n",
      " > 310 [-0.0949   0.02376 -0.05817  0.06223  0.04657] set, Γ 0(i); the subscript ’0’ is the initial time step. It is worth noting that the strength of links between a player X i and his k nearest neighbors represented by ρt− 1(X i, X j ),j ∈ Γ t− 1(i)(t ≥ 1) is time- varying, whose initial values is calculated by ρ0(X i, X j) = { 1/ |Γ 0(i)| = 1 /k, j ∈ Γ 0(i) 0, otherwise (8) where the symbol | · | denotes the cardinality of a set. After the initial connections are constructed among players (dat a points), on this weighted and directed knn network, a quantum game can be d eﬁned as following. Deﬁnition 2A quantum game Ω = {X,G t,S,Z t} on a network Gt is a 4- tuple: X is a set of players; Gt represents the connections among players; S = {s(i),i = 1 , 2, · · · ,N } represents a set of players’ strategies including the full range of quantum strategies; Zt = {zt(i),i = 1 , 2, · · · ,N } represents a set of players’ expected payoﬀs. Here, the variable tdenotes the time step (the number of iterations). In each round, players choose theirs strate gies simultaneously, and each player can only observe its neighbors’ payoﬀs, but d oes not know the strategy proﬁles of all other players in X. 53.1 Cases of quantum strategies and payoﬀ matrices At ﬁrst, each player selects a strategy from his strategy set, an d then plays a 2 × 2 entangled quantum game against one of his k neighbors respectively. In the classical 2 × 2 game, such as the Prisoners’ Dilemma, usually there are only two pure strategies, cooperation and defection, but in the quant um game, one can design diﬀerent unitary operators as strategies, i.e., the stra tegy set S may be identiﬁed with some subset of the group of 2 × 2 unitary matrices [6]. Here, for the purpose of clustering and simplifying computation, the stra tegy set of a player X i is restricted in a set S1 = { ˆH, ˆD} or S2 = { ˆFt− 1(i,j ), ˆD}, and then two cases of strategy sets are described respectively. Case 1: In this case, a player and his opponent can apply strategies inS1 = { ˆH, ˆD}. When a player X i use the Hadamard matrix ˆH as a strategy, his\n",
      " > 311 [-0.09644   0.006954 -0.05286   0.10565   0.03647 ] each player can only observe its neighbors’ payoﬀs, but d oes not know the strategy proﬁles of all other players in X. 53.1 Cases of quantum strategies and payoﬀ matrices At ﬁrst, each player selects a strategy from his strategy set, an d then plays a 2 × 2 entangled quantum game against one of his k neighbors respectively. In the classical 2 × 2 game, such as the Prisoners’ Dilemma, usually there are only two pure strategies, cooperation and defection, but in the quant um game, one can design diﬀerent unitary operators as strategies, i.e., the stra tegy set S may be identiﬁed with some subset of the group of 2 × 2 unitary matrices [6]. Here, for the purpose of clustering and simplifying computation, the stra tegy set of a player X i is restricted in a set S1 = { ˆH, ˆD} or S2 = { ˆFt− 1(i,j ), ˆD}, and then two cases of strategy sets are described respectively. Case 1: In this case, a player and his opponent can apply strategies inS1 = { ˆH, ˆD}. When a player X i use the Hadamard matrix ˆH as a strategy, his opponent (neighbor) X j has two optional strategies { ˆH, ˆD}, but which strategy is chosen is dependent on the strength of the link between them, as is a rule of the clustering algorithm. If the strength ρt− 1(X j , X i) equals to zero, i.e., there is no link directed from the player X j to the player X i, then the player X j will apply the strategy ’Defection’ ( ˆD). Alternatively, if ρt− 1(X j , X i) >0, namely mutual connections between them, the player X j implements the strategy ˆH. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, by applying the model of the quantum game the ﬁnal state of the game is |ψf,j ⟩ = { 1 2 (|00⟩ − i|01⟩ − i|10⟩+ |11⟩), ˆH⊗ ˆH 1√ 2 (i|00⟩ − |01⟩), ˆH⊗ ˆD (9) Case 2: The strategy setS2 = { ˆFt− 1(i,j ), ˆD} is adopted in the case. The strategy ˆFt− 1(i,j ), ˆFt− 1(i,j ) = ( √ ρt− 1(X i, X j ) √ 1 − ρt− 1(X i, X j )√ 1 − ρt− 1(X i, X j ) − √ ρt− 1(X i, X j ) ) , is a general form of Hadamard matrix ˆH whose elements are associated with the strength of links ρt− 1(X i, X j ). When\n",
      " > 312 [-0.054    0.023   -0.06128  0.0911   0.03168] opponent (neighbor) X j has two optional strategies { ˆH, ˆD}, but which strategy is chosen is dependent on the strength of the link between them, as is a rule of the clustering algorithm. If the strength ρt− 1(X j , X i) equals to zero, i.e., there is no link directed from the player X j to the player X i, then the player X j will apply the strategy ’Defection’ ( ˆD). Alternatively, if ρt− 1(X j , X i) >0, namely mutual connections between them, the player X j implements the strategy ˆH. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, by applying the model of the quantum game the ﬁnal state of the game is |ψf,j ⟩ = { 1 2 (|00⟩ − i|01⟩ − i|10⟩+ |11⟩), ˆH⊗ ˆH 1√ 2 (i|00⟩ − |01⟩), ˆH⊗ ˆD (9) Case 2: The strategy setS2 = { ˆFt− 1(i,j ), ˆD} is adopted in the case. The strategy ˆFt− 1(i,j ), ˆFt− 1(i,j ) = ( √ ρt− 1(X i, X j ) √ 1 − ρt− 1(X i, X j )√ 1 − ρt− 1(X i, X j ) − √ ρt− 1(X i, X j ) ) , is a general form of Hadamard matrix ˆH whose elements are associated with the strength of links ρt− 1(X i, X j ). When ρt− 1(X i, X j )=0.5, the strategy ˆFt− 1(i,j ) recovers the strategy ˆH. Similarly, the neighbor X j , when ρt− 1(X j , X i) = 0, applies the strategy ’Defection’ ( ˆD), while using the strategy ˆFt− 1(i,j ) when ρt− 1(X j , X i) > 0. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, after their moves, the ﬁnal state of the game is |ψf,j ⟩ =      √ ρ1ρ2|00⟩ − i √ ρ2(1 − ρ1)|01⟩ −i √ ρ1(1 − ρ2)|10⟩+ √ (1 − ρ1)(1 − ρ2)|11⟩, ˆFt− 1 ⊗ ˆFt− 1 i√1 − ρ1|00⟩ − √ρ1|01⟩, ˆFt− 1 ⊗ ˆD . (10) According to the payoﬀ matrix, the player’s expected payoﬀ can be computed by zt− 1(i) = ∑ j∈ Γ t− 1 (i) zt− 1(X i, X j ) = ∑ j∈ Γ t− 1 (i) R|⟨ψf,j |00⟩|2 + S|⟨ψf,j |01⟩|2 + T|⟨ψf,j |10⟩|2 + P|⟨ψf,j |11⟩|2. (11) 6In practice, the payoﬀ matrix takes PD-like or Snowdrift (SD)-like f orm, de- scribed in Table 2 and 3. In the PD-like payoﬀ matrix, the following inequ ali- Table 2: PD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= 0 .6ωt− 1(X i, X j ) S = 0 .01ωt− 1(X i, X j ) D= 1 T = ωt− 1(X i, X j ) P = 0 .2ωt− 1(X i, X j ) Table 3: SD-like\n",
      " > 313 [-0.04218  -0.007328 -0.0706    0.0801    0.0391  ] When ρt− 1(X i, X j )=0.5, the strategy ˆFt− 1(i,j ) recovers the strategy ˆH. Similarly, the neighbor X j , when ρt− 1(X j , X i) = 0, applies the strategy ’Defection’ ( ˆD), while using the strategy ˆFt− 1(i,j ) when ρt− 1(X j , X i) > 0. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, after their moves, the ﬁnal state of the game is |ψf,j ⟩ =      √ ρ1ρ2|00⟩ − i √ ρ2(1 − ρ1)|01⟩ −i √ ρ1(1 − ρ2)|10⟩+ √ (1 − ρ1)(1 − ρ2)|11⟩, ˆFt− 1 ⊗ ˆFt− 1 i√1 − ρ1|00⟩ − √ρ1|01⟩, ˆFt− 1 ⊗ ˆD . (10) According to the payoﬀ matrix, the player’s expected payoﬀ can be computed by zt− 1(i) = ∑ j∈ Γ t− 1 (i) zt− 1(X i, X j ) = ∑ j∈ Γ t− 1 (i) R|⟨ψf,j |00⟩|2 + S|⟨ψf,j |01⟩|2 + T|⟨ψf,j |10⟩|2 + P|⟨ψf,j |11⟩|2. (11) 6In practice, the payoﬀ matrix takes PD-like or Snowdrift (SD)-like f orm, de- scribed in Table 2 and 3. In the PD-like payoﬀ matrix, the following inequ ali- Table 2: PD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= 0 .6ωt− 1(X i, X j ) S = 0 .01ωt− 1(X i, X j ) D= 1 T = ωt− 1(X i, X j ) P = 0 .2ωt− 1(X i, X j ) Table 3: SD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= ωt− 1(X i, X j ) − c 2 S = ωt− 1(X i, X j ) − c D= 1 T = ωt− 1(X i, X j ) P = 0 .01ωt− 1(X i, X j ) ties holds: T >R>P >S and 2 R>T + S [28]. To avoid a case that a player’s expected payoﬀ is zero, the variable S in Table 2 takes a small value instead of zero in Table 1. In addition, the Snowdrift game assumes that two drivers are blocked by a snowdrift, each of whom is in either side of the snowd rift. If they want to go back home, one of them or both must shovel a path through the snowdrift. So, there exists a cost c in the SD-like payoﬀ matrix and the following inequality holds: T > R > S > P[28], where c = β · ωt− 1(X i, X j ) and β is a proportional factor. Besides, the variable ωt− 1(X i, X j ) in two payoﬀ matrices is calculated by the formulation below. ωt− 1(X i, X j ) = ρt− 1(X i, X j ) × Degt− 1(X j )/d (X i, X j ) (12) 3.2 Design of LRR functions When all players’ payoﬀs have been computed, each player will obse rve his neighbors’ payoﬀs, and apply a link-removing-and-rewiring\n",
      " > 314 [-0.0625   0.00736 -0.0368   0.0522   0.0652 ] SD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= ωt− 1(X i, X j ) − c 2 S = ωt− 1(X i, X j ) − c D= 1 T = ωt− 1(X i, X j ) P = 0 .01ωt− 1(X i, X j ) ties holds: T >R>P >S and 2 R>T + S [28]. To avoid a case that a player’s expected payoﬀ is zero, the variable S in Table 2 takes a small value instead of zero in Table 1. In addition, the Snowdrift game assumes that two drivers are blocked by a snowdrift, each of whom is in either side of the snowd rift. If they want to go back home, one of them or both must shovel a path through the snowdrift. So, there exists a cost c in the SD-like payoﬀ matrix and the following inequality holds: T > R > S > P[28], where c = β · ωt− 1(X i, X j ) and β is a proportional factor. Besides, the variable ωt− 1(X i, X j ) in two payoﬀ matrices is calculated by the formulation below. ωt− 1(X i, X j ) = ρt− 1(X i, X j ) × Degt− 1(X j )/d (X i, X j ) (12) 3.2 Design of LRR functions When all players’ payoﬀs have been computed, each player will obse rve his neighbors’ payoﬀs, and apply a link-removing-and-rewiring (LRR) f unction Li(·) to change his links. A LRR function is deﬁned as below. Deﬁnition 3The LRR function Li(·) is a function of payoﬀs, whose output is a set with k elements, namely an updated neighbor set Γ t(i) of a player Xi. It is given as below. Γ t(i) = Li ( ˆzt− 1(i) ) = argmaxk j∈ Γ t− 1 (i) S Υ t− 1(i) ({ zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) }) ˆzt− 1(i) = { zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) } , Υ t− 1(i) = ⋃ j∈ Γ + t− 1 (i) Γ t− 1(j) Γ + t− 1(i) = { j|zt− 1(j) ≥ θt− 1(i),j ∈ Γ t− 1(i) } , Γ − t− 1(i) = Γ t− 1(i)\\Γ + t− 1(i) (13) where θt− 1(i) is a payoﬀ threshold, Υ t− 1(i) is called an extended neighbor set, and the function argmaxk(·) is to ﬁnd k neighbors with the ﬁrst k largest payoﬀs in the set Γ t− 1(i) ⋃ Υ t− 1(i). Here, two LRR functions L1 i(·) and L2 i(·) are designed. The function L1 i(·) always observes an extended neighbor set formed by half neighbor s of a data 7point X i, α = ⌈ 0.5 × | Γ t− 1(i)| ⌉ , where the symbol ⌈·⌉ is to take an integer part of a number satisfying\n",
      " > 315 [-0.096    0.0329  -0.02234  0.0633   0.0514 ] link-removing-and-rewiring (LRR) f unction Li(·) to change his links. A LRR function is deﬁned as below. Deﬁnition 3The LRR function Li(·) is a function of payoﬀs, whose output is a set with k elements, namely an updated neighbor set Γ t(i) of a player Xi. It is given as below. Γ t(i) = Li ( ˆzt− 1(i) ) = argmaxk j∈ Γ t− 1 (i) S Υ t− 1(i) ({ zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) }) ˆzt− 1(i) = { zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) } , Υ t− 1(i) = ⋃ j∈ Γ + t− 1 (i) Γ t− 1(j) Γ + t− 1(i) = { j|zt− 1(j) ≥ θt− 1(i),j ∈ Γ t− 1(i) } , Γ − t− 1(i) = Γ t− 1(i)\\Γ + t− 1(i) (13) where θt− 1(i) is a payoﬀ threshold, Υ t− 1(i) is called an extended neighbor set, and the function argmaxk(·) is to ﬁnd k neighbors with the ﬁrst k largest payoﬀs in the set Γ t− 1(i) ⋃ Υ t− 1(i). Here, two LRR functions L1 i(·) and L2 i(·) are designed. The function L1 i(·) always observes an extended neighbor set formed by half neighbor s of a data 7point X i, α = ⌈ 0.5 × | Γ t− 1(i)| ⌉ , where the symbol ⌈·⌉ is to take an integer part of a number satisfying the integer part is no larger than the nu mber. Next, the payoﬀ threshold θ1 t− 1(i) is set by θ1 t− 1(i) = findα ({zt− 1(i),j ∈ Γ t− 1(i)}), where the function findα (·) is to ﬁnd the α-th largest payoﬀ in a set that contains all neighbors’ payoﬀs of the data point. When the LRR fun ction L1 i(·) is applied, the links connecting to the neighbors with small payoﬀs are removed and meanwhile new links are created between the data point and foun d players with higher payoﬀs. Hence, according to Eq.(13), the new neighbor set is Γ t(i) = L1 i(ˆzt− 1(i)). Unlike the LRR function L1 i(·), the LRR function L2 i(·) adjusts the number of neighbors dynamically instead of the constant number of neighbo rs in L1 i(·). Therefore, the payoﬀ threshold θ2 t− 1(i) takes the average of neighbors’ payoﬀs, θ2 t− 1(i) = ∑ j∈ Γ t− 1(i) zt− 1(i)/ |Γ t− 1(i)|. Next, the set Γ + t− 1(i) is formed according to Eq.(13), Γ + t− 1(i) = {j|zt− 1(j) ≥ θ2 t− 1(i),j ∈ Γ t− 1(i)}, and then the new neigh- bor set is achieved by means of the LRR\n",
      " > 316 [-0.072    0.02963 -0.0891   0.0563   0.06366] satisfying the integer part is no larger than the nu mber. Next, the payoﬀ threshold θ1 t− 1(i) is set by θ1 t− 1(i) = findα ({zt− 1(i),j ∈ Γ t− 1(i)}), where the function findα (·) is to ﬁnd the α-th largest payoﬀ in a set that contains all neighbors’ payoﬀs of the data point. When the LRR fun ction L1 i(·) is applied, the links connecting to the neighbors with small payoﬀs are removed and meanwhile new links are created between the data point and foun d players with higher payoﬀs. Hence, according to Eq.(13), the new neighbor set is Γ t(i) = L1 i(ˆzt− 1(i)). Unlike the LRR function L1 i(·), the LRR function L2 i(·) adjusts the number of neighbors dynamically instead of the constant number of neighbo rs in L1 i(·). Therefore, the payoﬀ threshold θ2 t− 1(i) takes the average of neighbors’ payoﬀs, θ2 t− 1(i) = ∑ j∈ Γ t− 1(i) zt− 1(i)/ |Γ t− 1(i)|. Next, the set Γ + t− 1(i) is formed according to Eq.(13), Γ + t− 1(i) = {j|zt− 1(j) ≥ θ2 t− 1(i),j ∈ Γ t− 1(i)}, and then the new neigh- bor set is achieved by means of the LRR function L2 i(·), Γ t(i) = L2 i(ˆzt− 1(i)). In the case, when the payoﬀs of all neighbors are equal to the pay oﬀ thresh- old θ2 t− 1(i), the output of the LRR function is Γ t(i) = Γ t− 1(i). This may be viewed as self-protective behavior for avoiding a payoﬀ loss due to n o enough information acquired. The LRR function Li(·) expands the view of a player X i, i.e., it makes him observe payoﬀs of players in the extended neighbor set, which pro vides a chance to ﬁnd players with higher payoﬀs around him. If no players with highe r payoﬀs are found in the extended neighbor set, namely min({zt− 1(j),j ∈ Γ t− 1(i)}) ≥ max({zt− 1(h),h ∈ Υ t− 1(i)}), then the output of the LRR function is Γ t(i) = Γ t− 1(i). Otherwise, players with small payoﬀs will be removed together wit h the corresponding links from the neighbor set and link set, and replaced by some found players with higher payoﬀ. This process is repeated till the pa yoﬀs of unlinked players in the extended neighbor set are no larger than tho se of linked neighbors.\n",
      " > 317 [-0.05722  -0.002977 -0.05478   0.06616   0.04736 ] LRR function L2 i(·), Γ t(i) = L2 i(ˆzt− 1(i)). In the case, when the payoﬀs of all neighbors are equal to the pay oﬀ thresh- old θ2 t− 1(i), the output of the LRR function is Γ t(i) = Γ t− 1(i). This may be viewed as self-protective behavior for avoiding a payoﬀ loss due to n o enough information acquired. The LRR function Li(·) expands the view of a player X i, i.e., it makes him observe payoﬀs of players in the extended neighbor set, which pro vides a chance to ﬁnd players with higher payoﬀs around him. If no players with highe r payoﬀs are found in the extended neighbor set, namely min({zt− 1(j),j ∈ Γ t− 1(i)}) ≥ max({zt− 1(h),h ∈ Υ t− 1(i)}), then the output of the LRR function is Γ t(i) = Γ t− 1(i). Otherwise, players with small payoﬀs will be removed together wit h the corresponding links from the neighbor set and link set, and replaced by some found players with higher payoﬀ. This process is repeated till the pa yoﬀs of unlinked players in the extended neighbor set are no larger than tho se of linked neighbors. Since the links among players, namely the link set E0 in the network G0(X ,E 0,d ), are changed by the LRR function, the network Gt(X ,E t,d ) has begun to evolve over time, when t≥ 1. Gt(X ,E t,d ) =                X (t) = { X i(t),i = 1 , 2, · · · ,N } Γ t(i) = Li(ˆzt− 1(i)) Et = ⋃ N i=1 Et(i) Et(i) = { et ( X i, X j ) | j ∈ Γ t(i) } (14) 3.3 Strength of links updating After the LRR function is applied, the strength of links of players ne eds to be formed and adjusted. The new strength of links of a player X i ∈ X is formed by means of the below formulation. ρt(X i, X j ) =      P h∈ Γ t− 1 (i)\\{ Γ t− 1(i) T Γ t(i)} ρt− 1 (X i, X h) ⏐ ⏐ ⏐Γ t(i)\\ { Γ t− 1(i) T Γ t(i) }⏐ ⏐ ⏐ j ∈ Γ t(i)\\ { Γ t− 1(i) ⋂ Γ t(i) } ρt− 1(X i, X j ) otherwise (15) 8Then, the player adjusts the strength of links as follows. First, he ﬁnds a neighbor X m with maximal payoﬀ in his neighbor set, m= argmax j∈ Γ t(i) ({ zt− 1(j),j ∈ Γ t(i) }) (16) Next, the strength of link ρt(X i, X j ),j ∈ Γ t(i) is taken its\n",
      " > 318 [-0.07184  0.0149  -0.08014  0.08     0.05338] neighbors. Since the links among players, namely the link set E0 in the network G0(X ,E 0,d ), are changed by the LRR function, the network Gt(X ,E t,d ) has begun to evolve over time, when t≥ 1. Gt(X ,E t,d ) =                X (t) = { X i(t),i = 1 , 2, · · · ,N } Γ t(i) = Li(ˆzt− 1(i)) Et = ⋃ N i=1 Et(i) Et(i) = { et ( X i, X j ) | j ∈ Γ t(i) } (14) 3.3 Strength of links updating After the LRR function is applied, the strength of links of players ne eds to be formed and adjusted. The new strength of links of a player X i ∈ X is formed by means of the below formulation. ρt(X i, X j ) =      P h∈ Γ t− 1 (i)\\{ Γ t− 1(i) T Γ t(i)} ρt− 1 (X i, X h) ⏐ ⏐ ⏐Γ t(i)\\ { Γ t− 1(i) T Γ t(i) }⏐ ⏐ ⏐ j ∈ Γ t(i)\\ { Γ t− 1(i) ⋂ Γ t(i) } ρt− 1(X i, X j ) otherwise (15) 8Then, the player adjusts the strength of links as follows. First, he ﬁnds a neighbor X m with maximal payoﬀ in his neighbor set, m= argmax j∈ Γ t(i) ({ zt− 1(j),j ∈ Γ t(i) }) (16) Next, the strength of link ρt(X i, X j ),j ∈ Γ t(i) is taken its square root and the player X m’s strength of the link becomes negative, { {√ ρt(X i, X j ),j ∈ Γ t(i) } √ ρt(X i, X m) = − √ ρt(X i, X m),m ∈ Γ t(i) (17) Further, let Avet(i) = ( ∑ j∈ Γ t(i) √ ρt(X i, X m))/ |Γ t(i)|, thus, the updated strength of link is ρt(X i, X j ) = ( 2 × Avet(i) − √ ρt(X i, X j ) ) 2 ,j ∈ Γ t(i). (18) The above-mentioned method is a variant of the Grover iteration G in the quantum search algorithm [3], a well-known algorithm in quantum compu tation, which is a way to adjust the probability amplitude of each term in a supe rposi- tion state. By adjustment, the probability amplitude of the wanted is increased, while the others are reduced. This whole process may be regarded a s the in- version about average operation [3]. For our case, each strength of link is taken its square root ﬁrst, and then the average Avet(i) of square roots is computed. Finally, all values are inverted about the average. There are three main reasons that we select the modiﬁed Grover iteration to update the strengt h\n",
      " > 319 [-0.07355  0.03973 -0.1035   0.08203  0.0392 ] square root and the player X m’s strength of the link becomes negative, { {√ ρt(X i, X j ),j ∈ Γ t(i) } √ ρt(X i, X m) = − √ ρt(X i, X m),m ∈ Γ t(i) (17) Further, let Avet(i) = ( ∑ j∈ Γ t(i) √ ρt(X i, X m))/ |Γ t(i)|, thus, the updated strength of link is ρt(X i, X j ) = ( 2 × Avet(i) − √ ρt(X i, X j ) ) 2 ,j ∈ Γ t(i). (18) The above-mentioned method is a variant of the Grover iteration G in the quantum search algorithm [3], a well-known algorithm in quantum compu tation, which is a way to adjust the probability amplitude of each term in a supe rposi- tion state. By adjustment, the probability amplitude of the wanted is increased, while the others are reduced. This whole process may be regarded a s the in- version about average operation [3]. For our case, each strength of link is taken its square root ﬁrst, and then the average Avet(i) of square roots is computed. Finally, all values are inverted about the average. There are three main reasons that we select the modiﬁed Grover iteration to update the strengt h of links: (a) the sum of updated strength of links retains one, ∑ j∈ Γ t(i) ρt(X i, X j ) = 1, (b) certain strength of links between a player and his neighbors is much la rger than the others, ρt(X i, X j ) ≫ ρt(X i, X h),h ∈ Γ t(i)\\j, after the strength of links is updated, and (c) it helps players’ payoﬀs to follow a power law distr ibution, in which only a few players’ payoﬀs are far larger than others’ in the end of iterations. Besides, the process that all players adjust their strength is ord er irrelevant, because the strength of links of all players is updated synchronou sly, and the network is a directed network, so the strength cannot be overrid den by other players. When the strength of links of each player has been update d, an iteration is completed. In conclusion, when t≥ 1 , the structure of network representing connections among players begins to evolve over time. 4 Discussions In the section, ﬁrstly, the relationship between the number of nea rest neigh- bors and the number of clusters is discussed,\n",
      " > 320 [-0.0495    0.011536 -0.0895    0.04968   0.05057 ] h of links: (a) the sum of updated strength of links retains one, ∑ j∈ Γ t(i) ρt(X i, X j ) = 1, (b) certain strength of links between a player and his neighbors is much la rger than the others, ρt(X i, X j ) ≫ ρt(X i, X h),h ∈ Γ t(i)\\j, after the strength of links is updated, and (c) it helps players’ payoﬀs to follow a power law distr ibution, in which only a few players’ payoﬀs are far larger than others’ in the end of iterations. Besides, the process that all players adjust their strength is ord er irrelevant, because the strength of links of all players is updated synchronou sly, and the network is a directed network, so the strength cannot be overrid den by other players. When the strength of links of each player has been update d, an iteration is completed. In conclusion, when t≥ 1 , the structure of network representing connections among players begins to evolve over time. 4 Discussions In the section, ﬁrstly, the relationship between the number of nea rest neigh- bors and the number of clusters is discussed, and then how the cos t in the SD-like payoﬀ matrix inﬂuences the results is analyzed, which provide s a way to choose the proportional factor. Finally, the total payoﬀs based on two diﬀerent payoﬀ matrices are compared and the relationship between the tot al payoﬀs and the rates of convergence of algorithms is explained. 94.1 Number of nearest neighbors vs. number of clusters The number k of nearest neighbors represents the number of neighbors to which a data point (player) X i ∈ X connects. For a dataset, the number k of nearest neighbors determines the number of clusters in part. G enerally speaking, the number of clusters decreases inversely with the num ber k of nearest neighbors. For example, when the number k of nearest neighbors is small, it is indicated that the player X i connects to only a few neighbors. At this time only those not-too-distance neighbors can be observed by the LRR fu nction, which means that the elements in the union of the extended neighbor set Υ t− 1(i) and the neighbor set Γ\n",
      " > 321 [-0.04623  0.01811 -0.0835   0.03766  0.05136] discussed, and then how the cos t in the SD-like payoﬀ matrix inﬂuences the results is analyzed, which provide s a way to choose the proportional factor. Finally, the total payoﬀs based on two diﬀerent payoﬀ matrices are compared and the relationship between the tot al payoﬀs and the rates of convergence of algorithms is explained. 94.1 Number of nearest neighbors vs. number of clusters The number k of nearest neighbors represents the number of neighbors to which a data point (player) X i ∈ X connects. For a dataset, the number k of nearest neighbors determines the number of clusters in part. G enerally speaking, the number of clusters decreases inversely with the num ber k of nearest neighbors. For example, when the number k of nearest neighbors is small, it is indicated that the player X i connects to only a few neighbors. At this time only those not-too-distance neighbors can be observed by the LRR fu nction, which means that the elements in the union of the extended neighbor set Υ t− 1(i) and the neighbor set Γ t− 1(i) are few. Therefore, when the evolution of the network formed by players is ended, many small clusters are established amo ng data points. On the other hand, a big number k of nearest neighbors provides more neighbors for each player, as speciﬁes that the cardinality of the u nion is larger than that when a small k is taken. This means that more neighbors can be observed and explored by the LRR function, so that big clusters co ntaining more data points are formed. For a dataset, the clustering results at the diﬀerent number k of nearest neighbors have been illustrated in Fig. 2, in which each data point only c onnects to one of its neighbors who has the largest strength of link, and clus ters are represented by diﬀerent signs. As is shown in Fig. 2, it can be found t hat only a few data points receive considerable links, whereas most of da ta points have only one link. This implies that when the structure of network te nds to stability, the network, if only the links with the largest strength are remained,\n",
      " > 322 [-0.0527   0.01236 -0.0629   0.05722  0.0506 ] Γ t− 1(i) are few. Therefore, when the evolution of the network formed by players is ended, many small clusters are established amo ng data points. On the other hand, a big number k of nearest neighbors provides more neighbors for each player, as speciﬁes that the cardinality of the u nion is larger than that when a small k is taken. This means that more neighbors can be observed and explored by the LRR function, so that big clusters co ntaining more data points are formed. For a dataset, the clustering results at the diﬀerent number k of nearest neighbors have been illustrated in Fig. 2, in which each data point only c onnects to one of its neighbors who has the largest strength of link, and clus ters are represented by diﬀerent signs. As is shown in Fig. 2, it can be found t hat only a few data points receive considerable links, whereas most of da ta points have only one link. This implies that when the structure of network te nds to stability, the network, if only the links with the largest strength are remained, is characterized by the scale-free network [29], i.e., winner takes all. Besides, in Fig. 2(a), six clusters are obtained by the clustering algorithm, whe n k= 9. As the number k of nearest neighbors rises, four clusters are obtained when k= 12, three clusters when k= 16. So, if the exact number of clusters is not known in advance, diﬀerent numbers of clusters may be achieved by adjust ing the number of nearest neighbors in practice. −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (a) k = 9 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (b) k = 12 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (c) k = 16 Figure 2: The number of nearest neighbors vs. number of clusters . (a) six clusters are obtained, when the number of nearest neighbors is k = 9. (b) four clusters, when k= 12. (c) three clusters, when k= 16 4.2 Eﬀect of the cost c in the SD-like payoﬀ matrix In the Snowdrift game, if the cost is too high, the SD-like payoﬀ matr ix recovers the PD-like payoﬀ matrix [28]. Therefore, the proportio\n",
      " > 323 [-0.01903  0.0201  -0.0449   0.0488   0.069  ] remained, is characterized by the scale-free network [29], i.e., winner takes all. Besides, in Fig. 2(a), six clusters are obtained by the clustering algorithm, whe n k= 9. As the number k of nearest neighbors rises, four clusters are obtained when k= 12, three clusters when k= 16. So, if the exact number of clusters is not known in advance, diﬀerent numbers of clusters may be achieved by adjust ing the number of nearest neighbors in practice. −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (a) k = 9 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (b) k = 12 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (c) k = 16 Figure 2: The number of nearest neighbors vs. number of clusters . (a) six clusters are obtained, when the number of nearest neighbors is k = 9. (b) four clusters, when k= 12. (c) three clusters, when k= 16 4.2 Eﬀect of the cost c in the SD-like payoﬀ matrix In the Snowdrift game, if the cost is too high, the SD-like payoﬀ matr ix recovers the PD-like payoﬀ matrix [28]. Therefore, the proportio nal factor β is restricted in an interval (0 , 0.5]. However, diﬀerent costs will bring about 10the changes of the payoﬀ matrix, which means that diﬀerent cluste ring results will be produced even in the same algorithm. Figure 3 illustrates how th e clustering results change at the diﬀerent number k of nearest neighbors when the proportional factor β takes diﬀerent values, in which the clustering results are represented by clustering accuracies. The deﬁnition of cluste ring accuracy is given below. Deﬁnition 4clusteri is the label which is assigned to a data point Xi in a dataset by the algorithm, and labeli is the actual label of the data point Xi in the dataset. So the clustering accuracy is [30]: accuracy = PN i=1 λ ( map(clusteri ),label i ) N λ(map(clusteri),label i) = { 1 if map(clusteri) = labeli 0 otherwise (19) where the mapping function map(·) maps the label got by the algorithm to the actual label. Clustering accuracy is an important evaluation criterion for clustering algo- rithms, which reﬂects\n",
      " > 324 [ 0.01163  0.03546 -0.03046  0.04572  0.05652] proportio nal factor β is restricted in an interval (0 , 0.5]. However, diﬀerent costs will bring about 10the changes of the payoﬀ matrix, which means that diﬀerent cluste ring results will be produced even in the same algorithm. Figure 3 illustrates how th e clustering results change at the diﬀerent number k of nearest neighbors when the proportional factor β takes diﬀerent values, in which the clustering results are represented by clustering accuracies. The deﬁnition of cluste ring accuracy is given below. Deﬁnition 4clusteri is the label which is assigned to a data point Xi in a dataset by the algorithm, and labeli is the actual label of the data point Xi in the dataset. So the clustering accuracy is [30]: accuracy = PN i=1 λ ( map(clusteri ),label i ) N λ(map(clusteri),label i) = { 1 if map(clusteri) = labeli 0 otherwise (19) where the mapping function map(·) maps the label got by the algorithm to the actual label. Clustering accuracy is an important evaluation criterion for clustering algo- rithms, which reﬂects the level of matches between the actual lab els in a dataset and the labels assigned by a clustering algorithm, so that the goal of a clustering algorithm is to obtain higher clustering accuracies. As is shown in Figure 3, it can be seen that similar results are obtained b y the algorithm at diﬀerent costs, and the best results are produce d when k = 7 and k= 8, but from the Figure 3(b), the clustering result with the largest mean and the least variance is yielded when β = 0 .3. Also, as mentioned above, the high cost leads to the recovery of the SD-like payoﬀ matrix, so the p roportional factor β = 0 .2 or β = 0 .3 is recommended. 4 5 6 7 8 9 10 11 12 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy beta=0.1 beta=0.2 beta=0.3 beta=0.4 beta=0.5 (a) 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.8 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 1 proportional factor beta mean and variance of results (b) Figure 3: The eﬀect of the cost for the clustering results.\n",
      " > 325 [-0.01971  0.01633 -0.05966  0.04413  0.05753] reﬂects the level of matches between the actual lab els in a dataset and the labels assigned by a clustering algorithm, so that the goal of a clustering algorithm is to obtain higher clustering accuracies. As is shown in Figure 3, it can be seen that similar results are obtained b y the algorithm at diﬀerent costs, and the best results are produce d when k = 7 and k= 8, but from the Figure 3(b), the clustering result with the largest mean and the least variance is yielded when β = 0 .3. Also, as mentioned above, the high cost leads to the recovery of the SD-like payoﬀ matrix, so the p roportional factor β = 0 .2 or β = 0 .3 is recommended. 4 5 6 7 8 9 10 11 12 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy beta=0.1 beta=0.2 beta=0.3 beta=0.4 beta=0.5 (a) 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.8 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 1 proportional factor beta mean and variance of results (b) Figure 3: The eﬀect of the cost for the clustering results. (a) the results of the algorithm using the SD-like payoﬀ matrix at diﬀerent number k of nearest neighbors. (b) the mean and variance corresponding to each curv e in (a). 4.3 Total payoﬀs and the rate of convergence In this subsection, at ﬁrst, the total payoﬀs of algorithms using t he PD- or SD-like payoﬀ matrix are compared respectively, and then the diﬀer ences be- tween total payoﬀs are explained. Later, the rates of converge nce of algorithms 11are discussed when two LRR functions are applied respectively, and further the impact for the rates of convergence is analyzed in two payoﬀ matric es. If all other conditions are ﬁxed, an algorithm will form two versions d ue to using PD- or SD-like payoﬀ matrix, and naturally this will bring diﬀerent results. As compared with the PD-like payoﬀ matrix, the payoﬀ P and S in the SD-like payoﬀ matrix have a reverse order in the payoﬀ inequality. In all algo rithms, the relationship between the total payoﬀs and the number of iteration s is drawn in Figure 4. From Figure\n",
      " > 326 [-0.04013   0.002272 -0.05338   0.01984   0.057   ] results. (a) the results of the algorithm using the SD-like payoﬀ matrix at diﬀerent number k of nearest neighbors. (b) the mean and variance corresponding to each curv e in (a). 4.3 Total payoﬀs and the rate of convergence In this subsection, at ﬁrst, the total payoﬀs of algorithms using t he PD- or SD-like payoﬀ matrix are compared respectively, and then the diﬀer ences be- tween total payoﬀs are explained. Later, the rates of converge nce of algorithms 11are discussed when two LRR functions are applied respectively, and further the impact for the rates of convergence is analyzed in two payoﬀ matric es. If all other conditions are ﬁxed, an algorithm will form two versions d ue to using PD- or SD-like payoﬀ matrix, and naturally this will bring diﬀerent results. As compared with the PD-like payoﬀ matrix, the payoﬀ P and S in the SD-like payoﬀ matrix have a reverse order in the payoﬀ inequality. In all algo rithms, the relationship between the total payoﬀs and the number of iteration s is drawn in Figure 4. From Figure 4, it can be found that the total payoﬀs in the algorithms with SD-like payoﬀ matrix are larger than that of the algorithms with P D-like payoﬀ matrix no matter which LRR function is selected. 1 2 3 4 5 6 7 8 9 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1(a) 1 2 3 4 5 6 7 8 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Figure 4: The total payoﬀs vs. the rates of convergence. (a) to tal payoﬀs of algorithms in the case of LRR function L1 i(·), (b) total payoﬀs of algorithms in the case of LRR function L2 i(·) Remark 1 The algorithms are named as follows. For example, the name of an algorithm, QGC1PDL1, denotes that the Case 1, PD-like payoﬀ matrix and the LRR function L1 i(·) are employed in this algorithm. According to two payoﬀ matrices, using Eq.(11), each player’s expe cted pay- oﬀ can be calculated in two cases of strategies respectively as below . Case 1: PD : zt(X i, X j ) = { 1\n",
      " > 327 [-0.02438  0.0194  -0.0369   0.01086  0.05002] Figure 4, it can be found that the total payoﬀs in the algorithms with SD-like payoﬀ matrix are larger than that of the algorithms with P D-like payoﬀ matrix no matter which LRR function is selected. 1 2 3 4 5 6 7 8 9 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1(a) 1 2 3 4 5 6 7 8 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Figure 4: The total payoﬀs vs. the rates of convergence. (a) to tal payoﬀs of algorithms in the case of LRR function L1 i(·), (b) total payoﬀs of algorithms in the case of LRR function L2 i(·) Remark 1 The algorithms are named as follows. For example, the name of an algorithm, QGC1PDL1, denotes that the Case 1, PD-like payoﬀ matrix and the LRR function L1 i(·) are employed in this algorithm. According to two payoﬀ matrices, using Eq.(11), each player’s expe cted pay- oﬀ can be calculated in two cases of strategies respectively as below . Case 1: PD : zt(X i, X j ) = { 1 4 (0.6ω + 0.01ω + ω + 0.2ω) = 0 .4525ω 1 2 (0.6ω + 0.01ω) = 0 .305ω (20) SD : zt(X i, X j ) = { 1 4 (ω − c 2 + ω − c+ ω + 0.01ω) = 1 4 (3.01 − 3α 2 )ω 1 2 (ω − c 2 + ω − c) = 1 2 (2 − 3α 2 )ω (21) Case 2: PD : zt(X i, X j ) =      ρ1ρ20.6ω + ρ2(1 − ρ1)0.01ω +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.2ω (1 − ρ1)0.6ω + ρ10.01ω (22) SD : zt(X i, X j ) =      ρ1ρ2(ω − c 2 ) + ρ2(1 − ρ1)(ω − c) +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.01ω (1 − ρ1)(ω − c 2 ) + ρ1(ω − c) (23) 12Comparing the expected payoﬀs in two cases, it can be observed th at when the SD-like payoﬀ matrix is used, the expected payoﬀ is larger than t hat of using PD-like payoﬀ matrix regardless of cases of strategies. Therefor e, this explains why diﬀerences between total payoﬀs are produced. Besides, Figure 4 not only describes the changes of total payoﬀs o f algo- rithms, but also reﬂects the rates of convergence of algorithms. When the total payoﬀs remain constant or ﬂuctuate slightly, this means that the a lgorithms have converged. At this time, players\n",
      " > 328 [-0.02736   0.01327  -0.05307   0.013016  0.06384 ] 1 4 (0.6ω + 0.01ω + ω + 0.2ω) = 0 .4525ω 1 2 (0.6ω + 0.01ω) = 0 .305ω (20) SD : zt(X i, X j ) = { 1 4 (ω − c 2 + ω − c+ ω + 0.01ω) = 1 4 (3.01 − 3α 2 )ω 1 2 (ω − c 2 + ω − c) = 1 2 (2 − 3α 2 )ω (21) Case 2: PD : zt(X i, X j ) =      ρ1ρ20.6ω + ρ2(1 − ρ1)0.01ω +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.2ω (1 − ρ1)0.6ω + ρ10.01ω (22) SD : zt(X i, X j ) =      ρ1ρ2(ω − c 2 ) + ρ2(1 − ρ1)(ω − c) +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.01ω (1 − ρ1)(ω − c 2 ) + ρ1(ω − c) (23) 12Comparing the expected payoﬀs in two cases, it can be observed th at when the SD-like payoﬀ matrix is used, the expected payoﬀ is larger than t hat of using PD-like payoﬀ matrix regardless of cases of strategies. Therefor e, this explains why diﬀerences between total payoﬀs are produced. Besides, Figure 4 not only describes the changes of total payoﬀs o f algo- rithms, but also reﬂects the rates of convergence of algorithms. When the total payoﬀs remain constant or ﬂuctuate slightly, this means that the a lgorithms have converged. At this time, players do not frequently apply the L RR function to change his neighbors but reach a stable state. As mentioned in th e section 3.2, the LRR function L2 i(·) only can observe an extended neighbor set formed by those larger-than-average neighbors in contrast to an exten ded neighbor set built by half neighbors in the LRR function L1 i(·). Generally speaking, for the same k, the median of payoﬀs is smaller than or equal to the mean, i.e., θ1 t− 1 ≤ θ2 t− 1, which means that the exploring area of the LRR function L1 i(·) is larger than that of the LRR function L2 i(·). So, as a whole, the algorithms with the LRR function L2 i(·) are slightly faster than that with the LRR function L1 i(·), i.e., the number of iterations that the former type of algorithms n eeds is a little less. Furthermore, in the algorithms, a phenomenon that the strategie s ˆH and ˆFt− 1 are more likely used by players in a high density area while the strategy ˆD is used by those in a low density area is always observed. This is becaus e usually they\n",
      " > 329 [-0.02954  0.04028 -0.09076  0.0686   0.03513] players do not frequently apply the L RR function to change his neighbors but reach a stable state. As mentioned in th e section 3.2, the LRR function L2 i(·) only can observe an extended neighbor set formed by those larger-than-average neighbors in contrast to an exten ded neighbor set built by half neighbors in the LRR function L1 i(·). Generally speaking, for the same k, the median of payoﬀs is smaller than or equal to the mean, i.e., θ1 t− 1 ≤ θ2 t− 1, which means that the exploring area of the LRR function L1 i(·) is larger than that of the LRR function L2 i(·). So, as a whole, the algorithms with the LRR function L2 i(·) are slightly faster than that with the LRR function L1 i(·), i.e., the number of iterations that the former type of algorithms n eeds is a little less. Furthermore, in the algorithms, a phenomenon that the strategie s ˆH and ˆFt− 1 are more likely used by players in a high density area while the strategy ˆD is used by those in a low density area is always observed. This is becaus e usually they are mutually neighbors in the high density area on the weig hted and directed knn network, but in the low density area this case is rev erse. As a result, the diﬀerences of payoﬀs between the high density and low d ensity areas are enlarged rapidly for the expected payoﬀ in the strategy proﬁle ( ˆH, ˆH) or ( ˆFt− 1, ˆFt− 1) is higher than that in other strategy proﬁle, and this also cause th e distribution of players’ payoﬀs follows a power-law distribution, whic h is why algorithms converge fast. 5 Simulations To evaluate these clustering algorithms, six datasets are selected from UCI repository [31], which are Soybean, Iris, Wine, Sonar, Ionosphere and Breast cancer Wisconsin datasets, and complete the simulations on them. I n this sec- tion, ﬁrstly these datasets are brieﬂy introduced, and then the s imulation results are demonstrated. The original data points in above datasets all are scattered in high d imen- sional spaces spanned by their features which are the individual me asurable heuristic properties\n",
      " > 330 [-0.0354   0.02625 -0.08484  0.05518  0.01907] they are mutually neighbors in the high density area on the weig hted and directed knn network, but in the low density area this case is rev erse. As a result, the diﬀerences of payoﬀs between the high density and low d ensity areas are enlarged rapidly for the expected payoﬀ in the strategy proﬁle ( ˆH, ˆH) or ( ˆFt− 1, ˆFt− 1) is higher than that in other strategy proﬁle, and this also cause th e distribution of players’ payoﬀs follows a power-law distribution, whic h is why algorithms converge fast. 5 Simulations To evaluate these clustering algorithms, six datasets are selected from UCI repository [31], which are Soybean, Iris, Wine, Sonar, Ionosphere and Breast cancer Wisconsin datasets, and complete the simulations on them. I n this sec- tion, ﬁrstly these datasets are brieﬂy introduced, and then the s imulation results are demonstrated. The original data points in above datasets all are scattered in high d imen- sional spaces spanned by their features which are the individual me asurable heuristic properties of the phenomena being observed, where the description of all datasets is summarized in Table 4. As for Breast dataset, some lo st features are replaced by random numbers, and the Wine dataset is standard ized. Finally, the algorithms are coded in Matlab 6.5. Throughout all simulations, data points in a dataset are viewed as pla yers in quantum games whose initial positions are taken from the dataset . Next, the initial network representing relations among data points are creat ed according to Def.1, after a distance function is selected, which only needs to s atisfy that the more similar data points are, the smaller the output of the funct ion is. In 13Table 4: Description of datasets. Dataset Instances Features classes Soybean 47 21 4 Iris 150 4 3 Wine 178 13 3 Sonar 208 60 2 Ionosphere 351 32 2 Breast 699 9 2 the simulations, the distance function is employed as following d ( X i, X j ) = exp ( ∥X i − X j ∥/ 2σ2 ) ,i,j = 1 , 2, · · · ,N (24) where the symbol ∥ · ∥ represents L2-norm. The advantage of this\n",
      " > 331 [-0.06152  0.01698 -0.0767   0.02129  0.02588] properties of the phenomena being observed, where the description of all datasets is summarized in Table 4. As for Breast dataset, some lo st features are replaced by random numbers, and the Wine dataset is standard ized. Finally, the algorithms are coded in Matlab 6.5. Throughout all simulations, data points in a dataset are viewed as pla yers in quantum games whose initial positions are taken from the dataset . Next, the initial network representing relations among data points are creat ed according to Def.1, after a distance function is selected, which only needs to s atisfy that the more similar data points are, the smaller the output of the funct ion is. In 13Table 4: Description of datasets. Dataset Instances Features classes Soybean 47 21 4 Iris 150 4 3 Wine 178 13 3 Sonar 208 60 2 Ionosphere 351 32 2 Breast 699 9 2 the simulations, the distance function is employed as following d ( X i, X j ) = exp ( ∥X i − X j ∥/ 2σ2 ) ,i,j = 1 , 2, · · · ,N (24) where the symbol ∥ · ∥ represents L2-norm. The advantage of this function is that it not only satisﬁes our requirements, but also overcomes the drawbacks of Euclidean distance. For instance, when two points are very close, t he output of Euclidean distance function approaches zero, which may make the c omputation of payoﬀ fail due to the payoﬀ approaching inﬁnite. Nevertheless, when Eq.(24) is selected as the distance function, it is more convenient to comput e the players’ payoﬀs, since its minimum is one and the reciprocals of its output are b etween zero and one, 1 /d (X i, X j ) ∈ [0, 1]. In addition, the distance between a player X i and itself, d(X i, X i), is one according to the deﬁned distance function, which means that initially he is one of his k nearest neighbors. So there is an edge between the player X i and himself, namely a self-loop. Additionally, the parameter σ in Eq.(24) takes one. As is analyzed in the section 4.2, the cost c in SD-like payoﬀ matrix is set by c= 0 .2ωt(X i, X j ) in the related clustering algorithms. The clustering algorithms are applied\n",
      " > 332 [-0.05334  0.0254  -0.0778   0.0483   0.0645 ] this function is that it not only satisﬁes our requirements, but also overcomes the drawbacks of Euclidean distance. For instance, when two points are very close, t he output of Euclidean distance function approaches zero, which may make the c omputation of payoﬀ fail due to the payoﬀ approaching inﬁnite. Nevertheless, when Eq.(24) is selected as the distance function, it is more convenient to comput e the players’ payoﬀs, since its minimum is one and the reciprocals of its output are b etween zero and one, 1 /d (X i, X j ) ∈ [0, 1]. In addition, the distance between a player X i and itself, d(X i, X i), is one according to the deﬁned distance function, which means that initially he is one of his k nearest neighbors. So there is an edge between the player X i and himself, namely a self-loop. Additionally, the parameter σ in Eq.(24) takes one. As is analyzed in the section 4.2, the cost c in SD-like payoﬀ matrix is set by c= 0 .2ωt(X i, X j ) in the related clustering algorithms. The clustering algorithms are applied on the six datasets respective ly. Be- cause two cases of strategies are designed and the diﬀerent payo ﬀ matrices and LRR functions are employed, the algorithms are run on every datas et at the diﬀerent number k of nearest neighbors. As is analyzed in section 4.1, for a dataset the number k of clusters decreases inversely with the number of nearest neighbors. When a small k is selected, it is possible that the number of clusters is larger than the preset number of the dataset, after the algorit hm is ended. So a merging-subroutine is called to merge unwanted clusters, which wo rks in this way. At ﬁrst, the cluster with the fewest data points is identiﬁed, a nd then it is merged to the cluster whose distance between their centroids is sm allest. This subroutine is repeated till the number of clusters is equal to the pr eset number. The clustering results obtained by these algorithms are compared in Fig. 5, in which each point represents a clustering accuracy. As is shown in F ig. 5, the similar results are obtained\n",
      " > 333 [-0.03195  0.03436 -0.05872  0.04764  0.03087] applied on the six datasets respective ly. Be- cause two cases of strategies are designed and the diﬀerent payo ﬀ matrices and LRR functions are employed, the algorithms are run on every datas et at the diﬀerent number k of nearest neighbors. As is analyzed in section 4.1, for a dataset the number k of clusters decreases inversely with the number of nearest neighbors. When a small k is selected, it is possible that the number of clusters is larger than the preset number of the dataset, after the algorit hm is ended. So a merging-subroutine is called to merge unwanted clusters, which wo rks in this way. At ﬁrst, the cluster with the fewest data points is identiﬁed, a nd then it is merged to the cluster whose distance between their centroids is sm allest. This subroutine is repeated till the number of clusters is equal to the pr eset number. The clustering results obtained by these algorithms are compared in Fig. 5, in which each point represents a clustering accuracy. As is shown in F ig. 5, the similar results are obtained by these algorithms at diﬀerent number o f nearest neighbors, but almost all the best results are obtained by the algor ithms using the LRR function L1 i(·). Further, we show a simple comparison with three other algorithms: K means [32, 33], PCA-Kmeans [33], LDA-Km [33]. The Kmeans algorithm is a popular clu s- tering algorithm because it is easy to implement. It begins with k randomly- chosen cluster centers, and then assigns each data point in a data set to the closest cluster center. Next, the cluster centers are recomput ed according to the current cluster memberships. This process will be repeated till a co nvergence 142 2.5 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(a) Soybean dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b)\n",
      " > 334 [-0.00983  0.05737 -0.04077  0.0264   0.0439 ] obtained by these algorithms at diﬀerent number o f nearest neighbors, but almost all the best results are obtained by the algor ithms using the LRR function L1 i(·). Further, we show a simple comparison with three other algorithms: K means [32, 33], PCA-Kmeans [33], LDA-Km [33]. The Kmeans algorithm is a popular clu s- tering algorithm because it is easy to implement. It begins with k randomly- chosen cluster centers, and then assigns each data point in a data set to the closest cluster center. Next, the cluster centers are recomput ed according to the current cluster memberships. This process will be repeated till a co nvergence 142 2.5 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(a) Soybean dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Iris dataset 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(c) Wine dataset 3 3.5 4 4.5 5 5.5 6 6.5 7 7.5 8 0.4 0.42 0.44 0.46 0.48 0.5 0.52 0.54 0.56 0.58 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(d) Sonar dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(e) Ionosphere dataset 3 4 5 6 7 8 9 10 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(f) breast dataset Figure 5: Comparison of clustering accuracies at diﬀerent k in all proposed algorithms. criterion is met. However, its major problem is sensitive to the selection of the initial partition [19]. The PCA-Kmeans algorithm consists\n",
      " > 335 [-0.01743  0.06824 -0.0454   0.02567  0.05627] QGC2SDL2(b) Iris dataset 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(c) Wine dataset 3 3.5 4 4.5 5 5.5 6 6.5 7 7.5 8 0.4 0.42 0.44 0.46 0.48 0.5 0.52 0.54 0.56 0.58 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(d) Sonar dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(e) Ionosphere dataset 3 4 5 6 7 8 9 10 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(f) breast dataset Figure 5: Comparison of clustering accuracies at diﬀerent k in all proposed algorithms. criterion is met. However, its major problem is sensitive to the selection of the initial partition [19]. The PCA-Kmeans algorithm consists of two steps : (1) Re- duce the data dimension by principal component analysis (PCA); (2) Clustering data points by the Kmeans algorithm. Ding et al combine linear discrimin ant analysis (LDA) with the Kmeans algorithm, and construct a new clust ering algorithm called ’LDA-Km’. In the LDA-Km algorithm, Kmeans is used to generate class labels, while LDA is used to do subspace selection. Finally, in the subspace selection process, data points are clustered. Our algorithms are established on the model of quantum games, so d ata points in datasets are considered as players. This idea is totally diﬀer ent from traditional clustering algorithms, such as Kmeans and its variants, because in traditional clustering algorithms data points for clustering are ﬁxe d, and various functions or methods are designed to ﬁnd cluster centers or sepa rating hyper- planes, whereas in the quantum-game-based clustering algorithms data points (players) themselves choose their clusters, which leads clusters a re formed au- tomatically\n",
      " > 336 [-0.04974  0.04187 -0.06616  0.05817  0.0587 ] consists of two steps : (1) Re- duce the data dimension by principal component analysis (PCA); (2) Clustering data points by the Kmeans algorithm. Ding et al combine linear discrimin ant analysis (LDA) with the Kmeans algorithm, and construct a new clust ering algorithm called ’LDA-Km’. In the LDA-Km algorithm, Kmeans is used to generate class labels, while LDA is used to do subspace selection. Finally, in the subspace selection process, data points are clustered. Our algorithms are established on the model of quantum games, so d ata points in datasets are considered as players. This idea is totally diﬀer ent from traditional clustering algorithms, such as Kmeans and its variants, because in traditional clustering algorithms data points for clustering are ﬁxe d, and various functions or methods are designed to ﬁnd cluster centers or sepa rating hyper- planes, whereas in the quantum-game-based clustering algorithms data points (players) themselves choose their clusters, which leads clusters a re formed au- tomatically during quantum games. In conclusion, traditional cluste ring algo- rithms do it from outside, while ours are from inside. Furthermore, o ur algo- rithms do not need to choose cluster centers at beginning, so ther e does not exist the problem that is ”sensitive to the selection of the initial partition” . Besides, distances between data points are commonly used as the measurem ent of their similarities in the Kmeans algorithm and its variants. However, when sim ilar- ities are measured in our algorithms, not only distances between dat a points but also their degrees and the strength of links are integrated, wh ich provides more information for the measurement of similarities. Later, accor ding to pay- oﬀs in quantum games, players apply a LRR function to change the st ructure of the network, which makes the clusters emerge. As a result, bet ter clustering accuracies are obtained by our algorithms. Table 5 displays the clustering accuracies of our algorithms and the o ther 15three algorithms using the datasets\n",
      " > 337 [-0.03598  0.05893 -0.05222  0.06726  0.0683 ] tomatically during quantum games. In conclusion, traditional cluste ring algo- rithms do it from outside, while ours are from inside. Furthermore, o ur algo- rithms do not need to choose cluster centers at beginning, so ther e does not exist the problem that is ”sensitive to the selection of the initial partition” . Besides, distances between data points are commonly used as the measurem ent of their similarities in the Kmeans algorithm and its variants. However, when sim ilar- ities are measured in our algorithms, not only distances between dat a points but also their degrees and the strength of links are integrated, wh ich provides more information for the measurement of similarities. Later, accor ding to pay- oﬀs in quantum games, players apply a LRR function to change the st ructure of the network, which makes the clusters emerge. As a result, bet ter clustering accuracies are obtained by our algorithms. Table 5 displays the clustering accuracies of our algorithms and the o ther 15three algorithms using the datasets in Table 4. It can be observed t hat on almost all datasets the quantum game based clustering algorithms h ave the best clustering accuracies. Only on the Iris dataset, the LDA-Km a lgorithm is better than ours, but our result is close to it as well. The Iris datase t contains three clusters, one of which is far from the other two, so data poin ts in it can be clustered easily and correctly. The other clusters in the Iris dataset, however, are mixed partly in their boundaries, which brings a diﬃculty for clustering. These mixed boundary points may be assigned to diﬀeren t clusters by algorithms, which is why the clustering accuracies of algorithms ar e various. It is more diﬃcult to cluster data points in the Sonar and Ionosphere dataset, because in these two datasets plenty of data points belonging to diﬀ erent clusters are mixed together. Therefore, the clustering accuracies of algo rithms in them are not high, and it is rather hard to improve the clustering accurac ies even by several percents. From the\n",
      " > 338 [-0.0413   0.0601  -0.03014  0.0352   0.0681 ] datasets in Table 4. It can be observed t hat on almost all datasets the quantum game based clustering algorithms h ave the best clustering accuracies. Only on the Iris dataset, the LDA-Km a lgorithm is better than ours, but our result is close to it as well. The Iris datase t contains three clusters, one of which is far from the other two, so data poin ts in it can be clustered easily and correctly. The other clusters in the Iris dataset, however, are mixed partly in their boundaries, which brings a diﬃculty for clustering. These mixed boundary points may be assigned to diﬀeren t clusters by algorithms, which is why the clustering accuracies of algorithms ar e various. It is more diﬃcult to cluster data points in the Sonar and Ionosphere dataset, because in these two datasets plenty of data points belonging to diﬀ erent clusters are mixed together. Therefore, the clustering accuracies of algo rithms in them are not high, and it is rather hard to improve the clustering accurac ies even by several percents. From the ﬁfth and sixth columns in Table 5, it c an be seen that the quantum game based clustering algorithms are bette r than other algorithms, which indicates the eﬀectiveness of our algorithms. Table 5: Comparison of clustering accuracies of algorithms. Algorithm Soybean Iris Wine Sonar Ionosphere Breast QGC1PDL1 97.9% 92.0% 94.9% 54.8% 75.5% 95.4% QGC1SDL1 95.6% 90.7% 96.6% 56.3% 74.1% 95.4% QGC2PDL1 95.6% 91.3% 96.6% 55.8% 73.8% 95.4% QGC2SDL1 89.4% 91.3% 96.6% 55.8% 75.5% 95.3% QGC1PDL2 95.8% 96.7% 95.5% 54.3% 74.1% 95.0% QGC1SDL2 89.4% 90.7% 95.5% 54.3% 74.6% 95.1% QGC2PDL2 89.4% 90.0% 95.5% 55.3% 74.6% 95.3% QGC2SDL2 89.4% 91.3% 94.9% 55.8% 74.9% 95.1% Kmeans [33] 68.1% 89.3% 70.2% 47.2% 71.0% – PCA-Kmeans [33] 72.3% 88.7% 70.2% 45.3% 71.0% – LDA-Km [33] 76.6% 98.0% 82.6% 51.0% 71.2% – 6 Conclusions The enormous successes gained by the quantum algorithms make us realize it is possible that the quantum algorithms can obtain solutions faster and bet- ter than those classical algorithms for some problems. Therefore\n",
      " > 339 [-0.06934  0.03693 -0.05267  0.0658   0.0585 ] the ﬁfth and sixth columns in Table 5, it c an be seen that the quantum game based clustering algorithms are bette r than other algorithms, which indicates the eﬀectiveness of our algorithms. Table 5: Comparison of clustering accuracies of algorithms. Algorithm Soybean Iris Wine Sonar Ionosphere Breast QGC1PDL1 97.9% 92.0% 94.9% 54.8% 75.5% 95.4% QGC1SDL1 95.6% 90.7% 96.6% 56.3% 74.1% 95.4% QGC2PDL1 95.6% 91.3% 96.6% 55.8% 73.8% 95.4% QGC2SDL1 89.4% 91.3% 96.6% 55.8% 75.5% 95.3% QGC1PDL2 95.8% 96.7% 95.5% 54.3% 74.1% 95.0% QGC1SDL2 89.4% 90.7% 95.5% 54.3% 74.6% 95.1% QGC2PDL2 89.4% 90.0% 95.5% 55.3% 74.6% 95.3% QGC2SDL2 89.4% 91.3% 94.9% 55.8% 74.9% 95.1% Kmeans [33] 68.1% 89.3% 70.2% 47.2% 71.0% – PCA-Kmeans [33] 72.3% 88.7% 70.2% 45.3% 71.0% – LDA-Km [33] 76.6% 98.0% 82.6% 51.0% 71.2% – 6 Conclusions The enormous successes gained by the quantum algorithms make us realize it is possible that the quantum algorithms can obtain solutions faster and bet- ter than those classical algorithms for some problems. Therefore , we combine the quantum game with the problem of data clustering, and establish clustering algorithms based on quantum games. In the algorithms, data points for clus- tering are regarded as players who can make decisions in quantum ga mes. On a weighted and directed knn network that represents relations am ong players, each player uses quantum strategies against every one of his neigh bors in a 2 × 2 entangled quantum game respectively. We design two cases of stra tegies: (i) one plays the strategy ˆH, the other plays the strategy ˆH or ˆD, (ii) one plays the strategy ˆFt− 1, the other plays the strategy ˆFt− 1 or ˆD according to the strength of links, in each of which players’ expected payoﬀs are calculated ba sed on the PD- and SD-like payoﬀ matrices respectively. According to neighbor s’ payoﬀs in one’s neighbor set, each player applies a LRR function ( L1 i(·) or L2 i(·)) to change his neighbors, i.e., the links connecting to neighbors with small payoﬀs 16are removed and then new links are created to those\n",
      " > 340 [-0.09705  0.03864 -0.07306  0.0976   0.04666] Therefore , we combine the quantum game with the problem of data clustering, and establish clustering algorithms based on quantum games. In the algorithms, data points for clus- tering are regarded as players who can make decisions in quantum ga mes. On a weighted and directed knn network that represents relations am ong players, each player uses quantum strategies against every one of his neigh bors in a 2 × 2 entangled quantum game respectively. We design two cases of stra tegies: (i) one plays the strategy ˆH, the other plays the strategy ˆH or ˆD, (ii) one plays the strategy ˆFt− 1, the other plays the strategy ˆFt− 1 or ˆD according to the strength of links, in each of which players’ expected payoﬀs are calculated ba sed on the PD- and SD-like payoﬀ matrices respectively. According to neighbor s’ payoﬀs in one’s neighbor set, each player applies a LRR function ( L1 i(·) or L2 i(·)) to change his neighbors, i.e., the links connecting to neighbors with small payoﬀs 16are removed and then new links are created to those with higher pay oﬀs. Later, the Grover iteration G is employed to update the strength of links between him and his neighbors. In the process of playing quantum game, the s tructure of the network formed by players tends to stability gradually. In ot her words, each player always connects to one of his neighbors with the largest strength or jumps among some neighbors with the largest strength in a constan t period. At this time, if only the links with the largest strength are left but all oth er links are removed among players, the network naturally divides into seve ral separate parts, each of which corresponds to a cluster. Additionally, in simulations, it can be found that the total expected p ayoﬀs of algorithms using SD-like payoﬀ matrix are higher than that of algorith ms using PD-like payoﬀ matrix. Later, the reason is explained. Further, we o bserve that the rates of convergence of the algorithms employing the LRR func tion L2 i(·) are faster slightly than that of the algorithms employing the LRR fun\n",
      " > 341 [-0.063    0.02512 -0.09094  0.0871   0.0464 ] those with higher pay oﬀs. Later, the Grover iteration G is employed to update the strength of links between him and his neighbors. In the process of playing quantum game, the s tructure of the network formed by players tends to stability gradually. In ot her words, each player always connects to one of his neighbors with the largest strength or jumps among some neighbors with the largest strength in a constan t period. At this time, if only the links with the largest strength are left but all oth er links are removed among players, the network naturally divides into seve ral separate parts, each of which corresponds to a cluster. Additionally, in simulations, it can be found that the total expected p ayoﬀs of algorithms using SD-like payoﬀ matrix are higher than that of algorith ms using PD-like payoﬀ matrix. Later, the reason is explained. Further, we o bserve that the rates of convergence of the algorithms employing the LRR func tion L2 i(·) are faster slightly than that of the algorithms employing the LRR fun ction L1 i(·), because more areas are explored by the LRR function L1 i(·), but this brings better clustering results. In the case when the exact numb er of clusters is unknown in advance, one can adjust the number k of nearest neighbors to control the number of clusters, where the number of clusters de creases inversely with the number k of nearest neighbors. Finally, the clustering algorithms are evaluated on six real datasets, and simulation results have demons trated that data points in a dataset are clustered reasonably and eﬃciently. Acknowledgments The authors would like to thank the anonymous referees for their h elpful comments and suggestions to improve the presentation of this pap er. This work was supported in part by the National Natural Science Foundation of China (No. 60405012, No. 60675055). References [1] V. Vedral and M. Plenio, “Basics of quantum computation,” Progress in Quantum Electronics , vol. 22, no. 1, pp. 1–39, 1998. [2] P. W. Shor, “Algorithms for quantum computation: discrete loga\n",
      " > 342 [-0.06177  0.02408 -0.07837  0.0834   0.05624] fun ction L1 i(·), because more areas are explored by the LRR function L1 i(·), but this brings better clustering results. In the case when the exact numb er of clusters is unknown in advance, one can adjust the number k of nearest neighbors to control the number of clusters, where the number of clusters de creases inversely with the number k of nearest neighbors. Finally, the clustering algorithms are evaluated on six real datasets, and simulation results have demons trated that data points in a dataset are clustered reasonably and eﬃciently. Acknowledgments The authors would like to thank the anonymous referees for their h elpful comments and suggestions to improve the presentation of this pap er. This work was supported in part by the National Natural Science Foundation of China (No. 60405012, No. 60675055). References [1] V. Vedral and M. Plenio, “Basics of quantum computation,” Progress in Quantum Electronics , vol. 22, no. 1, pp. 1–39, 1998. [2] P. W. Shor, “Algorithms for quantum computation: discrete loga rithms and factoring,” in Proc. of the 35th Annual Symposium on Foundations of Computer Science , pp. 124–134, 1994. [3] L. K. Grover, “Quantum mechanics helps in searching for a needle in a haystack,” Physical Review Letters , vol. 79, no. 2, p. 325, 1997. [4] G. Brassard, P. Høyer, and A. Tapp, “Quantum counting,” in Automata, Languages and Programming , vol. 1443, pp. 820–831, 1998. [5] D. A. Meyer, “Quantum strategies,” Physical Review Letters , vol. 82, no. 5, p. 1052, 1999. [6] J. Eisert, M. Wilkens, and M. Lewenstein, “Quantum games and qu antum strategies,” Physical Review Letters , vol. 83, no. 15, p. 3077, 1999. 17[7] A. P. Flitney and D. Abbott, “Advantage of a quantum player ove r a classical one in 2 x 2 quantum games,” Proceedings of the Royal Society B: Biological Sciences, vol. 459, no. 2038, p. 2463, 2003. [8] L. Marinatto and T. Weber, “A quantum approach to static game s of com- plete information,” Physics Letters A , vol. 272, no. 5-6, pp. 291–303, 2000. [9] C. F. Lee and N. F. Johnson, “Eﬃciency\n",
      " > 343 [-0.1021   0.00499 -0.04684  0.05148  0.0535 ] rithms and factoring,” in Proc. of the 35th Annual Symposium on Foundations of Computer Science , pp. 124–134, 1994. [3] L. K. Grover, “Quantum mechanics helps in searching for a needle in a haystack,” Physical Review Letters , vol. 79, no. 2, p. 325, 1997. [4] G. Brassard, P. Høyer, and A. Tapp, “Quantum counting,” in Automata, Languages and Programming , vol. 1443, pp. 820–831, 1998. [5] D. A. Meyer, “Quantum strategies,” Physical Review Letters , vol. 82, no. 5, p. 1052, 1999. [6] J. Eisert, M. Wilkens, and M. Lewenstein, “Quantum games and qu antum strategies,” Physical Review Letters , vol. 83, no. 15, p. 3077, 1999. 17[7] A. P. Flitney and D. Abbott, “Advantage of a quantum player ove r a classical one in 2 x 2 quantum games,” Proceedings of the Royal Society B: Biological Sciences, vol. 459, no. 2038, p. 2463, 2003. [8] L. Marinatto and T. Weber, “A quantum approach to static game s of com- plete information,” Physics Letters A , vol. 272, no. 5-6, pp. 291–303, 2000. [9] C. F. Lee and N. F. Johnson, “Eﬃciency and formalism of quantum games,” Physical Review A , vol. 67, no. 2, p. 022311, 2003. [10] J. Du, H. Li, X. Xu, M. Shi, J. Wu, X. Zhou, and R. Han, “Experime ntal realization of quantum games on a quantum computer,” Physical Review Letters, vol. 88, no. 13, p. 137902, 2002. [11] R. Prevedel, A. Stefanov, P. Walther, and A. Zeilinger, “Exper imental realization of a quantum game on a one-way quantum computer,” New Journal of Physics , vol. 5, pp. 205–215, 2007. [12] C. Schmid, A. P. Flitney, W. Wieczorek, N. Kiesel, H. Weinfurter, and L. C. L. Hollenberg, “Experimental implementation of a four-player quan- tum game,” arXiv:0901.0063v1, 2009. [13] H. Guo, J. Zhang, and G. J. Koehler, “A survey of quantum gam es,” De- cision Support Systems , vol. 46, no. 1, pp. 318–332, 2008. [14] D. Horn and A. Gottlieb, “Algorithm for data clustering in patter n recog- nition problems based on quantum mechanics,” Physical Review Letters , vol. 88, no. 1, p. 018702, 2001. [15] M. Sasaki and A. Carlini, “Quantum learning and\n",
      " > 344 [-0.09515  0.01851 -0.0461   0.04675  0.04745] “Eﬃciency and formalism of quantum games,” Physical Review A , vol. 67, no. 2, p. 022311, 2003. [10] J. Du, H. Li, X. Xu, M. Shi, J. Wu, X. Zhou, and R. Han, “Experime ntal realization of quantum games on a quantum computer,” Physical Review Letters, vol. 88, no. 13, p. 137902, 2002. [11] R. Prevedel, A. Stefanov, P. Walther, and A. Zeilinger, “Exper imental realization of a quantum game on a one-way quantum computer,” New Journal of Physics , vol. 5, pp. 205–215, 2007. [12] C. Schmid, A. P. Flitney, W. Wieczorek, N. Kiesel, H. Weinfurter, and L. C. L. Hollenberg, “Experimental implementation of a four-player quan- tum game,” arXiv:0901.0063v1, 2009. [13] H. Guo, J. Zhang, and G. J. Koehler, “A survey of quantum gam es,” De- cision Support Systems , vol. 46, no. 1, pp. 318–332, 2008. [14] D. Horn and A. Gottlieb, “Algorithm for data clustering in patter n recog- nition problems based on quantum mechanics,” Physical Review Letters , vol. 88, no. 1, p. 018702, 2001. [15] M. Sasaki and A. Carlini, “Quantum learning and universal quant um matching machine,” Physical Review A , vol. 66, no. 2, p. 022303, 2002. [16] C. A. Trugenberger, “Quantum pattern recognition,” Quantum Informa- tion Processing, vol. 1, no. 6, pp. 471–493, 2002. [17] R. Sch¨ utzhold, “Pattern recognition on a quantum computer ,” Physical Review A , vol. 67, no. 6, p. 062311, 2003. [18] E. A¨ ımeur, G. Brassard, and S. Gambs, “Quantum clustering a lgorithms,” in Proceedings of the 24th International Conference on Machin e Learning , (Corvallis, OR), 2007. [19] A. K. Jain, M. N. Murty, and P. J. Flynn, “Data clustering: a rev iew,” ACM Computing Surveys , vol. 31, no. 3, pp. 264–323, 1999. [20] A. Ekert, P. M. Hayden, and H. Inamori, “Course 10: Basic con cepts in quantum computation,” in Coherent atomic matter waves , vol. 72, p. 661, Springer Berlin / Heidelberg, 2001. [21] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information. Cambridge: Cambridge University Press, 20002005. [22] J. Nash, “Equilibrium points in n-person games,” Proceedings\n",
      " > 345 [-0.0788    0.013435 -0.051     0.07117   0.04196 ] and universal quant um matching machine,” Physical Review A , vol. 66, no. 2, p. 022303, 2002. [16] C. A. Trugenberger, “Quantum pattern recognition,” Quantum Informa- tion Processing, vol. 1, no. 6, pp. 471–493, 2002. [17] R. Sch¨ utzhold, “Pattern recognition on a quantum computer ,” Physical Review A , vol. 67, no. 6, p. 062311, 2003. [18] E. A¨ ımeur, G. Brassard, and S. Gambs, “Quantum clustering a lgorithms,” in Proceedings of the 24th International Conference on Machin e Learning , (Corvallis, OR), 2007. [19] A. K. Jain, M. N. Murty, and P. J. Flynn, “Data clustering: a rev iew,” ACM Computing Surveys , vol. 31, no. 3, pp. 264–323, 1999. [20] A. Ekert, P. M. Hayden, and H. Inamori, “Course 10: Basic con cepts in quantum computation,” in Coherent atomic matter waves , vol. 72, p. 661, Springer Berlin / Heidelberg, 2001. [21] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information. Cambridge: Cambridge University Press, 20002005. [22] J. Nash, “Equilibrium points in n-person games,” Proceedings of the Na- tional Academy of Sciences , vol. 36, pp. 48–49, 1950. 18[23] J. Nash, “Non-cooperative games,” The Annals of Mathematics , vol. 54, no. 2, pp. 286–295, 1951. [24] D. Fudenberg and J. Tirole, Game Theory . MIT Press, 1983. [25] S. C. Benjamin and P. M. Hayden, “Multiplayer quantum games,” Physical Review A , vol. 64, no. 3, p. 030301, 2001. [26] J. Du, H. Li, X. Xu, M. Shi, X. Zhou, and R. Han, “Entanglement c orre- lated phase changes in quantum games,” Arxiv preprint quant-ph/0111138 , 2001. [27] J. Du, H. Li, X. Xu, X. Zhou, and R. Han, “Phase-transition-like behaviour of quantum games,” Journal of Physics A: Mathematical and Theoretical , vol. 36, pp. 6551–6562, 2003. [28] C. Hauert and M. Doebeli, “Spatial structure often inhibits the evolution of cooperation in the snowdrift game,” Nature, vol. 428, no. 6983, pp. 643– 646, 2004. [29] A.-L. Barab´ asi and E. Bonabeau, “Scale-free networks,” Scientiﬁc Ameri- can, vol. 288, no. 5, pp. 60–69, 2003. [30] G. Erkan, “Language model-based document\n",
      " > 346 [-0.06805    0.0004191 -0.06152    0.06555    0.02615  ] Proceedings of the Na- tional Academy of Sciences , vol. 36, pp. 48–49, 1950. 18[23] J. Nash, “Non-cooperative games,” The Annals of Mathematics , vol. 54, no. 2, pp. 286–295, 1951. [24] D. Fudenberg and J. Tirole, Game Theory . MIT Press, 1983. [25] S. C. Benjamin and P. M. Hayden, “Multiplayer quantum games,” Physical Review A , vol. 64, no. 3, p. 030301, 2001. [26] J. Du, H. Li, X. Xu, M. Shi, X. Zhou, and R. Han, “Entanglement c orre- lated phase changes in quantum games,” Arxiv preprint quant-ph/0111138 , 2001. [27] J. Du, H. Li, X. Xu, X. Zhou, and R. Han, “Phase-transition-like behaviour of quantum games,” Journal of Physics A: Mathematical and Theoretical , vol. 36, pp. 6551–6562, 2003. [28] C. Hauert and M. Doebeli, “Spatial structure often inhibits the evolution of cooperation in the snowdrift game,” Nature, vol. 428, no. 6983, pp. 643– 646, 2004. [29] A.-L. Barab´ asi and E. Bonabeau, “Scale-free networks,” Scientiﬁc Ameri- can, vol. 288, no. 5, pp. 60–69, 2003. [30] G. Erkan, “Language model-based document clustering using r andom walks,” in Proceedings of the main conference on Human Language Tech- nology Conference of the North American Chapter of the Assoc iation of Computational Linguistics , (New York, New York), Association for Com- putational Linguistics, 2006. [31] A. Asuncion and D. J. Newman, UCI Machine Learning Repository (http://www.ics.uci.edu/ mlearn/MLRepository.html). Irvine, CA: Univer- sity of California, School of Information and Computer Science, 20 07. [32] J. MacQueen, “Some methods for classiﬁcation and analysis of m ultivariate observations,” in Proceedings of Fifth Berkeley Symposium on Mathematical Statistics and Probability , vol. 1, (Statistical Laboratory of the University of California, Berkeley), pp. 281–297, 1967. [33] C. Ding and T. Li, “Adaptive dimension reduction using discriminant anal- ysis and k-means clustering,” in Proceedings of the 24th International Con- ference on Machine Learning , (Corvallis, OR), pp. 521–528, 2007. 19−5 −4 −3 −2 −1 0 1 2 3 −4 −3 −2 −1 0 1 2 3\n",
      " > 347 [-0.07306  0.0328  -0.0647   0.0735   0.0431 ] arXiv:0812.0743v2 [cs.LG] 10 Oct 2009 A Novel Clustering Algorithm Based on Quantum Games Qiang Li, Yan He, Jing-ping Jiang College of Electrical Engineering, Zhejiang University, Hang Zhou, Zhejiang, 310027, China May 28, 2018 Abstract The enormous successes have been made by quantum algorithms dur- ing the last decade. In this paper, we combine the quantum gam e with the problem of data clustering, and then develop a quantum-g ame-based clustering algorithm, in which data points in a dataset are c onsidered as players who can make decisions and implement quantum stra tegies in quantum games. After each round of a quantum game, each playe r’s ex- pected payoﬀ is calculated. Later, he uses an link-removing -and-rewiring (LRR) function to change his neighbors and adjust the streng th of links connecting to them in order to maximize his payoﬀ. Further, a lgorithms are discussed and analyzed in two cases of strategies, two pa yoﬀ ma- trixes and two LRR functions. Consequently, the simulation results have demonstrated that data points in datasets are clustered rea sonably and eﬃciently, and the clustering algorithms have fast rates of convergence. Moreover, the comparison with other algorithms also provid es an indica- tion of the eﬀectiveness of the proposed approach. Keywords: Unsupervised learning; Data clustering; Quantum compu- tation; Quantum game 1 Introduction Quantum computation is an extremely exciting and rapidly growing ﬁeld . More recently, an increasing number of researchers with diﬀerent backgrounds, ranging from physics, computer sciences and information theory t o mathematics and philosophy, are involved in researching properties of quantum- based com- putation [1]. During the last decade, a series of signiﬁcant breakthr oughs had been made. One was that in 1994 Peter Shor surprised the world by p roposing a polynomial-time quantum algorithm for integer factorization [2], while in the classical world the best-known classical factoring algorithm works in superpoly- nomial time. Three years later, in 1997, Lov Grover proved that a q uantum computer could search an unsorted database in the square root o f the time [3]. Meanwhile, Gilles Brassard et al. combined ideas from Grover’s and Sho r’s quantum algorithms to propose a quantum counting algorithm [4]. 1In recent years, many interests focus on the quantum game theo ry and con- siderable work has been done. For instance, D. A. Meyer [5] studied the Penny Flip game in the quantum world ﬁrstly. His result showed that if a player was allowed to implement quantum strategies, he would always defeat his o pponent who played the classical strategies and increase his expected payo ﬀ as well. J. Eisert et al. [6] quantized the Prisoners’ Dilemma and demonstrated that the dilemma could be escaped when both players resort to quantum stra tegies. A. P. Flitney et al. [7] generalized Eisert’s result, the miracle move, i.e., th e result of the game would move towards the quantum player’s preferred re sult, while the other player used classical strategies. L. Marinatto et al. [8] in vestigated the Battle of the Sexes game in quantum domain. Their result showed tha t there existed a unique equilibrium in the game, when the entangled strategie s were allowed. C. F. Lee et al. [9] reported that the quantum game is more eﬃcient than the classical game, and they found an upper bound for this eﬃ ciency. Be- sides, some experiments about the quantum games have also been im plemented on diﬀerent quantum computers [10, 11, 12]. For more details about quantum games, see [13]. Successes achieved by quantum algorithms make us guess that pow erful quantum computers can ﬁgure out solutions faster and better th an the best known classical counterparts for certain types of problems. Fur thermore, it is more important that they oﬀer a new way to ﬁnd potentially dramatic algorith- mic speed-ups. Therefore, we may ask naturally: can we construc t quantum versions of classical algorithms or present new quantum algorithms to solve the problems in pattern recognition faster and better on a quantu m computer? Following this idea, some researchers have proposed their novel me thods and demonstrated exciting results [14, 15, 16, 17, 18]. In addition, data clustering is a main\n",
      " > 348 [-0.0751   0.04443 -0.057    0.0878   0.02463] square root o f the time [3]. Meanwhile, Gilles Brassard et al. combined ideas from Grover’s and Sho r’s quantum algorithms to propose a quantum counting algorithm [4]. 1In recent years, many interests focus on the quantum game theo ry and con- siderable work has been done. For instance, D. A. Meyer [5] studied the Penny Flip game in the quantum world ﬁrstly. His result showed that if a player was allowed to implement quantum strategies, he would always defeat his o pponent who played the classical strategies and increase his expected payo ﬀ as well. J. Eisert et al. [6] quantized the Prisoners’ Dilemma and demonstrated that the dilemma could be escaped when both players resort to quantum stra tegies. A. P. Flitney et al. [7] generalized Eisert’s result, the miracle move, i.e., th e result of the game would move towards the quantum player’s preferred re sult, while the other player used classical strategies. L. Marinatto et al. [8] in vestigated the Battle of the Sexes game in quantum domain. Their result showed tha t there existed a unique equilibrium in the game, when the entangled strategie s were allowed. C. F. Lee et al. [9] reported that the quantum game is more eﬃcient than the classical game, and they found an upper bound for this eﬃ ciency. Be- sides, some experiments about the quantum games have also been im plemented on diﬀerent quantum computers [10, 11, 12]. For more details about quantum games, see [13]. Successes achieved by quantum algorithms make us guess that pow erful quantum computers can ﬁgure out solutions faster and better th an the best known classical counterparts for certain types of problems. Fur thermore, it is more important that they oﬀer a new way to ﬁnd potentially dramatic algorith- mic speed-ups. Therefore, we may ask naturally: can we construc t quantum versions of classical algorithms or present new quantum algorithms to solve the problems in pattern recognition faster and better on a quantu m computer? Following this idea, some researchers have proposed their novel me thods and demonstrated exciting results [14, 15, 16, 17, 18]. In addition, data clustering is a main branch of Pattern Recognition, which is widely used in many ﬁelds such as pattern analysis, data mining, infor ma- tion retrieval and image segmentation. In these ﬁelds, however, t here is usually little priori knowledge available about the data. In response to thes e restric- tions, clustering methodology come into being which is particularly suit able for the exploration of interrelationships among data points. Data clust ering is the formal study of algorithms and methods for grouping or classifying unlabeled data points [19]. In other words, its task is to ﬁnd the inherent stru cture of a given collection of unlabeled data points and group them into meaningf ul clus- ters [19]. In this paper, we attempt to combine the quantum game wit h the problem of data clustering in order to establish a novel clustering alg orithm based on quantum games. In our algorithms, unlabeled data points in a dataset are regarded as players who can make decisions in quantum games. O n a time- varying network formed by players, each player is permitted to use quantum strategies and plays a 2 × 2 entangled quantum game against every one of his neighbors respectively. Later, he applies a link-removing-and-rew iring (LRR) function to remove the links of neighbors with small payoﬀs and crea te new links to neighbors with higher payoﬀs at the same time. Furthermore, th e strength of links between a player and his neighbors is diﬀerent from one anoth er, which is updated by the Grover iteration. During quantum games, the str ucture of network and the strength of links between players tend toward st ability grad- ually. Finally, if each player only connects to the neighbor with the high est strength, the network will naturally divide into several separate p arts, each of which corresponds to a cluster. 2The remainder of this paper is organized as follows: Section 2 introdu ces some important concepts about the quantum computation and the quantum Prisoners’ Dilemma brieﬂy. In Section 3, the algorithms are establish ed in two cases of strategies, payoﬀ matrices and link-removing-and-rewir ing (LRR) func- tions, and then they\n",
      " > 349 [-0.08124  0.03998 -0.05774  0.0983   0.0344 ] main branch of Pattern Recognition, which is widely used in many ﬁelds such as pattern analysis, data mining, infor ma- tion retrieval and image segmentation. In these ﬁelds, however, t here is usually little priori knowledge available about the data. In response to thes e restric- tions, clustering methodology come into being which is particularly suit able for the exploration of interrelationships among data points. Data clust ering is the formal study of algorithms and methods for grouping or classifying unlabeled data points [19]. In other words, its task is to ﬁnd the inherent stru cture of a given collection of unlabeled data points and group them into meaningf ul clus- ters [19]. In this paper, we attempt to combine the quantum game wit h the problem of data clustering in order to establish a novel clustering alg orithm based on quantum games. In our algorithms, unlabeled data points in a dataset are regarded as players who can make decisions in quantum games. O n a time- varying network formed by players, each player is permitted to use quantum strategies and plays a 2 × 2 entangled quantum game against every one of his neighbors respectively. Later, he applies a link-removing-and-rew iring (LRR) function to remove the links of neighbors with small payoﬀs and crea te new links to neighbors with higher payoﬀs at the same time. Furthermore, th e strength of links between a player and his neighbors is diﬀerent from one anoth er, which is updated by the Grover iteration. During quantum games, the str ucture of network and the strength of links between players tend toward st ability grad- ually. Finally, if each player only connects to the neighbor with the high est strength, the network will naturally divide into several separate p arts, each of which corresponds to a cluster. 2The remainder of this paper is organized as follows: Section 2 introdu ces some important concepts about the quantum computation and the quantum Prisoners’ Dilemma brieﬂy. In Section 3, the algorithms are establish ed in two cases of strategies, payoﬀ matrices and link-removing-and-rewir ing (LRR) func- tions, and then they are elaborated and analyzed. In Section 4, th e relationship between the number of nearest neighbors and the number of clust ers is dis- cussed. Next, the eﬀect of the cost in the SD-like payoﬀ matrix is an alyzed, and the relationship between the total payoﬀs and the rates of co nvergence of algorithms is explained. In Section 5, those datasets used in the simu lations are introduced brieﬂy, and then results of algorithms are demonst rated. The conclusion is given in Section 6. 2 Quantum computation and quantum game 2.1 Quantum computation The elementary unit of quantum computation is called the qubit, which is typically a microscopic system, such as an atom, a nuclear spin, or a p olarized photon. In quantum computation, the Boolean states 0 and 1 are r epresented by a prescribed pair of normalized and mutually orthogonal quantum st ates labeled as {|0⟩, |1⟩} to form a ’computational basis’ [20]. Any pure state of the qubit can be written as a superposition state α|0⟩+ β|1⟩ for some α and β satisfying |α|2 + |β|2 = 1 [20]. A collection of n qubits is called a quantum register of size n, which spans a Hilbert space of 2 n dimensions, so 2 n mutually orthogonal quantum states can be available. Quantum state preparations, and any other manipulations on qubit s, have to be performed by unitary operations. A quantum logic gate is a dev ice which performs a ﬁxed unitary operation on selected qubits in a ﬁxed perio d of time, and a quantum circuit is a device consisting of quantum logic gates who se com- putational steps are synchronized in time [20]. The most common qua ntum gate is the Hadamard gate, which acts on a qubit in state |0⟩ or |1⟩ to produce    |0⟩ H − → 1 √ 2 |0⟩+ 1√ 2 |1⟩ |1⟩ H − → 1√ 2 |0⟩ − 1√ 2 |1⟩ ,H = 1√ 2 ( 1 1 1−1 ) . (1) For more details, see [20, 21]. 2.2 Quantum Prisoners’ Dilemma The Prisoners’ Dilemma (PD), a well-known example in the classical gam e theory, is an abstract of many phenomena in the real world and it ha s been wildly used in plenty of scientiﬁc ﬁelds. In this game, each of two player s has two optional strategies, cooperation (C) and defection (D). Lat er, he\n",
      " > 350 [-0.0807   0.01736 -0.08575  0.0808   0.04062] they are elaborated and analyzed. In Section 4, th e relationship between the number of nearest neighbors and the number of clust ers is dis- cussed. Next, the eﬀect of the cost in the SD-like payoﬀ matrix is an alyzed, and the relationship between the total payoﬀs and the rates of co nvergence of algorithms is explained. In Section 5, those datasets used in the simu lations are introduced brieﬂy, and then results of algorithms are demonst rated. The conclusion is given in Section 6. 2 Quantum computation and quantum game 2.1 Quantum computation The elementary unit of quantum computation is called the qubit, which is typically a microscopic system, such as an atom, a nuclear spin, or a p olarized photon. In quantum computation, the Boolean states 0 and 1 are r epresented by a prescribed pair of normalized and mutually orthogonal quantum st ates labeled as {|0⟩, |1⟩} to form a ’computational basis’ [20]. Any pure state of the qubit can be written as a superposition state α|0⟩+ β|1⟩ for some α and β satisfying |α|2 + |β|2 = 1 [20]. A collection of n qubits is called a quantum register of size n, which spans a Hilbert space of 2 n dimensions, so 2 n mutually orthogonal quantum states can be available. Quantum state preparations, and any other manipulations on qubit s, have to be performed by unitary operations. A quantum logic gate is a dev ice which performs a ﬁxed unitary operation on selected qubits in a ﬁxed perio d of time, and a quantum circuit is a device consisting of quantum logic gates who se com- putational steps are synchronized in time [20]. The most common qua ntum gate is the Hadamard gate, which acts on a qubit in state |0⟩ or |1⟩ to produce    |0⟩ H − → 1 √ 2 |0⟩+ 1√ 2 |1⟩ |1⟩ H − → 1√ 2 |0⟩ − 1√ 2 |1⟩ ,H = 1√ 2 ( 1 1 1−1 ) . (1) For more details, see [20, 21]. 2.2 Quantum Prisoners’ Dilemma The Prisoners’ Dilemma (PD), a well-known example in the classical gam e theory, is an abstract of many phenomena in the real world and it ha s been wildly used in plenty of scientiﬁc ﬁelds. In this game, each of two player s has two optional strategies, cooperation (C) and defection (D). Lat er, he chooses one strategy against the other’s for maximizing his own payoﬀ, so do es the other side at the same time, but both sides do not know the opponent’s str ategy. As a result, each player receives a payoﬀ which depends on his selected strategy, where the payoﬀ matrix under diﬀerent strategy proﬁles is describ ed in Table 1. According to the classical game theory, the strategy proﬁle (def ection, defection) 3Table 1: Payoﬀ matrix for the Prisoners’ Dilemma. C = 0 D= 1 C = 0 R= 3 S = 0 D= 1 T = 5 P = 1 is the unique Nash Equilibrium [22, 23], but unfortunately it is not Paret o optimal [24]. In the quantum game, however, thanks to the quantum strategie s, the dilemma in the classical game can be escaped in a restricted strategic space [6]. The physical model of quantum Prisoners’ Dilemma presented by Eis ert [6] is shown in Figure 1. Figure 1: The block diagram of the system. If the possible outcomes of the classical strategies, C = 0 and D = 1, are assigned to two basis vectors {|C = 0 ⟩, |D = 1 ⟩} in Hilbert space respectively, then at any time the state of the game may be represented by a vec tor in the space spanned by the basis {|00⟩, |01⟩, |10⟩, |11⟩} [6]. Assume the initial state of the game is |ψ0⟩ = ˆJ |00⟩, where ˆJ is an entangling operator which is known to both players. For a two-player game with two pure strategies, the general form of ˆJ may be written as [25, 26] ˆJ(γ) = exp(iγ 2 σ⊗ 2 x ) = I⊗ 2cosγ 2 + iσ⊗ 2 x sinγ 2 (2) where γ ∈ [0,π/ 2] is a measure of entanglement of a game. When γ = π/ 2, there is a maximally entangled game, in which the entangling operator t akes form ˆJ(γ) = 1√ 2 (I⊗ 2 + iσ⊗ 2 x ). (3) Next, each player chooses a unitary operator ˆY1( ˆY2) from the strategy space S1(S2) and operates it on the qubit that belongs to him, which makes the ga me in a state ( ˆY1 ⊗ ˆY2) ˆJ|00⟩. Speciﬁcally, the unitary operators ˆC and ˆD that correspond to the strategies, cooperation and defection, are g iven below [6] ˆC = (1 0 0 1 ) , ˆD= ( 0 1 −1 0 ) . (4) In the end, before a projective measurement in the basis {|0⟩, |1⟩} is carried out, the ﬁnal state is |ψf ⟩ = ˆJ†( ˆY1 ⊗ ˆY2)\n",
      " > 351 [-0.08777  0.02959 -0.06793  0.0999   0.05127] chooses one strategy against the other’s for maximizing his own payoﬀ, so do es the other side at the same time, but both sides do not know the opponent’s str ategy. As a result, each player receives a payoﬀ which depends on his selected strategy, where the payoﬀ matrix under diﬀerent strategy proﬁles is describ ed in Table 1. According to the classical game theory, the strategy proﬁle (def ection, defection) 3Table 1: Payoﬀ matrix for the Prisoners’ Dilemma. C = 0 D= 1 C = 0 R= 3 S = 0 D= 1 T = 5 P = 1 is the unique Nash Equilibrium [22, 23], but unfortunately it is not Paret o optimal [24]. In the quantum game, however, thanks to the quantum strategie s, the dilemma in the classical game can be escaped in a restricted strategic space [6]. The physical model of quantum Prisoners’ Dilemma presented by Eis ert [6] is shown in Figure 1. Figure 1: The block diagram of the system. If the possible outcomes of the classical strategies, C = 0 and D = 1, are assigned to two basis vectors {|C = 0 ⟩, |D = 1 ⟩} in Hilbert space respectively, then at any time the state of the game may be represented by a vec tor in the space spanned by the basis {|00⟩, |01⟩, |10⟩, |11⟩} [6]. Assume the initial state of the game is |ψ0⟩ = ˆJ |00⟩, where ˆJ is an entangling operator which is known to both players. For a two-player game with two pure strategies, the general form of ˆJ may be written as [25, 26] ˆJ(γ) = exp(iγ 2 σ⊗ 2 x ) = I⊗ 2cosγ 2 + iσ⊗ 2 x sinγ 2 (2) where γ ∈ [0,π/ 2] is a measure of entanglement of a game. When γ = π/ 2, there is a maximally entangled game, in which the entangling operator t akes form ˆJ(γ) = 1√ 2 (I⊗ 2 + iσ⊗ 2 x ). (3) Next, each player chooses a unitary operator ˆY1( ˆY2) from the strategy space S1(S2) and operates it on the qubit that belongs to him, which makes the ga me in a state ( ˆY1 ⊗ ˆY2) ˆJ|00⟩. Speciﬁcally, the unitary operators ˆC and ˆD that correspond to the strategies, cooperation and defection, are g iven below [6] ˆC = (1 0 0 1 ) , ˆD= ( 0 1 −1 0 ) . (4) In the end, before a projective measurement in the basis {|0⟩, |1⟩} is carried out, the ﬁnal state is |ψf ⟩ = ˆJ†( ˆY1 ⊗ ˆY2) ˆJ |00⟩. (5) Thus, the player’s expected payoﬀ is written as z= R|⟨ψf |00⟩|2 + S|⟨ψf |01⟩|2 + T|⟨ψf |10⟩|2 + P|⟨ψf |11⟩|2. (6) For more details, see [6, 27]. 43 Algorithm In the section, we will combine the model of the quantum game with th e problem of data clustering, and then establish clustering algorithms based on quantum games. Assume an unlabeled dataset X = {X 1, X 2, · · · , X N },which are distributed in a m-dimensional metric space. Each data point in the dataset is considered as a player in quantum games who can make decisions and always hope to maximize his payoﬀ. In the metric space, there is a distance f unction d : X × X − → R, satisfying the closer the two players are, the smaller the output is. Based on the distance function, a k nearest neighbors (knn) network as a weighted and directed network, G0(X ,E 0,d ), may be created among data points by adding k edges directed toward its k nearest neighbors for each player. Deﬁnition 1 If there is a set X with N players, X = {X1, X2, · · · , XN }, the weighted and directed knn network, G0(X,E 0,d ), is created as below.                  X = { Xi,i = 1 , 2, · · · ,N } E0 = ⋃ N i=1 E0(i) E0(i) = { e0 ( Xi, Xj ) | j ∈ Γ 0(i) } Γ 0(i) = { j ⏐ ⏐ ⏐j = argmink Xh∈ X ({ d(Xi, Xh), Xh ∈ X } )} (7) Here, each player in the set X corresponds to a vertex in the network G0(X,E 0,d ); E0 is a link set and a link in the network represents certain rela tionship between a pair of players; the distances denote the weights over link s; the function, argmink(·), is to ﬁnd k nearest neighbors of a player which construct a ne igh- bor set, Γ 0(i); the subscript ’0’ is the initial time step. It is worth noting that the strength of links between a player X i and his k nearest neighbors represented by ρt− 1(X i, X j ),j ∈ Γ t− 1(i)(t ≥ 1) is time- varying, whose initial values is calculated by ρ0(X i, X j) = { 1/ |Γ 0(i)| = 1 /k, j ∈ Γ 0(i) 0, otherwise (8) where the symbol | · | denotes the cardinality of a set. After the initial connections are constructed among players (dat a points), on this weighted and directed knn network, a quantum game\n",
      " > 352 [-0.06647  0.01746 -0.0687   0.0777   0.04587] ˆY2) ˆJ |00⟩. (5) Thus, the player’s expected payoﬀ is written as z= R|⟨ψf |00⟩|2 + S|⟨ψf |01⟩|2 + T|⟨ψf |10⟩|2 + P|⟨ψf |11⟩|2. (6) For more details, see [6, 27]. 43 Algorithm In the section, we will combine the model of the quantum game with th e problem of data clustering, and then establish clustering algorithms based on quantum games. Assume an unlabeled dataset X = {X 1, X 2, · · · , X N },which are distributed in a m-dimensional metric space. Each data point in the dataset is considered as a player in quantum games who can make decisions and always hope to maximize his payoﬀ. In the metric space, there is a distance f unction d : X × X − → R, satisfying the closer the two players are, the smaller the output is. Based on the distance function, a k nearest neighbors (knn) network as a weighted and directed network, G0(X ,E 0,d ), may be created among data points by adding k edges directed toward its k nearest neighbors for each player. Deﬁnition 1 If there is a set X with N players, X = {X1, X2, · · · , XN }, the weighted and directed knn network, G0(X,E 0,d ), is created as below.                  X = { Xi,i = 1 , 2, · · · ,N } E0 = ⋃ N i=1 E0(i) E0(i) = { e0 ( Xi, Xj ) | j ∈ Γ 0(i) } Γ 0(i) = { j ⏐ ⏐ ⏐j = argmink Xh∈ X ({ d(Xi, Xh), Xh ∈ X } )} (7) Here, each player in the set X corresponds to a vertex in the network G0(X,E 0,d ); E0 is a link set and a link in the network represents certain rela tionship between a pair of players; the distances denote the weights over link s; the function, argmink(·), is to ﬁnd k nearest neighbors of a player which construct a ne igh- bor set, Γ 0(i); the subscript ’0’ is the initial time step. It is worth noting that the strength of links between a player X i and his k nearest neighbors represented by ρt− 1(X i, X j ),j ∈ Γ t− 1(i)(t ≥ 1) is time- varying, whose initial values is calculated by ρ0(X i, X j) = { 1/ |Γ 0(i)| = 1 /k, j ∈ Γ 0(i) 0, otherwise (8) where the symbol | · | denotes the cardinality of a set. After the initial connections are constructed among players (dat a points), on this weighted and directed knn network, a quantum game can be d eﬁned as following. Deﬁnition 2A quantum game Ω = {X,G t,S,Z t} on a network Gt is a 4- tuple: X is a set of players; Gt represents the connections among players; S = {s(i),i = 1 , 2, · · · ,N } represents a set of players’ strategies including the full range of quantum strategies; Zt = {zt(i),i = 1 , 2, · · · ,N } represents a set of players’ expected payoﬀs. Here, the variable tdenotes the time step (the number of iterations). In each round, players choose theirs strate gies simultaneously, and each player can only observe its neighbors’ payoﬀs, but d oes not know the strategy proﬁles of all other players in X. 53.1 Cases of quantum strategies and payoﬀ matrices At ﬁrst, each player selects a strategy from his strategy set, an d then plays a 2 × 2 entangled quantum game against one of his k neighbors respectively. In the classical 2 × 2 game, such as the Prisoners’ Dilemma, usually there are only two pure strategies, cooperation and defection, but in the quant um game, one can design diﬀerent unitary operators as strategies, i.e., the stra tegy set S may be identiﬁed with some subset of the group of 2 × 2 unitary matrices [6]. Here, for the purpose of clustering and simplifying computation, the stra tegy set of a player X i is restricted in a set S1 = { ˆH, ˆD} or S2 = { ˆFt− 1(i,j ), ˆD}, and then two cases of strategy sets are described respectively. Case 1: In this case, a player and his opponent can apply strategies inS1 = { ˆH, ˆD}. When a player X i use the Hadamard matrix ˆH as a strategy, his opponent (neighbor) X j has two optional strategies { ˆH, ˆD}, but which strategy is chosen is dependent on the strength of the link between them, as is a rule of the clustering algorithm. If the strength ρt− 1(X j , X i) equals to zero, i.e., there is no link directed from the player X j to the player X i, then the player X j will apply the strategy ’Defection’ ( ˆD). Alternatively, if ρt− 1(X j , X i) >0, namely mutual connections between them, the player X j implements the strategy ˆH. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, by applying the model of the quantum game the ﬁnal state\n",
      " > 353 [-0.08356  0.03017 -0.04272  0.06305  0.065  ] game can be d eﬁned as following. Deﬁnition 2A quantum game Ω = {X,G t,S,Z t} on a network Gt is a 4- tuple: X is a set of players; Gt represents the connections among players; S = {s(i),i = 1 , 2, · · · ,N } represents a set of players’ strategies including the full range of quantum strategies; Zt = {zt(i),i = 1 , 2, · · · ,N } represents a set of players’ expected payoﬀs. Here, the variable tdenotes the time step (the number of iterations). In each round, players choose theirs strate gies simultaneously, and each player can only observe its neighbors’ payoﬀs, but d oes not know the strategy proﬁles of all other players in X. 53.1 Cases of quantum strategies and payoﬀ matrices At ﬁrst, each player selects a strategy from his strategy set, an d then plays a 2 × 2 entangled quantum game against one of his k neighbors respectively. In the classical 2 × 2 game, such as the Prisoners’ Dilemma, usually there are only two pure strategies, cooperation and defection, but in the quant um game, one can design diﬀerent unitary operators as strategies, i.e., the stra tegy set S may be identiﬁed with some subset of the group of 2 × 2 unitary matrices [6]. Here, for the purpose of clustering and simplifying computation, the stra tegy set of a player X i is restricted in a set S1 = { ˆH, ˆD} or S2 = { ˆFt− 1(i,j ), ˆD}, and then two cases of strategy sets are described respectively. Case 1: In this case, a player and his opponent can apply strategies inS1 = { ˆH, ˆD}. When a player X i use the Hadamard matrix ˆH as a strategy, his opponent (neighbor) X j has two optional strategies { ˆH, ˆD}, but which strategy is chosen is dependent on the strength of the link between them, as is a rule of the clustering algorithm. If the strength ρt− 1(X j , X i) equals to zero, i.e., there is no link directed from the player X j to the player X i, then the player X j will apply the strategy ’Defection’ ( ˆD). Alternatively, if ρt− 1(X j , X i) >0, namely mutual connections between them, the player X j implements the strategy ˆH. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, by applying the model of the quantum game the ﬁnal state of the game is |ψf,j ⟩ = { 1 2 (|00⟩ − i|01⟩ − i|10⟩+ |11⟩), ˆH⊗ ˆH 1√ 2 (i|00⟩ − |01⟩), ˆH⊗ ˆD (9) Case 2: The strategy setS2 = { ˆFt− 1(i,j ), ˆD} is adopted in the case. The strategy ˆFt− 1(i,j ), ˆFt− 1(i,j ) = ( √ ρt− 1(X i, X j ) √ 1 − ρt− 1(X i, X j )√ 1 − ρt− 1(X i, X j ) − √ ρt− 1(X i, X j ) ) , is a general form of Hadamard matrix ˆH whose elements are associated with the strength of links ρt− 1(X i, X j ). When ρt− 1(X i, X j )=0.5, the strategy ˆFt− 1(i,j ) recovers the strategy ˆH. Similarly, the neighbor X j , when ρt− 1(X j , X i) = 0, applies the strategy ’Defection’ ( ˆD), while using the strategy ˆFt− 1(i,j ) when ρt− 1(X j , X i) > 0. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, after their moves, the ﬁnal state of the game is |ψf,j ⟩ =      √ ρ1ρ2|00⟩ − i √ ρ2(1 − ρ1)|01⟩ −i √ ρ1(1 − ρ2)|10⟩+ √ (1 − ρ1)(1 − ρ2)|11⟩, ˆFt− 1 ⊗ ˆFt− 1 i√1 − ρ1|00⟩ − √ρ1|01⟩, ˆFt− 1 ⊗ ˆD . (10) According to the payoﬀ matrix, the player’s expected payoﬀ can be computed by zt− 1(i) = ∑ j∈ Γ t− 1 (i) zt− 1(X i, X j ) = ∑ j∈ Γ t− 1 (i) R|⟨ψf,j |00⟩|2 + S|⟨ψf,j |01⟩|2 + T|⟨ψf,j |10⟩|2 + P|⟨ψf,j |11⟩|2. (11) 6In practice, the payoﬀ matrix takes PD-like or Snowdrift (SD)-like f orm, de- scribed in Table 2 and 3. In the PD-like payoﬀ matrix, the following inequ ali- Table 2: PD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= 0 .6ωt− 1(X i, X j ) S = 0 .01ωt− 1(X i, X j ) D= 1 T = ωt− 1(X i, X j ) P = 0 .2ωt− 1(X i, X j ) Table 3: SD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= ωt− 1(X i, X j ) − c 2 S = ωt− 1(X i, X j ) − c D= 1 T = ωt− 1(X i, X j ) P = 0 .01ωt− 1(X i, X j ) ties holds: T >R>P >S and 2 R>T + S [28]. To avoid a case that a player’s expected payoﬀ is zero, the variable S in Table 2 takes a small value instead of zero in Table 1. In addition, the Snowdrift game assumes that two drivers are blocked by a snowdrift, each of whom is in either side of the snowd rift. If they want to go back home, one of them or both must shovel a path through the snowdrift. So, there exists a cost c in the SD-like payoﬀ matrix and the following inequality holds: T > R > S > P[28], where c = β · ωt− 1(X i, X j ) and β\n",
      " > 354 [-0.0821  -0.0094  -0.05487  0.0709   0.0426 ] state of the game is |ψf,j ⟩ = { 1 2 (|00⟩ − i|01⟩ − i|10⟩+ |11⟩), ˆH⊗ ˆH 1√ 2 (i|00⟩ − |01⟩), ˆH⊗ ˆD (9) Case 2: The strategy setS2 = { ˆFt− 1(i,j ), ˆD} is adopted in the case. The strategy ˆFt− 1(i,j ), ˆFt− 1(i,j ) = ( √ ρt− 1(X i, X j ) √ 1 − ρt− 1(X i, X j )√ 1 − ρt− 1(X i, X j ) − √ ρt− 1(X i, X j ) ) , is a general form of Hadamard matrix ˆH whose elements are associated with the strength of links ρt− 1(X i, X j ). When ρt− 1(X i, X j )=0.5, the strategy ˆFt− 1(i,j ) recovers the strategy ˆH. Similarly, the neighbor X j , when ρt− 1(X j , X i) = 0, applies the strategy ’Defection’ ( ˆD), while using the strategy ˆFt− 1(i,j ) when ρt− 1(X j , X i) > 0. If the initial state of the game is |ψ0⟩ = ˆJ|00⟩, after their moves, the ﬁnal state of the game is |ψf,j ⟩ =      √ ρ1ρ2|00⟩ − i √ ρ2(1 − ρ1)|01⟩ −i √ ρ1(1 − ρ2)|10⟩+ √ (1 − ρ1)(1 − ρ2)|11⟩, ˆFt− 1 ⊗ ˆFt− 1 i√1 − ρ1|00⟩ − √ρ1|01⟩, ˆFt− 1 ⊗ ˆD . (10) According to the payoﬀ matrix, the player’s expected payoﬀ can be computed by zt− 1(i) = ∑ j∈ Γ t− 1 (i) zt− 1(X i, X j ) = ∑ j∈ Γ t− 1 (i) R|⟨ψf,j |00⟩|2 + S|⟨ψf,j |01⟩|2 + T|⟨ψf,j |10⟩|2 + P|⟨ψf,j |11⟩|2. (11) 6In practice, the payoﬀ matrix takes PD-like or Snowdrift (SD)-like f orm, de- scribed in Table 2 and 3. In the PD-like payoﬀ matrix, the following inequ ali- Table 2: PD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= 0 .6ωt− 1(X i, X j ) S = 0 .01ωt− 1(X i, X j ) D= 1 T = ωt− 1(X i, X j ) P = 0 .2ωt− 1(X i, X j ) Table 3: SD-like payoﬀ matrix. C = 0 D= 1 C = 0 R= ωt− 1(X i, X j ) − c 2 S = ωt− 1(X i, X j ) − c D= 1 T = ωt− 1(X i, X j ) P = 0 .01ωt− 1(X i, X j ) ties holds: T >R>P >S and 2 R>T + S [28]. To avoid a case that a player’s expected payoﬀ is zero, the variable S in Table 2 takes a small value instead of zero in Table 1. In addition, the Snowdrift game assumes that two drivers are blocked by a snowdrift, each of whom is in either side of the snowd rift. If they want to go back home, one of them or both must shovel a path through the snowdrift. So, there exists a cost c in the SD-like payoﬀ matrix and the following inequality holds: T > R > S > P[28], where c = β · ωt− 1(X i, X j ) and β is a proportional factor. Besides, the variable ωt− 1(X i, X j ) in two payoﬀ matrices is calculated by the formulation below. ωt− 1(X i, X j ) = ρt− 1(X i, X j ) × Degt− 1(X j )/d (X i, X j ) (12) 3.2 Design of LRR functions When all players’ payoﬀs have been computed, each player will obse rve his neighbors’ payoﬀs, and apply a link-removing-and-rewiring (LRR) f unction Li(·) to change his links. A LRR function is deﬁned as below. Deﬁnition 3The LRR function Li(·) is a function of payoﬀs, whose output is a set with k elements, namely an updated neighbor set Γ t(i) of a player Xi. It is given as below. Γ t(i) = Li ( ˆzt− 1(i) ) = argmaxk j∈ Γ t− 1 (i) S Υ t− 1(i) ({ zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) }) ˆzt− 1(i) = { zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) } , Υ t− 1(i) = ⋃ j∈ Γ + t− 1 (i) Γ t− 1(j) Γ + t− 1(i) = { j|zt− 1(j) ≥ θt− 1(i),j ∈ Γ t− 1(i) } , Γ − t− 1(i) = Γ t− 1(i)\\Γ + t− 1(i) (13) where θt− 1(i) is a payoﬀ threshold, Υ t− 1(i) is called an extended neighbor set, and the function argmaxk(·) is to ﬁnd k neighbors with the ﬁrst k largest payoﬀs in the set Γ t− 1(i) ⋃ Υ t− 1(i). Here, two LRR functions L1 i(·) and L2 i(·) are designed. The function L1 i(·) always observes an extended neighbor set formed by half neighbor s of a data 7point X i, α = ⌈ 0.5 × | Γ t− 1(i)| ⌉ , where the symbol ⌈·⌉ is to take an integer part of a number satisfying the integer part is no larger than the nu mber. Next, the payoﬀ threshold θ1 t− 1(i) is set by θ1 t− 1(i) = findα ({zt− 1(i),j ∈ Γ t− 1(i)}), where the function findα (·) is to ﬁnd the α-th largest payoﬀ in a set that contains all neighbors’ payoﬀs of the data point. When the LRR fun ction L1 i(·) is applied, the links connecting to the neighbors with small payoﬀs are removed and meanwhile new links are created between the data point and foun d players with higher payoﬀs. Hence, according to Eq.(13), the new neighbor set is Γ t(i) = L1 i(ˆzt− 1(i)). Unlike the LRR function L1 i(·), the LRR function L2 i(·) adjusts the number of neighbors dynamically instead of the constant number of neighbo rs in L1 i(·). Therefore, the payoﬀ threshold θ2 t− 1(i) takes the\n",
      " > 355 [-0.05118  -0.007328 -0.0477    0.04288   0.05246 ] β is a proportional factor. Besides, the variable ωt− 1(X i, X j ) in two payoﬀ matrices is calculated by the formulation below. ωt− 1(X i, X j ) = ρt− 1(X i, X j ) × Degt− 1(X j )/d (X i, X j ) (12) 3.2 Design of LRR functions When all players’ payoﬀs have been computed, each player will obse rve his neighbors’ payoﬀs, and apply a link-removing-and-rewiring (LRR) f unction Li(·) to change his links. A LRR function is deﬁned as below. Deﬁnition 3The LRR function Li(·) is a function of payoﬀs, whose output is a set with k elements, namely an updated neighbor set Γ t(i) of a player Xi. It is given as below. Γ t(i) = Li ( ˆzt− 1(i) ) = argmaxk j∈ Γ t− 1 (i) S Υ t− 1(i) ({ zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) }) ˆzt− 1(i) = { zt− 1(j),j ∈ Γ t− 1(i) ⋃ Υ t− 1(i) } , Υ t− 1(i) = ⋃ j∈ Γ + t− 1 (i) Γ t− 1(j) Γ + t− 1(i) = { j|zt− 1(j) ≥ θt− 1(i),j ∈ Γ t− 1(i) } , Γ − t− 1(i) = Γ t− 1(i)\\Γ + t− 1(i) (13) where θt− 1(i) is a payoﬀ threshold, Υ t− 1(i) is called an extended neighbor set, and the function argmaxk(·) is to ﬁnd k neighbors with the ﬁrst k largest payoﬀs in the set Γ t− 1(i) ⋃ Υ t− 1(i). Here, two LRR functions L1 i(·) and L2 i(·) are designed. The function L1 i(·) always observes an extended neighbor set formed by half neighbor s of a data 7point X i, α = ⌈ 0.5 × | Γ t− 1(i)| ⌉ , where the symbol ⌈·⌉ is to take an integer part of a number satisfying the integer part is no larger than the nu mber. Next, the payoﬀ threshold θ1 t− 1(i) is set by θ1 t− 1(i) = findα ({zt− 1(i),j ∈ Γ t− 1(i)}), where the function findα (·) is to ﬁnd the α-th largest payoﬀ in a set that contains all neighbors’ payoﬀs of the data point. When the LRR fun ction L1 i(·) is applied, the links connecting to the neighbors with small payoﬀs are removed and meanwhile new links are created between the data point and foun d players with higher payoﬀs. Hence, according to Eq.(13), the new neighbor set is Γ t(i) = L1 i(ˆzt− 1(i)). Unlike the LRR function L1 i(·), the LRR function L2 i(·) adjusts the number of neighbors dynamically instead of the constant number of neighbo rs in L1 i(·). Therefore, the payoﬀ threshold θ2 t− 1(i) takes the average of neighbors’ payoﬀs, θ2 t− 1(i) = ∑ j∈ Γ t− 1(i) zt− 1(i)/ |Γ t− 1(i)|. Next, the set Γ + t− 1(i) is formed according to Eq.(13), Γ + t− 1(i) = {j|zt− 1(j) ≥ θ2 t− 1(i),j ∈ Γ t− 1(i)}, and then the new neigh- bor set is achieved by means of the LRR function L2 i(·), Γ t(i) = L2 i(ˆzt− 1(i)). In the case, when the payoﬀs of all neighbors are equal to the pay oﬀ thresh- old θ2 t− 1(i), the output of the LRR function is Γ t(i) = Γ t− 1(i). This may be viewed as self-protective behavior for avoiding a payoﬀ loss due to n o enough information acquired. The LRR function Li(·) expands the view of a player X i, i.e., it makes him observe payoﬀs of players in the extended neighbor set, which pro vides a chance to ﬁnd players with higher payoﬀs around him. If no players with highe r payoﬀs are found in the extended neighbor set, namely min({zt− 1(j),j ∈ Γ t− 1(i)}) ≥ max({zt− 1(h),h ∈ Υ t− 1(i)}), then the output of the LRR function is Γ t(i) = Γ t− 1(i). Otherwise, players with small payoﬀs will be removed together wit h the corresponding links from the neighbor set and link set, and replaced by some found players with higher payoﬀ. This process is repeated till the pa yoﬀs of unlinked players in the extended neighbor set are no larger than tho se of linked neighbors. Since the links among players, namely the link set E0 in the network G0(X ,E 0,d ), are changed by the LRR function, the network Gt(X ,E t,d ) has begun to evolve over time, when t≥ 1. Gt(X ,E t,d ) =                X (t) = { X i(t),i = 1 , 2, · · · ,N } Γ t(i) = Li(ˆzt− 1(i)) Et = ⋃ N i=1 Et(i) Et(i) = { et ( X i, X j ) | j ∈ Γ t(i) } (14) 3.3 Strength of links updating After the LRR function is applied, the strength of links of players ne eds to be formed and adjusted. The new strength of links of a player X i ∈ X is formed by means of the below formulation. ρt(X i, X j ) =      P h∈ Γ t− 1 (i)\\{ Γ t− 1(i) T Γ t(i)} ρt− 1 (X i, X h) ⏐ ⏐ ⏐Γ t(i)\\ { Γ t− 1(i) T Γ t(i) }⏐ ⏐ ⏐ j ∈ Γ t(i)\\ { Γ t− 1(i) ⋂ Γ t(i) } ρt− 1(X i, X j ) otherwise (15) 8Then, the player adjusts the strength of links as follows. First, he ﬁnds\n",
      " > 356 [-0.0795   0.02225 -0.08777  0.0827   0.0508 ] the average of neighbors’ payoﬀs, θ2 t− 1(i) = ∑ j∈ Γ t− 1(i) zt− 1(i)/ |Γ t− 1(i)|. Next, the set Γ + t− 1(i) is formed according to Eq.(13), Γ + t− 1(i) = {j|zt− 1(j) ≥ θ2 t− 1(i),j ∈ Γ t− 1(i)}, and then the new neigh- bor set is achieved by means of the LRR function L2 i(·), Γ t(i) = L2 i(ˆzt− 1(i)). In the case, when the payoﬀs of all neighbors are equal to the pay oﬀ thresh- old θ2 t− 1(i), the output of the LRR function is Γ t(i) = Γ t− 1(i). This may be viewed as self-protective behavior for avoiding a payoﬀ loss due to n o enough information acquired. The LRR function Li(·) expands the view of a player X i, i.e., it makes him observe payoﬀs of players in the extended neighbor set, which pro vides a chance to ﬁnd players with higher payoﬀs around him. If no players with highe r payoﬀs are found in the extended neighbor set, namely min({zt− 1(j),j ∈ Γ t− 1(i)}) ≥ max({zt− 1(h),h ∈ Υ t− 1(i)}), then the output of the LRR function is Γ t(i) = Γ t− 1(i). Otherwise, players with small payoﬀs will be removed together wit h the corresponding links from the neighbor set and link set, and replaced by some found players with higher payoﬀ. This process is repeated till the pa yoﬀs of unlinked players in the extended neighbor set are no larger than tho se of linked neighbors. Since the links among players, namely the link set E0 in the network G0(X ,E 0,d ), are changed by the LRR function, the network Gt(X ,E t,d ) has begun to evolve over time, when t≥ 1. Gt(X ,E t,d ) =                X (t) = { X i(t),i = 1 , 2, · · · ,N } Γ t(i) = Li(ˆzt− 1(i)) Et = ⋃ N i=1 Et(i) Et(i) = { et ( X i, X j ) | j ∈ Γ t(i) } (14) 3.3 Strength of links updating After the LRR function is applied, the strength of links of players ne eds to be formed and adjusted. The new strength of links of a player X i ∈ X is formed by means of the below formulation. ρt(X i, X j ) =      P h∈ Γ t− 1 (i)\\{ Γ t− 1(i) T Γ t(i)} ρt− 1 (X i, X h) ⏐ ⏐ ⏐Γ t(i)\\ { Γ t− 1(i) T Γ t(i) }⏐ ⏐ ⏐ j ∈ Γ t(i)\\ { Γ t− 1(i) ⋂ Γ t(i) } ρt− 1(X i, X j ) otherwise (15) 8Then, the player adjusts the strength of links as follows. First, he ﬁnds a neighbor X m with maximal payoﬀ in his neighbor set, m= argmax j∈ Γ t(i) ({ zt− 1(j),j ∈ Γ t(i) }) (16) Next, the strength of link ρt(X i, X j ),j ∈ Γ t(i) is taken its square root and the player X m’s strength of the link becomes negative, { {√ ρt(X i, X j ),j ∈ Γ t(i) } √ ρt(X i, X m) = − √ ρt(X i, X m),m ∈ Γ t(i) (17) Further, let Avet(i) = ( ∑ j∈ Γ t(i) √ ρt(X i, X m))/ |Γ t(i)|, thus, the updated strength of link is ρt(X i, X j ) = ( 2 × Avet(i) − √ ρt(X i, X j ) ) 2 ,j ∈ Γ t(i). (18) The above-mentioned method is a variant of the Grover iteration G in the quantum search algorithm [3], a well-known algorithm in quantum compu tation, which is a way to adjust the probability amplitude of each term in a supe rposi- tion state. By adjustment, the probability amplitude of the wanted is increased, while the others are reduced. This whole process may be regarded a s the in- version about average operation [3]. For our case, each strength of link is taken its square root ﬁrst, and then the average Avet(i) of square roots is computed. Finally, all values are inverted about the average. There are three main reasons that we select the modiﬁed Grover iteration to update the strengt h of links: (a) the sum of updated strength of links retains one, ∑ j∈ Γ t(i) ρt(X i, X j ) = 1, (b) certain strength of links between a player and his neighbors is much la rger than the others, ρt(X i, X j ) ≫ ρt(X i, X h),h ∈ Γ t(i)\\j, after the strength of links is updated, and (c) it helps players’ payoﬀs to follow a power law distr ibution, in which only a few players’ payoﬀs are far larger than others’ in the end of iterations. Besides, the process that all players adjust their strength is ord er irrelevant, because the strength of links of all players is updated synchronou sly, and the network is a directed network, so the strength cannot be overrid den by other players. When the strength of links of each player has been update d, an iteration is completed. In conclusion, when t≥ 1 , the structure of network representing connections among players begins to evolve over time. 4 Discussions In the section, ﬁrstly, the relationship\n",
      " > 357 [-0.07556  0.01723 -0.0941   0.0693   0.05402] a neighbor X m with maximal payoﬀ in his neighbor set, m= argmax j∈ Γ t(i) ({ zt− 1(j),j ∈ Γ t(i) }) (16) Next, the strength of link ρt(X i, X j ),j ∈ Γ t(i) is taken its square root and the player X m’s strength of the link becomes negative, { {√ ρt(X i, X j ),j ∈ Γ t(i) } √ ρt(X i, X m) = − √ ρt(X i, X m),m ∈ Γ t(i) (17) Further, let Avet(i) = ( ∑ j∈ Γ t(i) √ ρt(X i, X m))/ |Γ t(i)|, thus, the updated strength of link is ρt(X i, X j ) = ( 2 × Avet(i) − √ ρt(X i, X j ) ) 2 ,j ∈ Γ t(i). (18) The above-mentioned method is a variant of the Grover iteration G in the quantum search algorithm [3], a well-known algorithm in quantum compu tation, which is a way to adjust the probability amplitude of each term in a supe rposi- tion state. By adjustment, the probability amplitude of the wanted is increased, while the others are reduced. This whole process may be regarded a s the in- version about average operation [3]. For our case, each strength of link is taken its square root ﬁrst, and then the average Avet(i) of square roots is computed. Finally, all values are inverted about the average. There are three main reasons that we select the modiﬁed Grover iteration to update the strengt h of links: (a) the sum of updated strength of links retains one, ∑ j∈ Γ t(i) ρt(X i, X j ) = 1, (b) certain strength of links between a player and his neighbors is much la rger than the others, ρt(X i, X j ) ≫ ρt(X i, X h),h ∈ Γ t(i)\\j, after the strength of links is updated, and (c) it helps players’ payoﬀs to follow a power law distr ibution, in which only a few players’ payoﬀs are far larger than others’ in the end of iterations. Besides, the process that all players adjust their strength is ord er irrelevant, because the strength of links of all players is updated synchronou sly, and the network is a directed network, so the strength cannot be overrid den by other players. When the strength of links of each player has been update d, an iteration is completed. In conclusion, when t≥ 1 , the structure of network representing connections among players begins to evolve over time. 4 Discussions In the section, ﬁrstly, the relationship between the number of nea rest neigh- bors and the number of clusters is discussed, and then how the cos t in the SD-like payoﬀ matrix inﬂuences the results is analyzed, which provide s a way to choose the proportional factor. Finally, the total payoﬀs based on two diﬀerent payoﬀ matrices are compared and the relationship between the tot al payoﬀs and the rates of convergence of algorithms is explained. 94.1 Number of nearest neighbors vs. number of clusters The number k of nearest neighbors represents the number of neighbors to which a data point (player) X i ∈ X connects. For a dataset, the number k of nearest neighbors determines the number of clusters in part. G enerally speaking, the number of clusters decreases inversely with the num ber k of nearest neighbors. For example, when the number k of nearest neighbors is small, it is indicated that the player X i connects to only a few neighbors. At this time only those not-too-distance neighbors can be observed by the LRR fu nction, which means that the elements in the union of the extended neighbor set Υ t− 1(i) and the neighbor set Γ t− 1(i) are few. Therefore, when the evolution of the network formed by players is ended, many small clusters are established amo ng data points. On the other hand, a big number k of nearest neighbors provides more neighbors for each player, as speciﬁes that the cardinality of the u nion is larger than that when a small k is taken. This means that more neighbors can be observed and explored by the LRR function, so that big clusters co ntaining more data points are formed. For a dataset, the clustering results at the diﬀerent number k of nearest neighbors have been illustrated in Fig. 2, in which each data point only c onnects to one of its neighbors who has the largest strength of link, and clus ters are represented by diﬀerent signs. As is shown in Fig. 2, it can be found t hat only a few data points receive considerable links, whereas most of da ta points have only one link. This implies that when the structure of network te nds to stability, the network, if only the links with the largest strength are remained,\n",
      " > 358 [-0.04404   0.013016 -0.06088   0.03534   0.06015 ] relationship between the number of nea rest neigh- bors and the number of clusters is discussed, and then how the cos t in the SD-like payoﬀ matrix inﬂuences the results is analyzed, which provide s a way to choose the proportional factor. Finally, the total payoﬀs based on two diﬀerent payoﬀ matrices are compared and the relationship between the tot al payoﬀs and the rates of convergence of algorithms is explained. 94.1 Number of nearest neighbors vs. number of clusters The number k of nearest neighbors represents the number of neighbors to which a data point (player) X i ∈ X connects. For a dataset, the number k of nearest neighbors determines the number of clusters in part. G enerally speaking, the number of clusters decreases inversely with the num ber k of nearest neighbors. For example, when the number k of nearest neighbors is small, it is indicated that the player X i connects to only a few neighbors. At this time only those not-too-distance neighbors can be observed by the LRR fu nction, which means that the elements in the union of the extended neighbor set Υ t− 1(i) and the neighbor set Γ t− 1(i) are few. Therefore, when the evolution of the network formed by players is ended, many small clusters are established amo ng data points. On the other hand, a big number k of nearest neighbors provides more neighbors for each player, as speciﬁes that the cardinality of the u nion is larger than that when a small k is taken. This means that more neighbors can be observed and explored by the LRR function, so that big clusters co ntaining more data points are formed. For a dataset, the clustering results at the diﬀerent number k of nearest neighbors have been illustrated in Fig. 2, in which each data point only c onnects to one of its neighbors who has the largest strength of link, and clus ters are represented by diﬀerent signs. As is shown in Fig. 2, it can be found t hat only a few data points receive considerable links, whereas most of da ta points have only one link. This implies that when the structure of network te nds to stability, the network, if only the links with the largest strength are remained, is characterized by the scale-free network [29], i.e., winner takes all. Besides, in Fig. 2(a), six clusters are obtained by the clustering algorithm, whe n k= 9. As the number k of nearest neighbors rises, four clusters are obtained when k= 12, three clusters when k= 16. So, if the exact number of clusters is not known in advance, diﬀerent numbers of clusters may be achieved by adjust ing the number of nearest neighbors in practice. −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (a) k = 9 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (b) k = 12 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (c) k = 16 Figure 2: The number of nearest neighbors vs. number of clusters . (a) six clusters are obtained, when the number of nearest neighbors is k = 9. (b) four clusters, when k= 12. (c) three clusters, when k= 16 4.2 Eﬀect of the cost c in the SD-like payoﬀ matrix In the Snowdrift game, if the cost is too high, the SD-like payoﬀ matr ix recovers the PD-like payoﬀ matrix [28]. Therefore, the proportio nal factor β is restricted in an interval (0 , 0.5]. However, diﬀerent costs will bring about 10the changes of the payoﬀ matrix, which means that diﬀerent cluste ring results will be produced even in the same algorithm. Figure 3 illustrates how th e clustering results change at the diﬀerent number k of nearest neighbors when the proportional factor β takes diﬀerent values, in which the clustering results are represented by clustering accuracies. The deﬁnition of cluste ring accuracy is given below. Deﬁnition 4clusteri is the label which is assigned to a data point Xi in a dataset by the algorithm, and labeli is the actual label of the data point Xi in the dataset. So the clustering accuracy is [30]: accuracy = PN i=1 λ ( map(clusteri ),label i ) N λ(map(clusteri),label i) = { 1 if map(clusteri) = labeli 0 otherwise (19) where the mapping function map(·) maps the label got by the algorithm to the actual label. Clustering accuracy is an important evaluation criterion for clustering algo- rithms, which reﬂects the level of matches between the actual lab els in a dataset and the labels assigned\n",
      " > 359 [-0.03806  0.00931 -0.0393   0.05975  0.0633 ] remained, is characterized by the scale-free network [29], i.e., winner takes all. Besides, in Fig. 2(a), six clusters are obtained by the clustering algorithm, whe n k= 9. As the number k of nearest neighbors rises, four clusters are obtained when k= 12, three clusters when k= 16. So, if the exact number of clusters is not known in advance, diﬀerent numbers of clusters may be achieved by adjust ing the number of nearest neighbors in practice. −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (a) k = 9 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (b) k = 12 −5 −4 −3 −2 −1 0 1 2 3 4 5 −5 −4 −3 −2 −1 0 1 2 3 4 (c) k = 16 Figure 2: The number of nearest neighbors vs. number of clusters . (a) six clusters are obtained, when the number of nearest neighbors is k = 9. (b) four clusters, when k= 12. (c) three clusters, when k= 16 4.2 Eﬀect of the cost c in the SD-like payoﬀ matrix In the Snowdrift game, if the cost is too high, the SD-like payoﬀ matr ix recovers the PD-like payoﬀ matrix [28]. Therefore, the proportio nal factor β is restricted in an interval (0 , 0.5]. However, diﬀerent costs will bring about 10the changes of the payoﬀ matrix, which means that diﬀerent cluste ring results will be produced even in the same algorithm. Figure 3 illustrates how th e clustering results change at the diﬀerent number k of nearest neighbors when the proportional factor β takes diﬀerent values, in which the clustering results are represented by clustering accuracies. The deﬁnition of cluste ring accuracy is given below. Deﬁnition 4clusteri is the label which is assigned to a data point Xi in a dataset by the algorithm, and labeli is the actual label of the data point Xi in the dataset. So the clustering accuracy is [30]: accuracy = PN i=1 λ ( map(clusteri ),label i ) N λ(map(clusteri),label i) = { 1 if map(clusteri) = labeli 0 otherwise (19) where the mapping function map(·) maps the label got by the algorithm to the actual label. Clustering accuracy is an important evaluation criterion for clustering algo- rithms, which reﬂects the level of matches between the actual lab els in a dataset and the labels assigned by a clustering algorithm, so that the goal of a clustering algorithm is to obtain higher clustering accuracies. As is shown in Figure 3, it can be seen that similar results are obtained b y the algorithm at diﬀerent costs, and the best results are produce d when k = 7 and k= 8, but from the Figure 3(b), the clustering result with the largest mean and the least variance is yielded when β = 0 .3. Also, as mentioned above, the high cost leads to the recovery of the SD-like payoﬀ matrix, so the p roportional factor β = 0 .2 or β = 0 .3 is recommended. 4 5 6 7 8 9 10 11 12 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy beta=0.1 beta=0.2 beta=0.3 beta=0.4 beta=0.5 (a) 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.8 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 1 proportional factor beta mean and variance of results (b) Figure 3: The eﬀect of the cost for the clustering results. (a) the results of the algorithm using the SD-like payoﬀ matrix at diﬀerent number k of nearest neighbors. (b) the mean and variance corresponding to each curv e in (a). 4.3 Total payoﬀs and the rate of convergence In this subsection, at ﬁrst, the total payoﬀs of algorithms using t he PD- or SD-like payoﬀ matrix are compared respectively, and then the diﬀer ences be- tween total payoﬀs are explained. Later, the rates of converge nce of algorithms 11are discussed when two LRR functions are applied respectively, and further the impact for the rates of convergence is analyzed in two payoﬀ matric es. If all other conditions are ﬁxed, an algorithm will form two versions d ue to using PD- or SD-like payoﬀ matrix, and naturally this will bring diﬀerent results. As compared with the PD-like payoﬀ matrix, the payoﬀ P and S in the SD-like payoﬀ matrix have a reverse order in the payoﬀ inequality. In all algo rithms, the relationship between the total payoﬀs and the number of iteration s is drawn in Figure 4. From Figure 4, it can be found that the total payoﬀs in the algorithms with SD-like payoﬀ matrix are larger than that of the algorithms with P D-like payoﬀ matrix no matter which LRR\n",
      " > 360 [-0.03387  0.00983 -0.06854  0.04974  0.0733 ] assigned by a clustering algorithm, so that the goal of a clustering algorithm is to obtain higher clustering accuracies. As is shown in Figure 3, it can be seen that similar results are obtained b y the algorithm at diﬀerent costs, and the best results are produce d when k = 7 and k= 8, but from the Figure 3(b), the clustering result with the largest mean and the least variance is yielded when β = 0 .3. Also, as mentioned above, the high cost leads to the recovery of the SD-like payoﬀ matrix, so the p roportional factor β = 0 .2 or β = 0 .3 is recommended. 4 5 6 7 8 9 10 11 12 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy beta=0.1 beta=0.2 beta=0.3 beta=0.4 beta=0.5 (a) 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.8 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 1 proportional factor beta mean and variance of results (b) Figure 3: The eﬀect of the cost for the clustering results. (a) the results of the algorithm using the SD-like payoﬀ matrix at diﬀerent number k of nearest neighbors. (b) the mean and variance corresponding to each curv e in (a). 4.3 Total payoﬀs and the rate of convergence In this subsection, at ﬁrst, the total payoﬀs of algorithms using t he PD- or SD-like payoﬀ matrix are compared respectively, and then the diﬀer ences be- tween total payoﬀs are explained. Later, the rates of converge nce of algorithms 11are discussed when two LRR functions are applied respectively, and further the impact for the rates of convergence is analyzed in two payoﬀ matric es. If all other conditions are ﬁxed, an algorithm will form two versions d ue to using PD- or SD-like payoﬀ matrix, and naturally this will bring diﬀerent results. As compared with the PD-like payoﬀ matrix, the payoﬀ P and S in the SD-like payoﬀ matrix have a reverse order in the payoﬀ inequality. In all algo rithms, the relationship between the total payoﬀs and the number of iteration s is drawn in Figure 4. From Figure 4, it can be found that the total payoﬀs in the algorithms with SD-like payoﬀ matrix are larger than that of the algorithms with P D-like payoﬀ matrix no matter which LRR function is selected. 1 2 3 4 5 6 7 8 9 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1(a) 1 2 3 4 5 6 7 8 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Figure 4: The total payoﬀs vs. the rates of convergence. (a) to tal payoﬀs of algorithms in the case of LRR function L1 i(·), (b) total payoﬀs of algorithms in the case of LRR function L2 i(·) Remark 1 The algorithms are named as follows. For example, the name of an algorithm, QGC1PDL1, denotes that the Case 1, PD-like payoﬀ matrix and the LRR function L1 i(·) are employed in this algorithm. According to two payoﬀ matrices, using Eq.(11), each player’s expe cted pay- oﬀ can be calculated in two cases of strategies respectively as below . Case 1: PD : zt(X i, X j ) = { 1 4 (0.6ω + 0.01ω + ω + 0.2ω) = 0 .4525ω 1 2 (0.6ω + 0.01ω) = 0 .305ω (20) SD : zt(X i, X j ) = { 1 4 (ω − c 2 + ω − c+ ω + 0.01ω) = 1 4 (3.01 − 3α 2 )ω 1 2 (ω − c 2 + ω − c) = 1 2 (2 − 3α 2 )ω (21) Case 2: PD : zt(X i, X j ) =      ρ1ρ20.6ω + ρ2(1 − ρ1)0.01ω +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.2ω (1 − ρ1)0.6ω + ρ10.01ω (22) SD : zt(X i, X j ) =      ρ1ρ2(ω − c 2 ) + ρ2(1 − ρ1)(ω − c) +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.01ω (1 − ρ1)(ω − c 2 ) + ρ1(ω − c) (23) 12Comparing the expected payoﬀs in two cases, it can be observed th at when the SD-like payoﬀ matrix is used, the expected payoﬀ is larger than t hat of using PD-like payoﬀ matrix regardless of cases of strategies. Therefor e, this explains why diﬀerences between total payoﬀs are produced. Besides, Figure 4 not only describes the changes of total payoﬀs o f algo- rithms, but also reﬂects the rates of convergence of algorithms. When the total payoﬀs remain constant or ﬂuctuate slightly, this means that the a lgorithms have converged. At this time, players do not frequently apply the L RR function to change his neighbors but reach a stable state. As mentioned in th e section 3.2, the LRR function L2 i(·) only can observe an extended neighbor set formed by those larger-than-average neighbors in contrast to\n",
      " > 361 [-0.01929  0.0176  -0.0704   0.04523  0.0321 ] LRR function is selected. 1 2 3 4 5 6 7 8 9 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1(a) 1 2 3 4 5 6 7 8 0 1000 2000 3000 4000 5000 6000 7000 number of iterations total payoffs QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Figure 4: The total payoﬀs vs. the rates of convergence. (a) to tal payoﬀs of algorithms in the case of LRR function L1 i(·), (b) total payoﬀs of algorithms in the case of LRR function L2 i(·) Remark 1 The algorithms are named as follows. For example, the name of an algorithm, QGC1PDL1, denotes that the Case 1, PD-like payoﬀ matrix and the LRR function L1 i(·) are employed in this algorithm. According to two payoﬀ matrices, using Eq.(11), each player’s expe cted pay- oﬀ can be calculated in two cases of strategies respectively as below . Case 1: PD : zt(X i, X j ) = { 1 4 (0.6ω + 0.01ω + ω + 0.2ω) = 0 .4525ω 1 2 (0.6ω + 0.01ω) = 0 .305ω (20) SD : zt(X i, X j ) = { 1 4 (ω − c 2 + ω − c+ ω + 0.01ω) = 1 4 (3.01 − 3α 2 )ω 1 2 (ω − c 2 + ω − c) = 1 2 (2 − 3α 2 )ω (21) Case 2: PD : zt(X i, X j ) =      ρ1ρ20.6ω + ρ2(1 − ρ1)0.01ω +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.2ω (1 − ρ1)0.6ω + ρ10.01ω (22) SD : zt(X i, X j ) =      ρ1ρ2(ω − c 2 ) + ρ2(1 − ρ1)(ω − c) +ρ1(1 − ρ2)ω + (1 − ρ1)(1 − ρ2)0.01ω (1 − ρ1)(ω − c 2 ) + ρ1(ω − c) (23) 12Comparing the expected payoﬀs in two cases, it can be observed th at when the SD-like payoﬀ matrix is used, the expected payoﬀ is larger than t hat of using PD-like payoﬀ matrix regardless of cases of strategies. Therefor e, this explains why diﬀerences between total payoﬀs are produced. Besides, Figure 4 not only describes the changes of total payoﬀs o f algo- rithms, but also reﬂects the rates of convergence of algorithms. When the total payoﬀs remain constant or ﬂuctuate slightly, this means that the a lgorithms have converged. At this time, players do not frequently apply the L RR function to change his neighbors but reach a stable state. As mentioned in th e section 3.2, the LRR function L2 i(·) only can observe an extended neighbor set formed by those larger-than-average neighbors in contrast to an exten ded neighbor set built by half neighbors in the LRR function L1 i(·). Generally speaking, for the same k, the median of payoﬀs is smaller than or equal to the mean, i.e., θ1 t− 1 ≤ θ2 t− 1, which means that the exploring area of the LRR function L1 i(·) is larger than that of the LRR function L2 i(·). So, as a whole, the algorithms with the LRR function L2 i(·) are slightly faster than that with the LRR function L1 i(·), i.e., the number of iterations that the former type of algorithms n eeds is a little less. Furthermore, in the algorithms, a phenomenon that the strategie s ˆH and ˆFt− 1 are more likely used by players in a high density area while the strategy ˆD is used by those in a low density area is always observed. This is becaus e usually they are mutually neighbors in the high density area on the weig hted and directed knn network, but in the low density area this case is rev erse. As a result, the diﬀerences of payoﬀs between the high density and low d ensity areas are enlarged rapidly for the expected payoﬀ in the strategy proﬁle ( ˆH, ˆH) or ( ˆFt− 1, ˆFt− 1) is higher than that in other strategy proﬁle, and this also cause th e distribution of players’ payoﬀs follows a power-law distribution, whic h is why algorithms converge fast. 5 Simulations To evaluate these clustering algorithms, six datasets are selected from UCI repository [31], which are Soybean, Iris, Wine, Sonar, Ionosphere and Breast cancer Wisconsin datasets, and complete the simulations on them. I n this sec- tion, ﬁrstly these datasets are brieﬂy introduced, and then the s imulation results are demonstrated. The original data points in above datasets all are scattered in high d imen- sional spaces spanned by their features which are the individual me asurable heuristic properties of the phenomena being observed, where the description of all datasets is summarized in Table 4. As for Breast dataset, some lo st features are replaced by random numbers, and the Wine dataset is standard ized. Finally, the algorithms are coded in Matlab 6.5. Throughout all simulations, data points in a dataset are viewed as pla yers in\n",
      " > 362 [-0.043    0.02365 -0.07245  0.06238  0.04645] an exten ded neighbor set built by half neighbors in the LRR function L1 i(·). Generally speaking, for the same k, the median of payoﬀs is smaller than or equal to the mean, i.e., θ1 t− 1 ≤ θ2 t− 1, which means that the exploring area of the LRR function L1 i(·) is larger than that of the LRR function L2 i(·). So, as a whole, the algorithms with the LRR function L2 i(·) are slightly faster than that with the LRR function L1 i(·), i.e., the number of iterations that the former type of algorithms n eeds is a little less. Furthermore, in the algorithms, a phenomenon that the strategie s ˆH and ˆFt− 1 are more likely used by players in a high density area while the strategy ˆD is used by those in a low density area is always observed. This is becaus e usually they are mutually neighbors in the high density area on the weig hted and directed knn network, but in the low density area this case is rev erse. As a result, the diﬀerences of payoﬀs between the high density and low d ensity areas are enlarged rapidly for the expected payoﬀ in the strategy proﬁle ( ˆH, ˆH) or ( ˆFt− 1, ˆFt− 1) is higher than that in other strategy proﬁle, and this also cause th e distribution of players’ payoﬀs follows a power-law distribution, whic h is why algorithms converge fast. 5 Simulations To evaluate these clustering algorithms, six datasets are selected from UCI repository [31], which are Soybean, Iris, Wine, Sonar, Ionosphere and Breast cancer Wisconsin datasets, and complete the simulations on them. I n this sec- tion, ﬁrstly these datasets are brieﬂy introduced, and then the s imulation results are demonstrated. The original data points in above datasets all are scattered in high d imen- sional spaces spanned by their features which are the individual me asurable heuristic properties of the phenomena being observed, where the description of all datasets is summarized in Table 4. As for Breast dataset, some lo st features are replaced by random numbers, and the Wine dataset is standard ized. Finally, the algorithms are coded in Matlab 6.5. Throughout all simulations, data points in a dataset are viewed as pla yers in quantum games whose initial positions are taken from the dataset . Next, the initial network representing relations among data points are creat ed according to Def.1, after a distance function is selected, which only needs to s atisfy that the more similar data points are, the smaller the output of the funct ion is. In 13Table 4: Description of datasets. Dataset Instances Features classes Soybean 47 21 4 Iris 150 4 3 Wine 178 13 3 Sonar 208 60 2 Ionosphere 351 32 2 Breast 699 9 2 the simulations, the distance function is employed as following d ( X i, X j ) = exp ( ∥X i − X j ∥/ 2σ2 ) ,i,j = 1 , 2, · · · ,N (24) where the symbol ∥ · ∥ represents L2-norm. The advantage of this function is that it not only satisﬁes our requirements, but also overcomes the drawbacks of Euclidean distance. For instance, when two points are very close, t he output of Euclidean distance function approaches zero, which may make the c omputation of payoﬀ fail due to the payoﬀ approaching inﬁnite. Nevertheless, when Eq.(24) is selected as the distance function, it is more convenient to comput e the players’ payoﬀs, since its minimum is one and the reciprocals of its output are b etween zero and one, 1 /d (X i, X j ) ∈ [0, 1]. In addition, the distance between a player X i and itself, d(X i, X i), is one according to the deﬁned distance function, which means that initially he is one of his k nearest neighbors. So there is an edge between the player X i and himself, namely a self-loop. Additionally, the parameter σ in Eq.(24) takes one. As is analyzed in the section 4.2, the cost c in SD-like payoﬀ matrix is set by c= 0 .2ωt(X i, X j ) in the related clustering algorithms. The clustering algorithms are applied on the six datasets respective ly. Be- cause two cases of strategies are designed and the diﬀerent payo ﬀ matrices and LRR functions are employed, the algorithms are run on every datas et at the diﬀerent number k of nearest neighbors. As is analyzed in section 4.1, for a dataset the number k of clusters decreases inversely with the number of nearest neighbors. When a small k is selected, it is possible that the number of\n",
      " > 363 [-0.06573  0.02884 -0.0738   0.04462  0.0652 ] quantum games whose initial positions are taken from the dataset . Next, the initial network representing relations among data points are creat ed according to Def.1, after a distance function is selected, which only needs to s atisfy that the more similar data points are, the smaller the output of the funct ion is. In 13Table 4: Description of datasets. Dataset Instances Features classes Soybean 47 21 4 Iris 150 4 3 Wine 178 13 3 Sonar 208 60 2 Ionosphere 351 32 2 Breast 699 9 2 the simulations, the distance function is employed as following d ( X i, X j ) = exp ( ∥X i − X j ∥/ 2σ2 ) ,i,j = 1 , 2, · · · ,N (24) where the symbol ∥ · ∥ represents L2-norm. The advantage of this function is that it not only satisﬁes our requirements, but also overcomes the drawbacks of Euclidean distance. For instance, when two points are very close, t he output of Euclidean distance function approaches zero, which may make the c omputation of payoﬀ fail due to the payoﬀ approaching inﬁnite. Nevertheless, when Eq.(24) is selected as the distance function, it is more convenient to comput e the players’ payoﬀs, since its minimum is one and the reciprocals of its output are b etween zero and one, 1 /d (X i, X j ) ∈ [0, 1]. In addition, the distance between a player X i and itself, d(X i, X i), is one according to the deﬁned distance function, which means that initially he is one of his k nearest neighbors. So there is an edge between the player X i and himself, namely a self-loop. Additionally, the parameter σ in Eq.(24) takes one. As is analyzed in the section 4.2, the cost c in SD-like payoﬀ matrix is set by c= 0 .2ωt(X i, X j ) in the related clustering algorithms. The clustering algorithms are applied on the six datasets respective ly. Be- cause two cases of strategies are designed and the diﬀerent payo ﬀ matrices and LRR functions are employed, the algorithms are run on every datas et at the diﬀerent number k of nearest neighbors. As is analyzed in section 4.1, for a dataset the number k of clusters decreases inversely with the number of nearest neighbors. When a small k is selected, it is possible that the number of clusters is larger than the preset number of the dataset, after the algorit hm is ended. So a merging-subroutine is called to merge unwanted clusters, which wo rks in this way. At ﬁrst, the cluster with the fewest data points is identiﬁed, a nd then it is merged to the cluster whose distance between their centroids is sm allest. This subroutine is repeated till the number of clusters is equal to the pr eset number. The clustering results obtained by these algorithms are compared in Fig. 5, in which each point represents a clustering accuracy. As is shown in F ig. 5, the similar results are obtained by these algorithms at diﬀerent number o f nearest neighbors, but almost all the best results are obtained by the algor ithms using the LRR function L1 i(·). Further, we show a simple comparison with three other algorithms: K means [32, 33], PCA-Kmeans [33], LDA-Km [33]. The Kmeans algorithm is a popular clu s- tering algorithm because it is easy to implement. It begins with k randomly- chosen cluster centers, and then assigns each data point in a data set to the closest cluster center. Next, the cluster centers are recomput ed according to the current cluster memberships. This process will be repeated till a co nvergence 142 2.5 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(a) Soybean dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Iris dataset 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(c) Wine dataset 3 3.5 4 4.5 5 5.5 6 6.5 7 7.5 8 0.4 0.42 0.44 0.46 0.48 0.5 0.52 0.54 0.56 0.58 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(d) Sonar dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 number of nearest neighbors\n",
      " > 364 [-0.04996  0.057   -0.07666  0.05338  0.0599 ] clusters is larger than the preset number of the dataset, after the algorit hm is ended. So a merging-subroutine is called to merge unwanted clusters, which wo rks in this way. At ﬁrst, the cluster with the fewest data points is identiﬁed, a nd then it is merged to the cluster whose distance between their centroids is sm allest. This subroutine is repeated till the number of clusters is equal to the pr eset number. The clustering results obtained by these algorithms are compared in Fig. 5, in which each point represents a clustering accuracy. As is shown in F ig. 5, the similar results are obtained by these algorithms at diﬀerent number o f nearest neighbors, but almost all the best results are obtained by the algor ithms using the LRR function L1 i(·). Further, we show a simple comparison with three other algorithms: K means [32, 33], PCA-Kmeans [33], LDA-Km [33]. The Kmeans algorithm is a popular clu s- tering algorithm because it is easy to implement. It begins with k randomly- chosen cluster centers, and then assigns each data point in a data set to the closest cluster center. Next, the cluster centers are recomput ed according to the current cluster memberships. This process will be repeated till a co nvergence 142 2.5 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(a) Soybean dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(b) Iris dataset 3 3.5 4 4.5 5 5.5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(c) Wine dataset 3 3.5 4 4.5 5 5.5 6 6.5 7 7.5 8 0.4 0.42 0.44 0.46 0.48 0.5 0.52 0.54 0.56 0.58 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(d) Sonar dataset 3 4 5 6 7 8 9 10 0.5 0.55 0.6 0.65 0.7 0.75 0.8 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(e) Ionosphere dataset 3 4 5 6 7 8 9 10 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(f) breast dataset Figure 5: Comparison of clustering accuracies at diﬀerent k in all proposed algorithms. criterion is met. However, its major problem is sensitive to the selection of the initial partition [19]. The PCA-Kmeans algorithm consists of two steps : (1) Re- duce the data dimension by principal component analysis (PCA); (2) Clustering data points by the Kmeans algorithm. Ding et al combine linear discrimin ant analysis (LDA) with the Kmeans algorithm, and construct a new clust ering algorithm called ’LDA-Km’. In the LDA-Km algorithm, Kmeans is used to generate class labels, while LDA is used to do subspace selection. Finally, in the subspace selection process, data points are clustered. Our algorithms are established on the model of quantum games, so d ata points in datasets are considered as players. This idea is totally diﬀer ent from traditional clustering algorithms, such as Kmeans and its variants, because in traditional clustering algorithms data points for clustering are ﬁxe d, and various functions or methods are designed to ﬁnd cluster centers or sepa rating hyper- planes, whereas in the quantum-game-based clustering algorithms data points (players) themselves choose their clusters, which leads clusters a re formed au- tomatically during quantum games. In conclusion, traditional cluste ring algo- rithms do it from outside, while ours are from inside. Furthermore, o ur algo- rithms do not need to choose cluster centers at beginning, so ther e does not exist the problem that is ”sensitive to the selection of the initial partition” . Besides, distances between data points are commonly used as the measurem ent of their similarities in the Kmeans algorithm and its variants. However, when sim ilar- ities are measured in our algorithms, not only distances between dat a points but also their degrees and the strength of\n",
      " > 365 [-0.03137  0.0665  -0.0476   0.03687  0.06915] neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(e) Ionosphere dataset 3 4 5 6 7 8 9 10 0.85 0.9 0.95 1 number of nearest neighbors k clustering accuracy QGC1PDL1 QGC1SDL1 QGC2PDL1 QGC2SDL1 QGC1PDL2 QGC1SDL2 QGC2PDL2 QGC2SDL2(f) breast dataset Figure 5: Comparison of clustering accuracies at diﬀerent k in all proposed algorithms. criterion is met. However, its major problem is sensitive to the selection of the initial partition [19]. The PCA-Kmeans algorithm consists of two steps : (1) Re- duce the data dimension by principal component analysis (PCA); (2) Clustering data points by the Kmeans algorithm. Ding et al combine linear discrimin ant analysis (LDA) with the Kmeans algorithm, and construct a new clust ering algorithm called ’LDA-Km’. In the LDA-Km algorithm, Kmeans is used to generate class labels, while LDA is used to do subspace selection. Finally, in the subspace selection process, data points are clustered. Our algorithms are established on the model of quantum games, so d ata points in datasets are considered as players. This idea is totally diﬀer ent from traditional clustering algorithms, such as Kmeans and its variants, because in traditional clustering algorithms data points for clustering are ﬁxe d, and various functions or methods are designed to ﬁnd cluster centers or sepa rating hyper- planes, whereas in the quantum-game-based clustering algorithms data points (players) themselves choose their clusters, which leads clusters a re formed au- tomatically during quantum games. In conclusion, traditional cluste ring algo- rithms do it from outside, while ours are from inside. Furthermore, o ur algo- rithms do not need to choose cluster centers at beginning, so ther e does not exist the problem that is ”sensitive to the selection of the initial partition” . Besides, distances between data points are commonly used as the measurem ent of their similarities in the Kmeans algorithm and its variants. However, when sim ilar- ities are measured in our algorithms, not only distances between dat a points but also their degrees and the strength of links are integrated, wh ich provides more information for the measurement of similarities. Later, accor ding to pay- oﬀs in quantum games, players apply a LRR function to change the st ructure of the network, which makes the clusters emerge. As a result, bet ter clustering accuracies are obtained by our algorithms. Table 5 displays the clustering accuracies of our algorithms and the o ther 15three algorithms using the datasets in Table 4. It can be observed t hat on almost all datasets the quantum game based clustering algorithms h ave the best clustering accuracies. Only on the Iris dataset, the LDA-Km a lgorithm is better than ours, but our result is close to it as well. The Iris datase t contains three clusters, one of which is far from the other two, so data poin ts in it can be clustered easily and correctly. The other clusters in the Iris dataset, however, are mixed partly in their boundaries, which brings a diﬃculty for clustering. These mixed boundary points may be assigned to diﬀeren t clusters by algorithms, which is why the clustering accuracies of algorithms ar e various. It is more diﬃcult to cluster data points in the Sonar and Ionosphere dataset, because in these two datasets plenty of data points belonging to diﬀ erent clusters are mixed together. Therefore, the clustering accuracies of algo rithms in them are not high, and it is rather hard to improve the clustering accurac ies even by several percents. From the ﬁfth and sixth columns in Table 5, it c an be seen that the quantum game based clustering algorithms are bette r than other algorithms, which indicates the eﬀectiveness of our algorithms. Table 5: Comparison of clustering accuracies of algorithms. Algorithm Soybean Iris Wine Sonar Ionosphere Breast QGC1PDL1 97.9% 92.0% 94.9% 54.8% 75.5% 95.4% QGC1SDL1 95.6% 90.7% 96.6% 56.3% 74.1% 95.4% QGC2PDL1 95.6% 91.3% 96.6% 55.8% 73.8% 95.4% QGC2SDL1 89.4% 91.3% 96.6% 55.8% 75.5% 95.3% QGC1PDL2 95.8% 96.7% 95.5% 54.3% 74.1% 95.0% QGC1SDL2 89.4% 90.7% 95.5% 54.3% 74.6% 95.1% QGC2PDL2 89.4% 90.0% 95.5% 55.3% 74.6% 95.3% QGC2SDL2 89.4% 91.3% 94.9% 55.8% 74.9% 95.1% Kmeans [33] 68.1% 89.3%\n",
      " > 366 [-0.0706   0.03745 -0.04736  0.0655   0.05914] links are integrated, wh ich provides more information for the measurement of similarities. Later, accor ding to pay- oﬀs in quantum games, players apply a LRR function to change the st ructure of the network, which makes the clusters emerge. As a result, bet ter clustering accuracies are obtained by our algorithms. Table 5 displays the clustering accuracies of our algorithms and the o ther 15three algorithms using the datasets in Table 4. It can be observed t hat on almost all datasets the quantum game based clustering algorithms h ave the best clustering accuracies. Only on the Iris dataset, the LDA-Km a lgorithm is better than ours, but our result is close to it as well. The Iris datase t contains three clusters, one of which is far from the other two, so data poin ts in it can be clustered easily and correctly. The other clusters in the Iris dataset, however, are mixed partly in their boundaries, which brings a diﬃculty for clustering. These mixed boundary points may be assigned to diﬀeren t clusters by algorithms, which is why the clustering accuracies of algorithms ar e various. It is more diﬃcult to cluster data points in the Sonar and Ionosphere dataset, because in these two datasets plenty of data points belonging to diﬀ erent clusters are mixed together. Therefore, the clustering accuracies of algo rithms in them are not high, and it is rather hard to improve the clustering accurac ies even by several percents. From the ﬁfth and sixth columns in Table 5, it c an be seen that the quantum game based clustering algorithms are bette r than other algorithms, which indicates the eﬀectiveness of our algorithms. Table 5: Comparison of clustering accuracies of algorithms. Algorithm Soybean Iris Wine Sonar Ionosphere Breast QGC1PDL1 97.9% 92.0% 94.9% 54.8% 75.5% 95.4% QGC1SDL1 95.6% 90.7% 96.6% 56.3% 74.1% 95.4% QGC2PDL1 95.6% 91.3% 96.6% 55.8% 73.8% 95.4% QGC2SDL1 89.4% 91.3% 96.6% 55.8% 75.5% 95.3% QGC1PDL2 95.8% 96.7% 95.5% 54.3% 74.1% 95.0% QGC1SDL2 89.4% 90.7% 95.5% 54.3% 74.6% 95.1% QGC2PDL2 89.4% 90.0% 95.5% 55.3% 74.6% 95.3% QGC2SDL2 89.4% 91.3% 94.9% 55.8% 74.9% 95.1% Kmeans [33] 68.1% 89.3% 70.2% 47.2% 71.0% – PCA-Kmeans [33] 72.3% 88.7% 70.2% 45.3% 71.0% – LDA-Km [33] 76.6% 98.0% 82.6% 51.0% 71.2% – 6 Conclusions The enormous successes gained by the quantum algorithms make us realize it is possible that the quantum algorithms can obtain solutions faster and bet- ter than those classical algorithms for some problems. Therefore , we combine the quantum game with the problem of data clustering, and establish clustering algorithms based on quantum games. In the algorithms, data points for clus- tering are regarded as players who can make decisions in quantum ga mes. On a weighted and directed knn network that represents relations am ong players, each player uses quantum strategies against every one of his neigh bors in a 2 × 2 entangled quantum game respectively. We design two cases of stra tegies: (i) one plays the strategy ˆH, the other plays the strategy ˆH or ˆD, (ii) one plays the strategy ˆFt− 1, the other plays the strategy ˆFt− 1 or ˆD according to the strength of links, in each of which players’ expected payoﬀs are calculated ba sed on the PD- and SD-like payoﬀ matrices respectively. According to neighbor s’ payoﬀs in one’s neighbor set, each player applies a LRR function ( L1 i(·) or L2 i(·)) to change his neighbors, i.e., the links connecting to neighbors with small payoﬀs 16are removed and then new links are created to those with higher pay oﬀs. Later, the Grover iteration G is employed to update the strength of links between him and his neighbors. In the process of playing quantum game, the s tructure of the network formed by players tends to stability gradually. In ot her words, each player always connects to one of his neighbors with the largest strength or jumps among some neighbors with the largest strength in a constan t period. At this time, if only the links with the largest strength are left but all oth er links are removed among players, the network naturally divides into seve ral separate parts, each of which corresponds to a cluster. Additionally, in simulations, it can be found that the total expected p ayoﬀs of algorithms using SD-like payoﬀ matrix are higher than\n",
      " > 367 [-0.06012  0.0315  -0.0698   0.0854   0.03168] 89.3% 70.2% 47.2% 71.0% – PCA-Kmeans [33] 72.3% 88.7% 70.2% 45.3% 71.0% – LDA-Km [33] 76.6% 98.0% 82.6% 51.0% 71.2% – 6 Conclusions The enormous successes gained by the quantum algorithms make us realize it is possible that the quantum algorithms can obtain solutions faster and bet- ter than those classical algorithms for some problems. Therefore , we combine the quantum game with the problem of data clustering, and establish clustering algorithms based on quantum games. In the algorithms, data points for clus- tering are regarded as players who can make decisions in quantum ga mes. On a weighted and directed knn network that represents relations am ong players, each player uses quantum strategies against every one of his neigh bors in a 2 × 2 entangled quantum game respectively. We design two cases of stra tegies: (i) one plays the strategy ˆH, the other plays the strategy ˆH or ˆD, (ii) one plays the strategy ˆFt− 1, the other plays the strategy ˆFt− 1 or ˆD according to the strength of links, in each of which players’ expected payoﬀs are calculated ba sed on the PD- and SD-like payoﬀ matrices respectively. According to neighbor s’ payoﬀs in one’s neighbor set, each player applies a LRR function ( L1 i(·) or L2 i(·)) to change his neighbors, i.e., the links connecting to neighbors with small payoﬀs 16are removed and then new links are created to those with higher pay oﬀs. Later, the Grover iteration G is employed to update the strength of links between him and his neighbors. In the process of playing quantum game, the s tructure of the network formed by players tends to stability gradually. In ot her words, each player always connects to one of his neighbors with the largest strength or jumps among some neighbors with the largest strength in a constan t period. At this time, if only the links with the largest strength are left but all oth er links are removed among players, the network naturally divides into seve ral separate parts, each of which corresponds to a cluster. Additionally, in simulations, it can be found that the total expected p ayoﬀs of algorithms using SD-like payoﬀ matrix are higher than that of algorith ms using PD-like payoﬀ matrix. Later, the reason is explained. Further, we o bserve that the rates of convergence of the algorithms employing the LRR func tion L2 i(·) are faster slightly than that of the algorithms employing the LRR fun ction L1 i(·), because more areas are explored by the LRR function L1 i(·), but this brings better clustering results. In the case when the exact numb er of clusters is unknown in advance, one can adjust the number k of nearest neighbors to control the number of clusters, where the number of clusters de creases inversely with the number k of nearest neighbors. Finally, the clustering algorithms are evaluated on six real datasets, and simulation results have demons trated that data points in a dataset are clustered reasonably and eﬃciently. Acknowledgments The authors would like to thank the anonymous referees for their h elpful comments and suggestions to improve the presentation of this pap er. This work was supported in part by the National Natural Science Foundation of China (No. 60405012, No. 60675055). References [1] V. Vedral and M. Plenio, “Basics of quantum computation,” Progress in Quantum Electronics , vol. 22, no. 1, pp. 1–39, 1998. [2] P. W. Shor, “Algorithms for quantum computation: discrete loga rithms and factoring,” in Proc. of the 35th Annual Symposium on Foundations of Computer Science , pp. 124–134, 1994. [3] L. K. Grover, “Quantum mechanics helps in searching for a needle in a haystack,” Physical Review Letters , vol. 79, no. 2, p. 325, 1997. [4] G. Brassard, P. Høyer, and A. Tapp, “Quantum counting,” in Automata, Languages and Programming , vol. 1443, pp. 820–831, 1998. [5] D. A. Meyer, “Quantum strategies,” Physical Review Letters , vol. 82, no. 5, p. 1052, 1999. [6] J. Eisert, M. Wilkens, and M. Lewenstein, “Quantum games and qu antum strategies,” Physical Review Letters , vol. 83, no. 15, p. 3077, 1999. 17[7] A. P. Flitney and D. Abbott, “Advantage of a quantum player ove r a classical one in 2 x 2 quantum games,” Proceedings of the Royal Society B: Biological Sciences, vol. 459, no. 2038, p. 2463, 2003. [8] L. Marinatto and\n",
      " > 368 [-0.05453  0.02304 -0.06757  0.07495  0.0424 ] than that of algorith ms using PD-like payoﬀ matrix. Later, the reason is explained. Further, we o bserve that the rates of convergence of the algorithms employing the LRR func tion L2 i(·) are faster slightly than that of the algorithms employing the LRR fun ction L1 i(·), because more areas are explored by the LRR function L1 i(·), but this brings better clustering results. In the case when the exact numb er of clusters is unknown in advance, one can adjust the number k of nearest neighbors to control the number of clusters, where the number of clusters de creases inversely with the number k of nearest neighbors. Finally, the clustering algorithms are evaluated on six real datasets, and simulation results have demons trated that data points in a dataset are clustered reasonably and eﬃciently. Acknowledgments The authors would like to thank the anonymous referees for their h elpful comments and suggestions to improve the presentation of this pap er. This work was supported in part by the National Natural Science Foundation of China (No. 60405012, No. 60675055). References [1] V. Vedral and M. Plenio, “Basics of quantum computation,” Progress in Quantum Electronics , vol. 22, no. 1, pp. 1–39, 1998. [2] P. W. Shor, “Algorithms for quantum computation: discrete loga rithms and factoring,” in Proc. of the 35th Annual Symposium on Foundations of Computer Science , pp. 124–134, 1994. [3] L. K. Grover, “Quantum mechanics helps in searching for a needle in a haystack,” Physical Review Letters , vol. 79, no. 2, p. 325, 1997. [4] G. Brassard, P. Høyer, and A. Tapp, “Quantum counting,” in Automata, Languages and Programming , vol. 1443, pp. 820–831, 1998. [5] D. A. Meyer, “Quantum strategies,” Physical Review Letters , vol. 82, no. 5, p. 1052, 1999. [6] J. Eisert, M. Wilkens, and M. Lewenstein, “Quantum games and qu antum strategies,” Physical Review Letters , vol. 83, no. 15, p. 3077, 1999. 17[7] A. P. Flitney and D. Abbott, “Advantage of a quantum player ove r a classical one in 2 x 2 quantum games,” Proceedings of the Royal Society B: Biological Sciences, vol. 459, no. 2038, p. 2463, 2003. [8] L. Marinatto and T. Weber, “A quantum approach to static game s of com- plete information,” Physics Letters A , vol. 272, no. 5-6, pp. 291–303, 2000. [9] C. F. Lee and N. F. Johnson, “Eﬃciency and formalism of quantum games,” Physical Review A , vol. 67, no. 2, p. 022311, 2003. [10] J. Du, H. Li, X. Xu, M. Shi, J. Wu, X. Zhou, and R. Han, “Experime ntal realization of quantum games on a quantum computer,” Physical Review Letters, vol. 88, no. 13, p. 137902, 2002. [11] R. Prevedel, A. Stefanov, P. Walther, and A. Zeilinger, “Exper imental realization of a quantum game on a one-way quantum computer,” New Journal of Physics , vol. 5, pp. 205–215, 2007. [12] C. Schmid, A. P. Flitney, W. Wieczorek, N. Kiesel, H. Weinfurter, and L. C. L. Hollenberg, “Experimental implementation of a four-player quan- tum game,” arXiv:0901.0063v1, 2009. [13] H. Guo, J. Zhang, and G. J. Koehler, “A survey of quantum gam es,” De- cision Support Systems , vol. 46, no. 1, pp. 318–332, 2008. [14] D. Horn and A. Gottlieb, “Algorithm for data clustering in patter n recog- nition problems based on quantum mechanics,” Physical Review Letters , vol. 88, no. 1, p. 018702, 2001. [15] M. Sasaki and A. Carlini, “Quantum learning and universal quant um matching machine,” Physical Review A , vol. 66, no. 2, p. 022303, 2002. [16] C. A. Trugenberger, “Quantum pattern recognition,” Quantum Informa- tion Processing, vol. 1, no. 6, pp. 471–493, 2002. [17] R. Sch¨ utzhold, “Pattern recognition on a quantum computer ,” Physical Review A , vol. 67, no. 6, p. 062311, 2003. [18] E. A¨ ımeur, G. Brassard, and S. Gambs, “Quantum clustering a lgorithms,” in Proceedings of the 24th International Conference on Machin e Learning , (Corvallis, OR), 2007. [19] A. K. Jain, M. N. Murty, and P. J. Flynn, “Data clustering: a rev iew,” ACM Computing Surveys , vol. 31, no. 3, pp. 264–323, 1999. [20] A. Ekert, P. M. Hayden, and H. Inamori, “Course 10: Basic con cepts in quantum computation,” in Coherent atomic matter waves , vol. 72, p. 661, Springer Berlin / Heidelberg, 2001. [21] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information. Cambridge: Cambridge\n",
      " > 369 [-0.08716   0.005726 -0.06207   0.067     0.02751 ] and T. Weber, “A quantum approach to static game s of com- plete information,” Physics Letters A , vol. 272, no. 5-6, pp. 291–303, 2000. [9] C. F. Lee and N. F. Johnson, “Eﬃciency and formalism of quantum games,” Physical Review A , vol. 67, no. 2, p. 022311, 2003. [10] J. Du, H. Li, X. Xu, M. Shi, J. Wu, X. Zhou, and R. Han, “Experime ntal realization of quantum games on a quantum computer,” Physical Review Letters, vol. 88, no. 13, p. 137902, 2002. [11] R. Prevedel, A. Stefanov, P. Walther, and A. Zeilinger, “Exper imental realization of a quantum game on a one-way quantum computer,” New Journal of Physics , vol. 5, pp. 205–215, 2007. [12] C. Schmid, A. P. Flitney, W. Wieczorek, N. Kiesel, H. Weinfurter, and L. C. L. Hollenberg, “Experimental implementation of a four-player quan- tum game,” arXiv:0901.0063v1, 2009. [13] H. Guo, J. Zhang, and G. J. Koehler, “A survey of quantum gam es,” De- cision Support Systems , vol. 46, no. 1, pp. 318–332, 2008. [14] D. Horn and A. Gottlieb, “Algorithm for data clustering in patter n recog- nition problems based on quantum mechanics,” Physical Review Letters , vol. 88, no. 1, p. 018702, 2001. [15] M. Sasaki and A. Carlini, “Quantum learning and universal quant um matching machine,” Physical Review A , vol. 66, no. 2, p. 022303, 2002. [16] C. A. Trugenberger, “Quantum pattern recognition,” Quantum Informa- tion Processing, vol. 1, no. 6, pp. 471–493, 2002. [17] R. Sch¨ utzhold, “Pattern recognition on a quantum computer ,” Physical Review A , vol. 67, no. 6, p. 062311, 2003. [18] E. A¨ ımeur, G. Brassard, and S. Gambs, “Quantum clustering a lgorithms,” in Proceedings of the 24th International Conference on Machin e Learning , (Corvallis, OR), 2007. [19] A. K. Jain, M. N. Murty, and P. J. Flynn, “Data clustering: a rev iew,” ACM Computing Surveys , vol. 31, no. 3, pp. 264–323, 1999. [20] A. Ekert, P. M. Hayden, and H. Inamori, “Course 10: Basic con cepts in quantum computation,” in Coherent atomic matter waves , vol. 72, p. 661, Springer Berlin / Heidelberg, 2001. [21] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information. Cambridge: Cambridge University Press, 20002005. [22] J. Nash, “Equilibrium points in n-person games,” Proceedings of the Na- tional Academy of Sciences , vol. 36, pp. 48–49, 1950. 18[23] J. Nash, “Non-cooperative games,” The Annals of Mathematics , vol. 54, no. 2, pp. 286–295, 1951. [24] D. Fudenberg and J. Tirole, Game Theory . MIT Press, 1983. [25] S. C. Benjamin and P. M. Hayden, “Multiplayer quantum games,” Physical Review A , vol. 64, no. 3, p. 030301, 2001. [26] J. Du, H. Li, X. Xu, M. Shi, X. Zhou, and R. Han, “Entanglement c orre- lated phase changes in quantum games,” Arxiv preprint quant-ph/0111138 , 2001. [27] J. Du, H. Li, X. Xu, X. Zhou, and R. Han, “Phase-transition-like behaviour of quantum games,” Journal of Physics A: Mathematical and Theoretical , vol. 36, pp. 6551–6562, 2003. [28] C. Hauert and M. Doebeli, “Spatial structure often inhibits the evolution of cooperation in the snowdrift game,” Nature, vol. 428, no. 6983, pp. 643– 646, 2004. [29] A.-L. Barab´ asi and E. Bonabeau, “Scale-free networks,” Scientiﬁc Ameri- can, vol. 288, no. 5, pp. 60–69, 2003. [30] G. Erkan, “Language model-based document clustering using r andom walks,” in Proceedings of the main conference on Human Language Tech- nology Conference of the North American Chapter of the Assoc iation of Computational Linguistics , (New York, New York), Association for Com- putational Linguistics, 2006. [31] A. Asuncion and D. J. Newman, UCI Machine Learning Repository (http://www.ics.uci.edu/ mlearn/MLRepository.html). Irvine, CA: Univer- sity of California, School of Information and Computer Science, 20 07. [32] J. MacQueen, “Some methods for classiﬁcation and analysis of m ultivariate observations,” in Proceedings of Fifth Berkeley Symposium on Mathematical Statistics and Probability , vol. 1, (Statistical Laboratory of the University of California, Berkeley), pp. 281–297, 1967. [33] C. Ding and T. Li, “Adaptive dimension reduction using discriminant anal- ysis and k-means clustering,” in Proceedings of the 24th International Con- ference on Machine Learning , (Corvallis, OR), pp. 521–528, 2007. 19−5 −4 −3 −2 −1 0 1 2 3 −4 −3 −2 −1 0 1 2 3\n"
     ]
    }
   ],
   "source": [
    "from rolling.paper import create_paper, print_paper\n",
    "paper = create_paper(\n",
    "    title=pdfs[0],\n",
    "    text=text,\n",
    "    embedding_function=model.encode\n",
    ")\n",
    "print_paper(paper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
