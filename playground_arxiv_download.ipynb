{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "from arxiv import Result\n",
    "\n",
    "# Construct the default API client.\n",
    "client = arxiv.Client()\n",
    "\n",
    "# Search for the 10 most recent articles matching the keyword \"quantum.\"\n",
    "search = arxiv.Search(\n",
    "  query = \"quantum\",\n",
    "  max_results = 10,\n",
    "  sort_by = arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "results = client.results(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arxiv.Result(entry_id='http://arxiv.org/abs/2503.20778v1', updated=datetime.datetime(2025, 3, 26, 17, 56, 38, tzinfo=datetime.timezone.utc), published=datetime.datetime(2025, 3, 26, 17, 56, 38, tzinfo=datetime.timezone.utc), title='Detectability of the chiral gravitational wave background from audible axions with the LISA-Taiji network', authors=[arxiv.Result.Author('Hong Su'), arxiv.Result.Author('Baoyu Xu'), arxiv.Result.Author('Ju Chen'), arxiv.Result.Author('Chang Liu'), arxiv.Result.Author('Yun-Long Zhang')], summary='The chiral gravitational wave background (GWB) can be produced by axion-like\\nfields in the early universe. We perform parameter estimation for two types of\\nchiral GWB with the LISA-Taiji network: axion-dark photon coupling and\\naxion-Nieh-Yan coupling. We estimate the spectral parameters of these two\\nmechanisms induced by axion and determine the normalized model parameters using\\nthe Fisher information matrix. For highly chiral GWB signals that we choose to\\nanalyze in the mHz band, the normalized model parameters are constrained with a\\nrelative error less than $6.7\\\\%$ (dark photon coupling) and $2.2\\\\%$ (Nieh-Yan\\ncoupling) at the one-sigma confidence level. The circular polarization\\nparameters are constrained with a relative error around $21\\\\%$ (dark photon\\ncoupling) and $6.2\\\\%$ (Nieh-Yan coupling) at the one-sigma confidence level.', comment='15 pages, 10 figures', journal_ref=None, doi=None, primary_category='astro-ph.CO', categories=['astro-ph.CO', 'gr-qc', 'hep-ph'], links=[arxiv.Result.Link('http://arxiv.org/abs/2503.20778v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2503.20778v1', title='pdf', rel='related', content_type=None)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = list(results)\n",
    "result_entry:Result = all_results[0]\n",
    "result_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entry_id': 'http://arxiv.org/abs/2503.20778v1',\n",
       " 'updated': datetime.datetime(2025, 3, 26, 17, 56, 38, tzinfo=datetime.timezone.utc),\n",
       " 'published': datetime.datetime(2025, 3, 26, 17, 56, 38, tzinfo=datetime.timezone.utc),\n",
       " 'title': 'Detectability of the chiral gravitational wave background from audible axions with the LISA-Taiji network',\n",
       " 'authors': [arxiv.Result.Author('Hong Su'),\n",
       "  arxiv.Result.Author('Baoyu Xu'),\n",
       "  arxiv.Result.Author('Ju Chen'),\n",
       "  arxiv.Result.Author('Chang Liu'),\n",
       "  arxiv.Result.Author('Yun-Long Zhang')],\n",
       " 'summary': 'The chiral gravitational wave background (GWB) can be produced by axion-like\\nfields in the early universe. We perform parameter estimation for two types of\\nchiral GWB with the LISA-Taiji network: axion-dark photon coupling and\\naxion-Nieh-Yan coupling. We estimate the spectral parameters of these two\\nmechanisms induced by axion and determine the normalized model parameters using\\nthe Fisher information matrix. For highly chiral GWB signals that we choose to\\nanalyze in the mHz band, the normalized model parameters are constrained with a\\nrelative error less than $6.7\\\\%$ (dark photon coupling) and $2.2\\\\%$ (Nieh-Yan\\ncoupling) at the one-sigma confidence level. The circular polarization\\nparameters are constrained with a relative error around $21\\\\%$ (dark photon\\ncoupling) and $6.2\\\\%$ (Nieh-Yan coupling) at the one-sigma confidence level.',\n",
       " 'comment': '15 pages, 10 figures',\n",
       " 'journal_ref': None,\n",
       " 'doi': None,\n",
       " 'primary_category': 'astro-ph.CO',\n",
       " 'categories': ['astro-ph.CO', 'gr-qc', 'hep-ph'],\n",
       " 'links': [arxiv.Result.Link('http://arxiv.org/abs/2503.20778v1', title=None, rel='alternate', content_type=None),\n",
       "  arxiv.Result.Link('http://arxiv.org/pdf/2503.20778v1', title='pdf', rel='related', content_type=None)],\n",
       " 'pdf_url': 'http://arxiv.org/pdf/2503.20778v1',\n",
       " '_raw': {'id': 'http://arxiv.org/abs/2503.20778v1',\n",
       "  'guidislink': True,\n",
       "  'link': 'http://arxiv.org/abs/2503.20778v1',\n",
       "  'updated': '2025-03-26T17:56:38Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2025, tm_mon=3, tm_mday=26, tm_hour=17, tm_min=56, tm_sec=38, tm_wday=2, tm_yday=85, tm_isdst=0),\n",
       "  'published': '2025-03-26T17:56:38Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2025, tm_mon=3, tm_mday=26, tm_hour=17, tm_min=56, tm_sec=38, tm_wday=2, tm_yday=85, tm_isdst=0),\n",
       "  'title': 'Detectability of the chiral gravitational wave background from audible\\n  axions with the LISA-Taiji network',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'Detectability of the chiral gravitational wave background from audible\\n  axions with the LISA-Taiji network'},\n",
       "  'summary': 'The chiral gravitational wave background (GWB) can be produced by axion-like\\nfields in the early universe. We perform parameter estimation for two types of\\nchiral GWB with the LISA-Taiji network: axion-dark photon coupling and\\naxion-Nieh-Yan coupling. We estimate the spectral parameters of these two\\nmechanisms induced by axion and determine the normalized model parameters using\\nthe Fisher information matrix. For highly chiral GWB signals that we choose to\\nanalyze in the mHz band, the normalized model parameters are constrained with a\\nrelative error less than $6.7\\\\%$ (dark photon coupling) and $2.2\\\\%$ (Nieh-Yan\\ncoupling) at the one-sigma confidence level. The circular polarization\\nparameters are constrained with a relative error around $21\\\\%$ (dark photon\\ncoupling) and $6.2\\\\%$ (Nieh-Yan coupling) at the one-sigma confidence level.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'The chiral gravitational wave background (GWB) can be produced by axion-like\\nfields in the early universe. We perform parameter estimation for two types of\\nchiral GWB with the LISA-Taiji network: axion-dark photon coupling and\\naxion-Nieh-Yan coupling. We estimate the spectral parameters of these two\\nmechanisms induced by axion and determine the normalized model parameters using\\nthe Fisher information matrix. For highly chiral GWB signals that we choose to\\nanalyze in the mHz band, the normalized model parameters are constrained with a\\nrelative error less than $6.7\\\\%$ (dark photon coupling) and $2.2\\\\%$ (Nieh-Yan\\ncoupling) at the one-sigma confidence level. The circular polarization\\nparameters are constrained with a relative error around $21\\\\%$ (dark photon\\ncoupling) and $6.2\\\\%$ (Nieh-Yan coupling) at the one-sigma confidence level.'},\n",
       "  'authors': [{'name': 'Hong Su'},\n",
       "   {'name': 'Baoyu Xu'},\n",
       "   {'name': 'Ju Chen'},\n",
       "   {'name': 'Chang Liu'},\n",
       "   {'name': 'Yun-Long Zhang'}],\n",
       "  'author_detail': {'name': 'Yun-Long Zhang'},\n",
       "  'author': 'Yun-Long Zhang',\n",
       "  'arxiv_comment': '15 pages, 10 figures',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/2503.20778v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/2503.20778v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'astro-ph.CO',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'astro-ph.CO',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'gr-qc', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None},\n",
       "   {'term': 'hep-ph',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_entry.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "download_dir = './arxiv_downloads'\n",
    "if not os.path.exists(download_dir):\n",
    "    os.mkdir(download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2503.20778v1.Detectability_of_the_chiral_gravitational_wave_background_from_audible_axions_with_the_LISA_Taiji_network.pdf'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_entry._get_default_filename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./arxiv_downloads\\\\2503.20778v1.Detectability_of_the_chiral_gravitational_wave_background_from_audible_axions_with_the_LISA_Taiji_network.pdf'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_entry.download_pdf(dirpath=download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./arxiv_downloads\\\\2503.20778v1.Detectability_of_the_chiral_gravitational_wave_background_from_audible_axions_with_the_LISA_Taiji_network.tar.gz'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_entry.download_source(dirpath=download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def download_if_new(download_dir:str, result:Result):\n",
    "    result_dir = result._get_default_filename()\n",
    "    result_dir = result_dir.replace('.pdf', '.tar.gz')\n",
    "    result_dir = os.path.join(download_dir, result_dir)\n",
    "    if os.path.exists(result_dir):\n",
    "        return False\n",
    "    \n",
    "    result.download_pdf(dirpath=download_dir)\n",
    "    return True\n",
    "\n",
    "download_if_new(download_dir, result_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    # https://arxiv.org/help/api/user-manual#query_details\n",
    "    \"cs.AI\", # Artificial Intelligence, \n",
    "    \"cs.CL\", # Computation and Language\n",
    "    \"cs.LG\", # Machine Learning,\n",
    "    \"stat.ML\", # Machine Learning,\n",
    "    \"cs.CV\", # Computer Vision and Pattern Recognition,\n",
    "    \"cs.MA\", # Multiagent Systems,\n",
    "    \"cs.NE\", # Neural and Evolutionary Computing,\n",
    "]\n",
    "\n",
    "search = arxiv.Search(\n",
    "  query = ' OR '.join(categories),\n",
    "  max_results = 100,\n",
    "  sort_by = arxiv.SortCriterion.SubmittedDate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001: Mobile-MMLU: A Mobile Intelligence Language Understanding Benchmark\n",
      "0002: Free4D: Tuning-free 4D Scene Generation with Spatial-Temporal Consistency\n",
      "0003: FB-4D: Spatial-Temporal Coherent Dynamic 3D Content Generation with Feature Banks\n",
      "0004: Understanding R1-Zero-Like Training: A Critical Perspective\n",
      "0005: Zero-Shot Audio-Visual Editing via Cross-Modal Delta Denoising\n",
      "0006: BASKET: A Large-Scale Video Dataset for Fine-Grained Skill Estimation\n",
      "0007: Feature4X: Bridging Any Monocular Video to 4D Agentic AI with Versatile Gaussian Feature Fields\n",
      "0008: Welfare and Cost Aggregation for Multi-Agent Control: When to Choose Which Social Cost Function, and Why?\n",
      "0009: Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data\n",
      "0010: An Empirical Study of the Impact of Federated Learning on Machine Learning Model Accuracy\n",
      "0011: Reliable algorithm selection for machine learning-guided design\n",
      "0012: ASGO: Adaptive Structured Gradient Optimization\n",
      "0013: MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search\n",
      "0014: ADS-Edit: A Multimodal Knowledge Editing Dataset for Autonomous Driving Systems\n",
      "0015: Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning\n",
      "0016: Optimal Scaling Laws for Efficiency Gains in a Theoretical Transformer-Augmented Sectional MoE Framework\n",
      "0017: Beyond Believability: Accurate Human Behavior Simulation with Fine-Tuned LLMs\n",
      "0018: UniSTD: Towards Unified Spatio-Temporal Learning across Diverse Disciplines\n",
      "0019: PhysGen3D: Crafting a Miniature Interactive World from a Single Image\n",
      "0020: MATHGLANCE: Multimodal Large Language Models Do Not Know Where to Look in Mathematical Diagrams\n",
      "0021: High Quality Diffusion Distillation on a Single GPU with Relative and Absolute Position Matching\n",
      "0022: Quantum Neural Network Restatement of Markov Jump Process\n",
      "0023: Emotion Detection and Music Recommendation System\n",
      "0024: Ontology-based Semantic Similarity Measures for Clustering Medical Concepts in Drug Safety\n",
      "0025: SChanger: Change Detection from a Semantic Change and Spatial Consistency Perspective\n",
      "0026: RecTable: Fast Modeling Tabular Data with Rectified Flow\n",
      "0027: Benchmarking and optimizing organism wide single-cell RNA alignment methods\n",
      "0028: Continual learning via probabilistic exchangeable sequence modelling\n",
      "0029: Dynamic Motion Blending for Versatile Motion Editing\n",
      "0030: Multi-Robot Coordination Under Physical Limitations\n",
      "0031: A weakly-supervised deep learning model for fast localisation and delineation of the skeleton, internal organs, and spinal canal on Whole-Body Diffusion-Weighted MRI (WB-DWI)\n",
      "0032: Learning Straight Flows by Learning Curved Interpolants\n",
      "0033: From Annotation to Adaptation: Metrics, Synthetic Data, and Aspect Extraction for Aspect-Based Sentiment Analysis with Large Language Models\n",
      "0034: Demand Estimation with Text and Image Data\n",
      "0035: UniEDU: A Unified Language and Vision Assistant for Education Applications\n",
      "0036: MMMORRF: Multimodal Multilingual Modularized Reciprocal Rank Fusion\n",
      "0037: Semi-supervised Node Importance Estimation with Informative Distribution Modeling for Uncertainty Regularization\n",
      "0038: A Low-complexity Structured Neural Network Approach to Intelligently Realize Wideband Multi-beam Beamformers\n",
      "0039: Graph-Enhanced Model-Free Reinforcement Learning Agents for Efficient Power Grid Topological Control\n",
      "0040: Flip Learning: Weakly Supervised Erase to Segment Nodules in Breast Ultrasound\n",
      "0041: GLRD: Global-Local Collaborative Reason and Debate with PSL for 3D Open-Vocabulary Detection\n",
      "0042: Benchmarking Machine Learning Methods for Distributed Acoustic Sensing\n",
      "0043: Vision as LoRA\n",
      "0044: Asset price movement prediction using empirical mode decomposition and Gaussian mixture models\n",
      "0045: Inductive Link Prediction on N-ary Relational Facts via Semantic Hypergraph Reasoning\n",
      "0046: Mitigating Low-Level Visual Hallucinations Requires Self-Awareness: Database, Model and Training Strategy\n",
      "0047: BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation\n",
      "0048: TAMA: A Human-AI Collaborative Thematic Analysis Framework Using Multi-Agent LLMs for Clinical Interviews\n",
      "0049: AutoRad-Lung: A Radiomic-Guided Prompting Autoregressive Vision-Language Model for Lung Nodule Malignancy Prediction\n",
      "0050: ARMO: Autoregressive Rigging for Multi-Category Objects\n",
      "0051: DR-PETS: Learning-Based Control With Planning in Adversarial Environments\n",
      "0052: Probabilistic Forecasting for Network Resource Analysis in Integrated Terrestrial and Non-Terrestrial Networks\n",
      "0053: AccidentSim: Generating Physically Realistic Vehicle Collision Videos from Real-World Accident Reports\n",
      "0054: UWarp: A Whole Slide Image Registration Pipeline to Characterize Scanner-Induced Local Domain Shift\n",
      "0055: Imitating Radiological Scrolling: A Global-Local Attention Model for 3D Chest CT Volumes Multi-Label Anomaly Classification\n",
      "0056: TN-Eval: Rubric and Evaluation Protocols for Measuring the Quality of Behavioral Therapy Notes\n",
      "0057: MMGen: Unified Multi-modal Image Generation and Understanding in One Go\n",
      "0058: Representation Improvement in Latent Space for Search-Based Testing of Autonomous Robotic Systems\n",
      "0059: Unlocking Efficient Long-to-Short LLM Reasoning with Model Merging\n",
      "0060: PVLens: Enhancing Pharmacovigilance Through Automated Label Extraction\n",
      "0061: Procedural Knowledge Ontology (PKO)\n",
      "0062: Enhancing Multi-modal Models with Heterogeneous MoE Adapters for Fine-tuning\n",
      "0063: Robust Flower Cluster Matching Using The Unscented Transform\n",
      "0064: $Î²$-GNN: A Robust Ensemble Approach Against Graph Structure Perturbation\n",
      "0065: Collaborative Storytelling and LLM: A Linguistic Analysis of Automatically-Generated Role-Playing Game Sessions\n",
      "0066: ProFed: a Benchmark for Proximity-based non-IID Federated Learning\n",
      "0067: State-Aware Perturbation Optimization for Robust Deep Reinforcement Learning\n",
      "0068: IAP: Improving Continual Learning of Vision-Language Models via Instance-Aware Prompting\n",
      "0069: A decision-theoretic approach to dealing with uncertainty in quantum mechanics\n",
      "0070: Diffusion Counterfactuals for Image Regressors\n",
      "0071: Synthetic Data Augmentation for Cross-domain Implicit Discourse Relation Recognition\n",
      "0072: Feature Statistics with Uncertainty Help Adversarial Robustness\n",
      "0073: Optimizing Case-Based Reasoning System for Functional Test Script Generation with Large Language Models\n",
      "0074: Exploring Robustness of Cortical Morphometry in the presence of white matter lesions, using Diffusion Models for Lesion Filling\n",
      "0075: Low-resource Information Extraction with the European Clinical Case Corpus\n",
      "0076: TerraTorch: The Geospatial Foundation Models Toolkit\n",
      "0077: A Theoretical Framework for Prompt Engineering: Approximating Smooth Functions with Transformer Prompts\n",
      "0078: A Retrieval-Based Approach to Medical Procedure Matching in Romanian\n",
      "0079: Injecting Adrenaline into LLM Serving: Boosting Resource Utilization and Throughput via Attention Disaggregation\n",
      "0080: Regression-Based Estimation of Causal Effects in the Presence of Selection Bias and Confounding\n",
      "0081: Fast, Modular, and Differentiable Framework for Machine Learning-Enhanced Molecular Simulations\n",
      "0082: Beyond Intermediate States: Explaining Visual Redundancy through Language\n",
      "0083: TD-BFR: Truncated Diffusion Model for Efficient Blind Face Restoration\n",
      "0084: Accelerate Parallelizable Reasoning via Parallel Decoding within One Sequence\n",
      "0085: StableToolBench-MirrorAPI: Modeling Tool Environments as Mirrors of 7,000+ Real-World APIs\n",
      "0086: GAIA-2: A Controllable Multi-View Generative World Model for Autonomous Driving\n",
      "0087: MAR-3D: Progressive Masked Auto-regressor for High-Resolution 3D Generation\n",
      "0088: Exploring the Effect of Robotic Embodiment and Empathetic Tone of LLMs on Empathy Elicitation\n",
      "0089: Small Object Detection: A Comprehensive Survey on Challenges, Techniques and Real-World Applications\n",
      "0090: Explainable ICD Coding via Entity Linking\n",
      "0091: Harmonia: A Multi-Agent Reinforcement Learning Approach to Data Placement and Migration in Hybrid Storage Systems\n",
      "0092: Riemannian Optimization on Relaxed Indicator Matrix Manifold\n",
      "0093: Vision-Amplified Semantic Entropy for Hallucination Detection in Medical Visual Question Answering\n",
      "0094: MLLM-Selector: Necessity and Diversity-driven High-Value Data Selection for Enhanced Visual Instruction Tuning\n",
      "0095: Design and Evaluation of Neural Network-Based Receiver Architectures for Reliable Communication\n",
      "0096: Enhancing Depression Detection via Question-wise Modality Fusion\n",
      "0097: Automated and Risk-Aware Engine Control Calibration Using Constrained Bayesian Optimization\n",
      "0098: Towards Efficient and General-Purpose Few-Shot Misclassification Detection for Vision-Language Models\n",
      "0099: VPO: Aligning Text-to-Video Generation Models with Prompt Optimization\n",
      "0100: Adaptive Local Clustering over Attributed Graphs\n",
      "0101: Underwater Image Enhancement by Convolutional Spiking Neural Networks\n",
      "0102: Contrastive Learning Guided Latent Diffusion Model for Image-to-Image Translation\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.title\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mdownload_if_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mdownload_if_new\u001b[39m\u001b[34m(download_dir, result)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(result_dir):\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\rolling_embedding\\.venv\\Lib\\site-packages\\arxiv\\__init__.py:212\u001b[39m, in \u001b[36mResult.download_pdf\u001b[39m\u001b[34m(self, dirpath, filename)\u001b[39m\n\u001b[32m    210\u001b[39m     filename = \u001b[38;5;28mself\u001b[39m._get_default_filename()\n\u001b[32m    211\u001b[39m path = os.path.join(dirpath, filename)\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m written_path, _ = \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpdf_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m written_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\_app\\Python312\\Lib\\urllib\\request.py:240\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m \u001b[33;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    238\u001b[39m url_type, path = _splittype(url)\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m contextlib.closing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    241\u001b[39m     headers = fp.info()\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\_app\\Python312\\Lib\\urllib\\request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\_app\\Python312\\Lib\\urllib\\request.py:515\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    512\u001b[39m     req = meth(req)\n\u001b[32m    514\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    518\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\_app\\Python312\\Lib\\urllib\\request.py:532\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    531\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\_app\\Python312\\Lib\\urllib\\request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\_app\\Python312\\Lib\\urllib\\request.py:1373\u001b[39m, in \u001b[36mHTTPHandler.http_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\_app\\Python312\\Lib\\urllib\\request.py:1348\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1346\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m   1347\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     r = \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1349\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1350\u001b[39m     h.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\_app\\Python312\\Lib\\http\\client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\_app\\Python312\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\_app\\Python312\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\_app\\Python312\\Lib\\socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for r in client.results(search):\n",
    "    i += 1\n",
    "    print(f'{i:04d}: {r.title}')\n",
    "    download_if_new(download_dir, r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
